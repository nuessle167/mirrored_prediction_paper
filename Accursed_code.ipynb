{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da35bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Matching Fermi-GBM and Swift Data###\n",
    "import pandas as pd\n",
    "import math\n",
    "import gc\n",
    "import julian\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "import scipy.stats as st\n",
    "import re\n",
    "import datetime\n",
    "from statistics import NormalDist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pdb\n",
    "import scipy.integrate as integrate\n",
    "from scipy.optimize import fsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4771729e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-f44b1bb923f1>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weird_xrt_data['GRB '][k]='0{}'.format(weird_xrt_data['GRB '][k])\n"
     ]
    }
   ],
   "source": [
    "##Data import##\n",
    "fermi_data=pd.read_csv('22_May_2023_Fermi_Data.csv')\n",
    "swift_data=pd.read_csv('real swift bat data 3.csv')\n",
    "swift_model_PL=pd.read_csv('swift_models_3_PL.csv')\n",
    "swift_model_CPL=pd.read_csv('swift_models_3_PL.csv')\n",
    "swift_fluxes_PL=pd.read_csv('swift_fluxes_3_PL.csv')\n",
    "swift_fluxes_CPL=pd.read_csv('swift_fluxes_3_PL.csv')\n",
    "swift_fluences_PL=pd.read_csv('swift_fluences_3_PL.csv')\n",
    "swift_fluences_CPL=pd.read_csv('swift_fluences_3_PL.csv')\n",
    "swift_fluences_reference=pd.read_csv('swift_fluences_3_match.csv')\n",
    "swift_redshifts=pd.read_csv('swift_redshifts.csv')\n",
    "second_redshifts=pd.read_csv(\"changed_alternative_GCN_redshifts.csv\")\n",
    "more_xrt_data=pd.read_csv('XRT_most_detailed_data.csv')\n",
    "weird_xrt_data=pd.DataFrame.copy(more_xrt_data)\n",
    "for k in range(0, len(weird_xrt_data)):\n",
    "    weird_xrt_data['GRB '][k]='0{}'.format(weird_xrt_data['GRB '][k])\n",
    "average_decay_data=pd.read_csv('Stage_2_decay_rates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "625aba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#God forbid I actually define a function#\n",
    "def singly_broken_PL(amplitude, break1, power1, power2, t0, t):\n",
    "    if t<break1 and t>t0:\n",
    "        value=amplitude*t**(power1)\n",
    "    elif t>=break1:\n",
    "        value=amplitude*t**(power2)*break1**(power1-power2)\n",
    "    else:\n",
    "        value='N/A'\n",
    "    return value\n",
    "\n",
    "def doubly_broken_PL(amplitude, break1, break2, power1, power2, power3, t0, t):\n",
    "    if t<break1 and t>t0:\n",
    "        value=amplitude*t**(power1)\n",
    "    elif t>=break1 and t<break2:\n",
    "        value=amplitude*t**(power2)*break1**(power1-power2)\n",
    "    elif t>=break2:\n",
    "        value=amplitude*t**(power3)*break1**(power1-power2)*break2**(power2-power3)\n",
    "    else:\n",
    "        value='N/A'\n",
    "    return value\n",
    "\n",
    "def triply_broken_PL(amplitude, break1, break2, break3, power1, power2, power3, power4, t0,\\\n",
    "                     t):\n",
    "    if t<break1 and t>t0:\n",
    "        value=amplitude*t**(power1)\n",
    "    elif t>=break1 and t<break2:\n",
    "        value=amplitude*t**(power2)*break1**(power1-power2)\n",
    "    elif t>=break2 and t<break3:\n",
    "        value=amplitude*t**(power3)*break1**(power1-power2)*break2**(power2-power3)\n",
    "    elif t>=break3:\n",
    "        value=amplitude*t**(power4)*break1**(power1-power2)*break2**(power2-power3)*\\\n",
    "                              break3**(power3-power4)\n",
    "    else:\n",
    "        value='N/A'\n",
    "    return value\n",
    "\n",
    "def quadruply_broken_PL(amplitude, break1, break2, break3, break4, power1, power2, power3,\\\n",
    "                        power4, power5, t0, t):\n",
    "    if t<break1 and t>t0:\n",
    "        value=amplitude*t**(power1)\n",
    "    elif t>=break1 and t<break2:\n",
    "        value=amplitude*t**(power2)*break1**(power1-power2)\n",
    "    elif t>=break2 and t<break3:\n",
    "        value=amplitude*t**(power3)*break1**(power1-power2)*break2**(power2-power3)\n",
    "    elif t>=break3 and t<break4:\n",
    "        value=amplitude*t**(power4)*break1**(power1-power2)*break2**(power2-power3)*\\\n",
    "                              break3**(power3-power4)\n",
    "    elif t>=break4:\n",
    "        value=amplitude*t**(power5)*break1**(power1-power2)*break2**(power2-power3)*\\\n",
    "                              break3**(power3-power4)*break4**(power4-power5)\n",
    "    else:\n",
    "        value='N/A'\n",
    "    return value\n",
    "\n",
    "def quintuply_broken_PL(amplitude, break1, break2, break3, break4, break5, power1, power2,\\\n",
    "                        power3, power4, power5, power6, t0, t):\n",
    "    if t<break1 and t>t0:\n",
    "        value=amplitude*t**(power1)\n",
    "    elif t>=break1 and t<break2:\n",
    "        value=amplitude*t**(power2)*break1**(power1-power2)\n",
    "    elif t>=break2 and t<break3:\n",
    "        value=amplitude*t**(power3)*break1**(power1-power2)*break2**(power2-power3)\n",
    "    elif t>=break3 and t<break4:\n",
    "        value=amplitude*t**(power4)*break1**(power1-power2)*break2**(power2-power3)*\\\n",
    "                              break3**(power3-power4)\n",
    "    elif t>=break4 and t<break5:\n",
    "        value=amplitude*t**(power5)*break1**(power1-power2)*break2**(power2-power3)*\\\n",
    "                              break3**(power3-power4)*break4**(power4-power5)\n",
    "    elif t>=break5:\n",
    "        value=amplitude*t**(power6)*break1**(power1-power2)*break2**(power2-power3)*\\\n",
    "                              break3**(power3-power4)*break4**(power4-power5)*\\\n",
    "                                break5**(power5-power6)\n",
    "    else:\n",
    "        value='N/A'\n",
    "    return value\n",
    "\n",
    "def defining_the_flux(tarjit, temporal_indices):\n",
    "    flux_catch=' Obs Flux_{} (pc) '.format(tarjit+1)\n",
    "    tarjete=tarjit+1\n",
    "    xrt_flux=more_xrt_data[flux_catch][xrt_match]\n",
    "    state=0\n",
    "    if xrt_flux==' N/A ' or xrt_flux=='N/A' or xrt_flux=='NaN':\n",
    "        flux_catch=' Obs Flux_{} (wt) '.format(tarjit+1)\n",
    "        xrt_flux=more_xrt_data[flux_catch][xrt_match]\n",
    "        state=1\n",
    "        #weird case where sometimes XRT is still repointing or something, IDK.\n",
    "        #It nets us 220101A, which is what I wanted.\n",
    "    if tarjit==0:\n",
    "        if xrt_flux==' N/A ' or xrt_flux=='N/A' or xrt_flux=='NaN':\n",
    "            flux_catch=' Obs Flux_{} (pc) '.format(tarjit+2)\n",
    "            xrt_flux=more_xrt_data[flux_catch][xrt_match]\n",
    "            tarjete=tarjit+2\n",
    "            state=0\n",
    "            if xrt_flux==' N/A ' or xrt_flux=='N/A' or xrt_flux=='NaN':\n",
    "                flux_catch=' Obs Flux_{} (wt) '.format(tarjit+2)\n",
    "                xrt_flux=more_xrt_data[flux_catch][xrt_match]\n",
    "                state=1\n",
    "                #weird case where if it's at the very beginning, XRT\n",
    "                #might not be measuring flux yet\n",
    "    return flux_catch, xrt_flux, tarjete, state\n",
    "\n",
    "def HR_err_func(S_top, S_bot, sig_S_top, sig_S_bot):\n",
    "    HR_err=np.sqrt(np.power((sig_S_top/S_bot), 2)+np.power((S_top*sig_S_bot)/\\\n",
    "                                                          np.power(S_bot,2), 2))\n",
    "    return HR_err\n",
    "\n",
    "def Fermi_HR_func(relevant_fermi_data, spectral_model, entry):\n",
    "    low_e_range=[15, 150]\n",
    "    high_e_range=[150, 1500]\n",
    "    if spectral_model=='flnc_plaw              ' or spectral_model==1:\n",
    "        p_1=float(relevant_fermi_data.at[entry, 'flnc_plaw_index'])\n",
    "        low_HR=integrate.quad(lambda x: power_law(x, p_1), low_e_range[0], \\\n",
    "                              low_e_range[1]) #PL\n",
    "        high_HR=integrate.quad(lambda x: power_law(x, p_1), high_e_range[0], \\\n",
    "                              high_e_range[1]) #PL\n",
    "        HR=high_HR[0]/low_HR[0]\n",
    "        \n",
    "    elif spectral_model=='flnc_comp              ' or spectral_model==2:\n",
    "        p_1=float(relevant_fermi_data.at[entry, 'flnc_comp_index'])\n",
    "        E_break=float(relevant_fermi_data.at[entry, 'flnc_comp_epeak'])\n",
    "        low_HR=integrate.quad(lambda x:  Compton_PL(x, p_1, E_break), \\\n",
    "                       low_e_range[0], low_e_range[1]) #CPL\n",
    "        high_HR=integrate.quad(lambda x: Compton_PL(x, p_1, E_break), \\\n",
    "                       high_e_range[0], high_e_range[1]) #CPL\n",
    "        HR=high_HR[0]/low_HR[0]\n",
    "        \n",
    "    elif spectral_model=='flnc_band              ' or spectral_model==3:\n",
    "        p_1=float(relevant_fermi_data.at[entry, 'flnc_band_alpha'])\n",
    "        p_2=float(relevant_fermi_data.at[entry, 'flnc_band_beta'])\n",
    "        E_break=float(relevant_fermi_data.at[entry, 'flnc_band_epeak'])\n",
    "        low_HR=integrate.quad(lambda x: Band_function(x, E_break, p_1, p_2), \\\n",
    "                       low_e_range[0], low_e_range[1]) #Band\n",
    "        high_HR=integrate.quad(lambda x: Band_function(x, E_break, p_1, p_2), \\\n",
    "                       high_e_range[0], high_e_range[1]) #Band\n",
    "        HR=high_HR[0]/low_HR[0]\n",
    "        \n",
    "    elif spectral_model=='flnc_sbpl              ' or spectral_model==4:\n",
    "        p_1=float(relevant_fermi_data.at[entry, 'flnc_sbpl_indx1'])\n",
    "        p_2=float(relevant_fermi_data.at[entry, 'flnc_sbpl_indx2'])\n",
    "        E_break=float(relevant_fermi_data.at[entry, 'flnc_sbpl_brken'])\n",
    "        smoothen=float(relevant_fermi_data.at[entry, 'flnc_sbpl_brksc'])\n",
    "        low_HR=integrate.quad(lambda x: Smoothly_Broken_PL(x, E_break, p_1, p_2, smoothen), \\\n",
    "                       low_e_range[0], low_e_range[1])\n",
    "        high_HR=integrate.quad(lambda x: Smoothly_Broken_PL(x, E_break, p_1, p_2, smoothen),\\\n",
    "                       high_e_range[0], high_e_range[1])\n",
    "        HR=high_HR[0]/low_HR[0]\n",
    "        \n",
    "    else:\n",
    "        if relevant_fermi_data.at[entry, 'flnc_plaw_index']:\n",
    "            p_1=float(relevant_fermi_data.at[entry, 'flnc_plaw_index'])\n",
    "            low_HR=integrate.quad(lambda x: power_law(x, p_1), low_e_range[0], \\\n",
    "                                  low_e_range[1])\n",
    "            high_HR=integrate.quad(lambda x: power_law(x, p_1), \\\n",
    "                               high_e_range[0], high_e_range[1]) \n",
    "            #PL because that's the simplest one, unfortunately\n",
    "            HR=high_HR[0]/low_HR[0]\n",
    "        else:\n",
    "            HR=np.NA\n",
    "    return HR\n",
    "\n",
    "def swift_error_calculator(entry, fluence_table):\n",
    "    if fluence_table.at[entry, ' 50_100kev_low '] != ' N/A ':\n",
    "         HR_err_left = HR_err_func(float(fluence_table.at[entry, ' 50_100kev ']), \\\n",
    "                                float(fluence_table.at[entry, ' 25_50kev ']), \\\n",
    "                                float(fluence_table.at[entry,' 50_100kev_low ']), \\\n",
    "                                float(fluence_table.at[entry,' 25_50kev_low ']))\n",
    "#         HR_err_left = (float(fluence_table.at[entry,' 50_100kev '])-\\\n",
    "#                         float(fluence_table.at[entry, ' 50_100kev_low ']))/\\\n",
    "#                             (float(fluence_table.at[entry, ' 25_50kev '])-\\\n",
    "#                                    float(fluence_table.at[entry,' 25_50kev_low ']))\n",
    "    else:\n",
    "        HR_err_left = 0\n",
    "    if fluence_table.at[entry, ' 50_100kev_hi '] != ' N/A ':\n",
    "         HR_err_right=HR_err_func(float(fluence_table.at[entry, ' 50_100kev ']),\\\n",
    "                                 float(fluence_table.at[entry, ' 25_50kev ']), \\\n",
    "                                 float(fluence_table.at[entry,' 50_100kev_hi ']), \\\n",
    "                             float(fluence_table.at[entry,' 25_50kev_hi ']))\n",
    "#         HR_err_right = (float(fluence_table.at[entry, ' 50_100kev '])-\\\n",
    "#                         float(fluence_table.at[entry, ' 50_100kev_hi ']))/\\\n",
    "#                             (float(fluence_table.at[entry, ' 25_50kev '])-\\\n",
    "#                                    float(fluence_table.at[entry, ' 25_50kev_hi ']))\n",
    "    else:\n",
    "        HR_err_right = 0\n",
    "    return [HR_err_left, HR_err_right]\n",
    "\n",
    "def power_law (variable, index):\n",
    "    value=variable**index\n",
    "    return value\n",
    "\n",
    "def Compton_PL (variable, index, break_E):\n",
    "    value=np.power(variable, index)*np.exp(-variable/break_E)\n",
    "    return value\n",
    "\n",
    "def Band_function (variable, break_E, index_1, index_2):\n",
    "    index_1=abs(index_1)\n",
    "    index_2=abs(index_2)\n",
    "    value=np.where(variable < ((index_1-index_2)*break_E)/(index_1), \\\n",
    "        ((variable/100)**index_2)*np.exp(index_2-index_1)*(((index_1-index_2)*\\\n",
    "        break_E)/(100*(index_1)))**(index_1-index_2), ((variable/100)**index_1)*\\\n",
    "        np.exp(-((index_1)*variable)/break_E))\n",
    "    return np.real(value)\n",
    "\n",
    "def Smoothly_Broken_PL (variable, break_E, index_1, index_2, smoothen):\n",
    "    value=(variable/break_E)**(index_1)*(0.5*(1+(variable/break_E)**(1/smoothen)))**\\\n",
    "    (-(index_1-index_2)/smoothen)\n",
    "    return value\n",
    "\n",
    "def z_power_law(variable, index, redshift):\n",
    "    value=(variable*(1+redshift))**(index)\n",
    "    return value\n",
    "\n",
    "def swift_fluence_function(burst_index, column_name):\n",
    "    if swift_fluences_reference.at[burst_index, ' Best-fit model']==' PL':\n",
    "        fluence=swift_fluences_PL.at[burst_index, column_name]\n",
    "    elif swift_fluences_reference.at[burst_index, ' Best-fit model']==' CPL':\n",
    "        fluence=swift_fluences_CPL.at[burst_index, column_name]\n",
    "    else:\n",
    "        fluence=np.NaN\n",
    "    return fluence\n",
    "\n",
    "def swift_flux_function(burst_index, column_name):\n",
    "    if swift_fluences_reference.at[burst_index, ' Best-fit model']==' PL':\n",
    "        flux=swift_fluxes_PL.at[burst_index, column_name]\n",
    "    elif swift_fluences_reference.at[burst_index, ' Best-fit model']==' CPL':\n",
    "        flux=swift_fluxes_CPL.at[burst_index, column_name]\n",
    "    else:\n",
    "        flux=np.NaN\n",
    "    return flux\n",
    "\n",
    "def swift_model_function(burst_index, column_name):\n",
    "    if swift_fluences_reference.at[burst_index, ' Best-fit model']==' PL':\n",
    "        model=swift_model_PL.at[burst_index, column_name]\n",
    "    elif swift_fluences_reference.at[burst_index, ' Best-fit model']==' CPL':\n",
    "        model=swift_model_CPL.at[burst_index, column_name]\n",
    "    else:\n",
    "        model=np.NaN\n",
    "    return model\n",
    "\n",
    "def getting_the_GBM_E_peak(relevant_fermi_data, spectral_model, entry):\n",
    "    if spectral_model=='flnc_plaw              ' or spectral_model==1:\n",
    "        if relevant_fermi_data.at[entry, 'flnc_comp_epeak']:\n",
    "            E_peak=float(relevant_fermi_data.at[entry, 'flnc_comp_epeak'])\n",
    "        elif relevant_fermi_data.at[entry, 'flnc_band_epeak']:\n",
    "            E_peak=float(relevant_fermi_data.at[entry, 'flnc_band_epeak'])\n",
    "        else:\n",
    "            E_peak=np.NaN\n",
    "    elif spectral_model=='flnc_comp              ' or spectral_model==2:\n",
    "        E_peak=float(relevant_fermi_data.at[entry, 'flnc_comp_epeak'])\n",
    "    elif spectral_model=='flnc_band              ' or spectral_model==3:\n",
    "        E_peak=float(relevant_fermi_data.at[entry, 'flnc_band_epeak'])\n",
    "    elif spectral_model=='flnc_sbpl              ' or spectral_model==4:\n",
    "        E_peak=float(relevant_fermi_data.at[entry, 'flnc_sbpl_brken'])\n",
    "    else:\n",
    "        E_peak=np.NaN\n",
    "    return E_peak\n",
    "\n",
    "def getting_the_BAT_E_peak(entry):\n",
    "    if swift_fluences_reference.at[entry, ' Best-fit model']==' CPL':\n",
    "        if swift_model_CPL.at[entry, ' Epeak '] != ' N/A ':\n",
    "            E_peak=float(swift_model_CPL.at[entry, ' Epeak '])\n",
    "        else:\n",
    "            E_peak= np.NaN\n",
    "    elif swift_fluences_reference.at[entry, ' Best-fit model']==' PL':\n",
    "        if swift_model_CPL.at[entry, ' Epeak ']:\n",
    "            if swift_model_CPL.at[entry, ' Epeak '] != ' N/A ':\n",
    "                E_peak=float(swift_model_CPL.at[entry, ' Epeak '])\n",
    "            else:\n",
    "                E_peak= np.NaN\n",
    "        else:\n",
    "            E_peak= np.NaN\n",
    "    else:\n",
    "        E_peak=np.NaN\n",
    "    return E_peak\n",
    "\n",
    "def Fermi_k_func(relevant_fermi_data, spectral_model, entry, redshift):\n",
    "#     pdb.set_trace()\n",
    "    low_e_range=[10, 1000]\n",
    "    high_e_range=[1/(1+redshift), 10000/(1+redshift)]\n",
    "    if spectral_model=='flnc_plaw              ' or spectral_model==1:\n",
    "        p_1=float(relevant_fermi_data.at[entry, 'flnc_plaw_index'])\n",
    "        denominator=integrate.quad(lambda x: power_law(x, p_1), low_e_range[0], \\\n",
    "                              low_e_range[1]) #PL\n",
    "        numerator=integrate.quad(lambda x: power_law(x, p_1), high_e_range[0], \\\n",
    "                              high_e_range[1]) #PL\n",
    "        k=numerator[0]/denominator[0]\n",
    "        \n",
    "    elif spectral_model=='flnc_comp              ' or spectral_model==2:\n",
    "        p_1=float(relevant_fermi_data.at[entry, 'flnc_comp_index'])\n",
    "        E_break=float(relevant_fermi_data.at[entry, 'flnc_comp_epeak'])\n",
    "        denominator=integrate.quad(lambda x:  Compton_PL(x, p_1, E_break), \\\n",
    "                       low_e_range[0], low_e_range[1]) #CPL\n",
    "        numerator=integrate.quad(lambda x: Compton_PL(x, p_1, E_break), \\\n",
    "                       high_e_range[0], high_e_range[1]) #CPL\n",
    "        k=numerator[0]/denominator[0]\n",
    "        \n",
    "    elif spectral_model=='flnc_band              ' or spectral_model==3:\n",
    "        p_1=float(relevant_fermi_data.at[entry, 'flnc_band_alpha'])\n",
    "        p_2=float(relevant_fermi_data.at[entry, 'flnc_band_beta'])\n",
    "        E_break=float(relevant_fermi_data.at[entry, 'flnc_band_epeak'])\n",
    "        denominator=integrate.quad(lambda x: Band_function(x, E_break, p_1, p_2), \\\n",
    "                       low_e_range[0], low_e_range[1]) #Band\n",
    "        numerator=integrate.quad(lambda x: Band_function(x, E_break, p_1, p_2), \\\n",
    "                       high_e_range[0], high_e_range[1]) #Band\n",
    "        k=numerator[0]/denominator[0]\n",
    "        \n",
    "    elif spectral_model=='flnc_sbpl              ' or spectral_model==4:\n",
    "        p_1=float(relevant_fermi_data.at[entry, 'flnc_sbpl_indx1'])\n",
    "        p_2=float(relevant_fermi_data.at[entry, 'flnc_sbpl_indx2'])\n",
    "        E_break=float(relevant_fermi_data.at[entry, 'flnc_sbpl_brken'])\n",
    "        smoothen=float(relevant_fermi_data.at[entry, 'flnc_sbpl_brksc'])\n",
    "        denominator=integrate.quad(lambda x: Smoothly_Broken_PL(x, E_break, p_1, p_2, smoothen), \\\n",
    "                       low_e_range[0], low_e_range[1])\n",
    "        numerator=integrate.quad(lambda x: Smoothly_Broken_PL(x, E_break, p_1, p_2, smoothen),\\\n",
    "                       high_e_range[0], high_e_range[1])\n",
    "        k=numerator[0]/denominator[0]\n",
    "        \n",
    "    else:\n",
    "        if relevant_fermi_data.at[entry, 'flnc_plaw_index']:\n",
    "            p_1=float(relevant_fermi_data.at[entry, 'flnc_plaw_index'])\n",
    "            denominator=integrate.quad(lambda x: power_law(x, p_1), low_e_range[0], \\\n",
    "                                  low_e_range[1])\n",
    "            numerator=integrate.quad(lambda x: power_law(x, p_1), \\\n",
    "                               high_e_range[0], high_e_range[1]) \n",
    "            #PL because that's the simplest one, unfortunately\n",
    "            k=numerator[0]/denominator[0]\n",
    "        else:\n",
    "            k=np.NA\n",
    "    return k\n",
    "\n",
    "def XRT_k_func(relevant_xrt_data, entry, redshift):\n",
    "#     pdb.set_trace()\n",
    "    low_e_range=[0.2, 10]\n",
    "    high_e_range=[0.2/(1+redshift), 10/(1+redshift)]\n",
    "    if float(relevant_xrt_data.at[entry, 'plaw_index']):\n",
    "        p_1=-abs(float(relevant_xrt_data.at[entry, 'plaw_index']))\n",
    "        denominator=integrate.quad(lambda x: power_law(x, p_1), low_e_range[0], \\\n",
    "                              low_e_range[1]) #PL\n",
    "        numerator=integrate.quad(lambda x: power_law(x, p_1), high_e_range[0], \\\n",
    "                              high_e_range[1]) #PL\n",
    "        k=np.real(numerator[0]/denominator[0])\n",
    "    else:\n",
    "        k=np.NaN\n",
    "    return k\n",
    "\n",
    "def kinetic_energy(nFn, beta, D_L, redshift, time, nu):\n",
    "#     pdb.set_trace()\n",
    "    time=((time/60)/60)/24\n",
    "    nu=nu/(10**18)\n",
    "    p=2*beta\n",
    "    Y=1\n",
    "    eps_e=0.1\n",
    "    eps_b=0.01\n",
    "    nFn_term=(nFn/(5.2*1e-14))**(4/(p+2))\n",
    "    dist_term=((D_L*1e-28)**(8/(p+2)))\n",
    "    rs_term=(1+redshift)**(-1)\n",
    "    time_term=(time**((3*p-2)/(p+2)))*(1+Y)**(4/(p+2))\n",
    "    if p != 2:\n",
    "        fluxy_term=((6.73*((p-2)/(p-1))**(p-1))*((3.3*1e-6)**((p-2.3)/2)))**(-4/(p+2))\n",
    "    else:\n",
    "        #This is jsut a guess around the value given the other results, \n",
    "        #since p=2 is a discountinuity\n",
    "        fluxy_term=((6.73*((p-1.9925)/(p-1))**(p-1))*((3.3*1e-6)**((p-2.3)/2)))**(-4/(p+2))\n",
    "    carrier_dens_terms=((eps_e*1e1)**((4*(1-p))/(p+2)))*(eps_b*1e2)**((2-p)/(p+2))\n",
    "    freq_term=(nu*1e-18)**((2*(p-2))/(p+2))\n",
    "    E_k=nFn_term*dist_term*rs_term*time_term*fluxy_term*carrier_dens_terms*freq_term\n",
    "    return E_k\n",
    "\n",
    "def efficiency(E_k, E_g):\n",
    "    eta=E_g/(E_g+E_k)\n",
    "    return eta\n",
    "\n",
    "def singly_broken_PL_derivative(amplitude, break1, power1, power2, t0, t):\n",
    "    if t<break1 and t>t0:\n",
    "        value=amplitude*power_1*t**(power1-1)\n",
    "    elif t>=break1:\n",
    "        value=amplitude*power_2*t**(power2-1)*break1**(power1-power2)\n",
    "    else:\n",
    "        value=np.NaN\n",
    "    return value\n",
    "\n",
    "def doubly_broken_PL_derivative(amplitude, break1, break2, power1, power2, power3, t0, t):\n",
    "    if t<break1 and t>t0:\n",
    "        value=amplitude*power1*t**(power1-1)\n",
    "    elif t>=break1 and t<break2:\n",
    "        value=amplitude*power2*t**(power2-1)*break1**(power1-power2)\n",
    "    elif t>=break2:\n",
    "        value=amplitude*power3*t**(power3-1)*break1**(power1-power2)*\\\n",
    "        break2**(power2-power3)\n",
    "    else:\n",
    "        value=np.NaN\n",
    "    return value\n",
    "\n",
    "def triply_broken_PL_derivative(amplitude, break1, break2, break3, power1, power2,\\\n",
    "                                power3, power4, t0, t):\n",
    "    if t<break1 and t>t0:\n",
    "        value=amplitude*power1*t**(power1-1)\n",
    "    elif t>=break1 and t<break2:\n",
    "        value=amplitude*power2*t**(power2-1)*break1**(power1-power2)\n",
    "    elif t>=break2 and t<break3:\n",
    "        value=amplitude*power3*t**(power3-1)*break1**(power1-power2)\\\n",
    "        *break2**(power2-power3)\n",
    "    elif t>=break3:\n",
    "        value=amplitude*power4*t**(power4-1)*break1**(power1-power2)*break2**(power2-power3)\\\n",
    "        *break3**(power3-power4)\n",
    "    else:\n",
    "        value=np.NaN\n",
    "    return value\n",
    "\n",
    "def quadruply_broken_PL_derivative(amplitude, break1, break2, break3, break4, power1,\\\n",
    "                                   power2, power3, power4, power5, t0, t):\n",
    "    if t<break1 and t>t0:\n",
    "        value=amplitude*power3*t**(power1-1)\n",
    "    elif t>=break1 and t<break2:\n",
    "        value=amplitude*power2*t**(power2-1)*break1**(power1-power2)\n",
    "    elif t>=break2 and t<break3:\n",
    "        value=amplitude*power3*t**(power3-1)*break1**(power1-power2)*break2**(power2-power3)\n",
    "    elif t>=break3 and t<break4:\n",
    "        value=amplitude*power4*t**(power4-1)*break1**(power1-power2)*break2**(power2-power3)\\\n",
    "        *break3**(power3-power4)\n",
    "    elif t>=break4:\n",
    "        value=amplitude*power5*t**(power5-1)*break1**(power1-power2)*break2**(power2-power3)\\\n",
    "        *break3**(power3-power4)*break4**(power4-power5)\n",
    "    else:\n",
    "        value=np.NaN\n",
    "    return value\n",
    "\n",
    "def quintuply_broken_PL_derivative(amplitude, break1, break2, break3, break4, break5, \\\n",
    "                                   power1, power2, power3, power4, power5, power6, t0, t):\n",
    "    if t<break1 and t>t0:\n",
    "        value=amplitude*power1*t**(power1-1)\n",
    "    elif t>=break1 and t<break2:\n",
    "        value=amplitude*power2*t**(power2-1)*break1**(power1-power2)\n",
    "    elif t>=break2 and t<break3:\n",
    "        value=amplitude*power3*t**(power3-1)*break1**(power1-power2)*break2**(power2-power3)\n",
    "    elif t>=break3 and t<break4:\n",
    "        value=amplitude*power4*t**(power4-1)*break1**(power1-power2)*break2**(power2-power3)\\\n",
    "        *break3**(power3-power4)\n",
    "    elif t>=break4 and t<break5:\n",
    "        value=amplitude*power5*t**(power5-1)*break1**(power1-power2)*break2**(power2-power3)\\\n",
    "        *break3**(power3-power4)*break4**(power4-power5)\n",
    "    elif t>=break5:\n",
    "        value=amplitude*power6*t**(power6-1)*break1**(power1-power2)*break2**(power2-power3)\\\n",
    "        *break3**(power3-power4)*break4**(power4-power5)*break5**(power5-power6)\n",
    "    else:\n",
    "        value=np.NaN\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "780e9dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yeah, this dictionary will make life 500x easier later\n",
    "Known_Precursors = {}\n",
    "Known_Precursors[\"Long Collapsars\"] = ('GRB050416A   ', 'GRB081007   ', 'GRB091127   ', \\\n",
    "                                       'GRB050525A   ', 'GRB050824   ', 'GRB060218   ', \\\n",
    "                                       'GRB060729   ', 'GRB060904B   ', 'GRB070419A   ', \\\n",
    "                                       'GRB071025   ', 'GRB071112C   ', 'GRB080109   ', \\\n",
    "                                       'GRB080319B   ', 'GRB081007A   ', 'GRB090618   ', \\\n",
    "                                       'GRB091127   ', 'GRB100316D   ', 'GRB100418A   ', \\\n",
    "                                       'GRB101219B   ', 'GRB101225A   ', 'GRB111209A   ', \\\n",
    "                                       'GRB111211A   ', 'GRB111228A   ', 'GRB120422A   ', \\\n",
    "                                       'GRB120714B   ', 'GRB120729A   ', 'GRB130215A   ', \\\n",
    "                                       'GRB130427A   ', 'GRB130702A   ', 'GRB130831A   ', \\\n",
    "                                       'GRB140206A   ', 'GRB140606B   ', 'GRB150818A   '\\\n",
    "                                       'GRB161219B   ', 'GRB161228B   ', 'GRB171010A   ', \\\n",
    "                                       'GRB171205A   ', 'GRB180720B   ', 'GRB180728A   ', \\\n",
    "                                       'GRB190114C   ', 'GRB190829A   ', 'GRB221009A   ', \\\n",
    "                                       'GRB211023A   ', 'GRB200826A   ', 'GRB210210A   ')\n",
    "Known_Precursors[\"Short Collapsars\"] = ('GRB200826A   ')\n",
    "Known_Precursors[\"Short Mergers\"] = ('GRB130603B   ', 'GRB160821B   ', 'GRB200522A   ', \\\n",
    "                                     'GRB150101B   ', 'GRB160624A   ', 'GRB170817A   ', \\\n",
    "                                     'GRB070809   ')\n",
    "Known_Precursors[\"Long Mergers\"] = ('GRB211211A   ', 'GRB230307A   ', 'GRB120304B   ', \\\n",
    "                                    'GRB111005A   ', 'GRB060614   ')\n",
    "Known_Precursors[\"Potentially Exotic\"] = (\"GRB210704A   \")\n",
    "Known_Precursors[\"Galactic Detected\"] = (\"GRB050509B   \", \"GRB050709   \", \"GRB051210    \", \\\n",
    "                                         \"GRB070714B   \", \"GRB071227    \", \"GRB080503    \", \\\n",
    "                                         \"GRB080905A   \", \"GRB090515    \", \"GRB160303A   \")\n",
    "###\n",
    "Fermi_Precursors = {}\n",
    "Fermi_Precursors[\"Long Collapsars\"] = ('GRB050416461', 'GRB050525002', 'GRB050824966', \\\n",
    "                                       'GRB060218148', 'GRB060729800', 'GRB060904104', \\\n",
    "                                       'GRB070419447', 'GRB071025172', 'GRB071112772', \\\n",
    "                                       'GRB080319258', 'GRB081007224', 'GRB090618353', \\\n",
    "                                       'GRB091127976', 'GRB100316531', 'GRB100418882', \\\n",
    "                                       'GRB101219686', 'GRB101225776', 'GRB111209300', \\\n",
    "                                       'GRB111211928', 'GRB111228656', 'GRB120422300', \\\n",
    "                                       'GRB120714888', 'GRB120729455', 'GRB130215063', \\\n",
    "                                       'GRB130427324', 'GRB130702003', 'GRB130831544', \\\n",
    "                                       'GRB140206303', 'GRB140606133', 'GRB150818483', \\\n",
    "                                       'GRB161219783', 'GRB161228552' ,'GRB171010792', \\\n",
    "                                       'GRB171205306', 'GRB180720598', 'GRB180728728', \\\n",
    "                                       'GRB190114872', 'GRB190829830', 'GRB200826187', \\\n",
    "                                       'GRB210210083', 'GRB211023545', 'GRB221009553')\n",
    "Fermi_Precursors[\"Short Collapsars\"] = ('GRB200826187')\n",
    "Fermi_Precursors[\"Short Mergers\"] = ('GRB070809807', 'GRB130603659', 'GRB150101641', \\\n",
    "                                     'GRB160624477', 'GRB160821936', 'GRB170817528', \\\n",
    "                                     'GRB200522487')\n",
    "Fermi_Precursors[\"Long Mergers\"] = ('GRB060614530', 'GRB111005336', 'GRB120304248', \\\n",
    "                                    'GRB211211548', 'GRB230307655')\n",
    "Fermi_Precursors[\"Potentially Exotic\"] = ('GRB210704814')\n",
    "Fermi_Precursors[\"Galactic Detected\"] = ('GRB050509166', 'GRB050709942', 'GRB051210240', \\\n",
    "                                         'GRB070714207', 'GRB071227842', 'GRB080503518', \\\n",
    "                                         'GRB080905499', 'GRB090515198', 'GRB160303454')\n",
    "###\n",
    "Overlap_Precursors = {}\n",
    "Overlap_Precursors[\"Long Collapsars\"] = (050416461.0, 50525002.0, 050824966.0, \\\n",
    "                                       060218148.0, 060729800.0, 060904104.0, \\\n",
    "                                       070419447.0, 071025172.0, 071112772.0, \\\n",
    "                                       080319258.0, 081007224.0, 090618353.0, \\\n",
    "                                       091127976.0, 100316531.0, 100418882.0, \\\n",
    "                                       101219686.0, 101225776.0, 111209300.0, \\\n",
    "                                       111211928.0, 111228656.0, 120422300.0, \\\n",
    "                                       120714888.0, 120729455.0, 130215063.0, \\\n",
    "                                       130427324.0, 130702003.0, 130831544.0, \\\n",
    "                                       140206303.0, 140606133.0, 150818483.0, \\\n",
    "                                       161219783.0, 161228552.0, 171010792.0, \\\n",
    "                                       171205306.0, 180720598.0, 180728728.0, \\\n",
    "                                       190114872.0, 190829830.0, 200826187.0, \\\n",
    "                                       210210083.0, 211023545.0, 221009553.0)\n",
    "Overlap_Precursors[\"Short Collapsars\"] = (200826187.0)\n",
    "Overlap_Precursors[\"Short Mergers\"] = (070809807.0, 130603659.0, 150101641.0, \\\n",
    "                                     160624477.0, 160821936.0, 170817528.0, \\\n",
    "                                     200522487.0)\n",
    "Overlap_Precursors[\"Long Mergers\"] = (060614530.0, 111005336.0, 120304248.0, \\\n",
    "                                    211211548.0, 230307655.0)\n",
    "Overlap_Precursors[\"Potentially Exotic\"] = (210704814.0)\n",
    "Overlap_Precursors[\"Galactic Detected\"] = (050509166.0, 050709942.0, 051210240.0, \\\n",
    "                                         070714207.0, 071227842.0, 080503518.0, \\\n",
    "                                         080905499.0, 090515198.0, 160303454.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd2f9119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1501\n",
      "1525\n",
      "1525\n",
      "1525\n",
      "1564\n"
     ]
    }
   ],
   "source": [
    "##Creating Sample 0##\n",
    "tiny_removals=[]\n",
    "singular_swift_fluences_list=np.zeros((1,8))\n",
    "singular_swift_fluxes_list=np.zeros((1,4))\n",
    "singular_swift_models_list=np.zeros((1,7))\n",
    "tarjete=0\n",
    "stage=0\n",
    "for i in range(0,len(swift_fluences_reference)):\n",
    "    #for each event\n",
    "    placeholder=[[swift_data.at[i, 'GRBname '], swift_fluence_function(i, ' 25_50kev '), \\\n",
    "                swift_fluence_function(i, ' 25_50kev_low '), \\\n",
    "                swift_fluence_function(i, ' 25_50kev_hi '), \\\n",
    "                swift_fluence_function(i, ' 50_100kev '),\\\n",
    "                                          swift_fluence_function(i, ' 50_100kev_low '),\\\n",
    "                                          swift_fluence_function(i, ' 50_100kev_hi '), \n",
    "                                          swift_fluence_function(i, ' 15_350kev ')]]\n",
    "    singular_swift_fluences_list=np.append(singular_swift_fluences_list, \\\n",
    "                placeholder, axis=0)\n",
    "    other_placeholder=[[swift_data.at[i, 'GRBname '], swift_flux_function(i, ' 15_350kev '), \\\n",
    "                swift_fluence_function(i, ' 15_350kev_low '), \\\n",
    "                swift_fluence_function(i, ' 15_350kev_hi ')]]\n",
    "    singular_swift_fluxes_list=np.append(singular_swift_fluxes_list, \\\n",
    "                other_placeholder, axis=0)\n",
    "    third_placeholder=[[swift_data.at[i, 'GRBname '], swift_model_function(i, ' alpha '), \\\n",
    "                swift_model_function(i, ' alpha_low '), \\\n",
    "                        swift_model_function(i, ' alpha_hi '), \\\n",
    "                        swift_model_function(i, ' Epeak '), \\\n",
    "                        swift_model_function(i, ' Epeak_low '), \\\n",
    "                        swift_model_function(i, ' Epeak_hi ')]]\n",
    "    singular_swift_models_list=np.append(singular_swift_models_list, \\\n",
    "                third_placeholder, axis=0)\n",
    "singular_swift_fluences_list=singular_swift_fluences_list[1:]\n",
    "singular_swift_fluxes_list=singular_swift_fluxes_list[1:]\n",
    "singular_swift_models_list=singular_swift_models_list[1:]\n",
    "swift_fluences=pd.DataFrame(singular_swift_fluences_list, columns=['GRBname ', ' 25_50kev ',\\\n",
    "                                                                  ' 25_50kev_low ', \\\n",
    "                                                                   ' 25_50kev_hi ', \\\n",
    "                                                                   ' 50_100kev ', \\\n",
    "                                                                   ' 50_100kev_low ', \\\n",
    "                                                                   ' 50_100kev_hi ', \\\n",
    "                                                                   ' 15_350kev '])\n",
    "swift_fluxes=pd.DataFrame(singular_swift_fluxes_list, columns=['GRBname ', ' 15_350kev ',\\\n",
    "                                                                  ' 15_350kev_low ', \\\n",
    "                                                                   ' 15_350kev_hi '])\n",
    "swift_models=pd.DataFrame(singular_swift_models_list, columns=['GRBname ', ' alpha ', \\\n",
    "                                                               ' alpha_low ', \\\n",
    "                                                               ' alpha_hi ', \\\n",
    "                                                              ' E_peak ', ' E_peak_low ', \\\n",
    "                                                              ' E_peak_hi '])\n",
    "for i in range(0,len(swift_fluences_reference)):\n",
    "    test_flux=swift_fluxes.at[i,' 15_350kev ']\n",
    "    test_direction=swift_data['  RA_ground   '][i]\n",
    "    test_time=swift_data['     T90      '][i]\n",
    "    if test_direction==' N/A ' or test_direction=='N/A':\n",
    "            tiny_removals.append(i)\n",
    "    elif test_time==' N/A ' or test_time=='N/A':\n",
    "            tiny_removals.append(i)\n",
    "    elif test_flux==' N/A ':\n",
    "            tiny_removals.append(i)\n",
    "if (len(swift_fluxes)-1)<(len(swift_data)-1):\n",
    "    for k in range(len(swift_fluxes)-1, len(swift_data)):\n",
    "        tiny_removals.append(k)\n",
    "sample_0_data = swift_data.drop(index=tiny_removals)\n",
    "print(len(sample_0_data))\n",
    "print(len(swift_fluences))\n",
    "print(len(swift_fluxes))\n",
    "print(len(swift_models))\n",
    "print(len(swift_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25794cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608\n",
      "258\n"
     ]
    }
   ],
   "source": [
    "##Creating Samples 1 and 4##\n",
    "removals=[]\n",
    "xrt_matches=np.zeros((1,2))\n",
    "xrt_stages=np.zeros((1,2))\n",
    "xrt_avg_slope=np.zeros((1,2))\n",
    "tarjete=0\n",
    "stage=0\n",
    "for i in range(0,len(swift_fluxes)):\n",
    "    #for each event\n",
    "    query=swift_data[' XRT_detection '][i]\n",
    "    #query the XRT detection then add it to the first empty list\n",
    "    #print(swift_fluxes.at[i,' 15_350kev '])\n",
    "    test_flux=swift_fluxes.at[i,' 15_350kev ']\n",
    "    test_direction=swift_data['  RA_ground   '][i]\n",
    "    test_time=swift_data['     T90      '][i]\n",
    "    #snap=swift_data['GRBname '][i].strip()[3:]\n",
    "    #pdb.set_trace()\n",
    "#     if swift_data['GRBname '][i]=='GRB080503    ':\n",
    "#         pdb.set_trace()\n",
    "    if len(np.where(swift_data['GRBname '][i].strip()[3:]==more_xrt_data['GRB '])[0])>0 \\\n",
    "    or len(np.where(swift_data['GRBname '][i][3:].strip()==weird_xrt_data['GRB '])[0])>0:\n",
    "#         if swift_data['GRBname '][i].strip()[3:]=='211211A':\n",
    "#             pdb.set_trace()\n",
    "        if len(np.where(swift_data['GRBname '][i].strip()[3:]==more_xrt_data['GRB '])[0])>0:\n",
    "            xrt_match=np.where(swift_data['GRBname '][i].strip()[3:]==\\\n",
    "                               more_xrt_data['GRB '])[0][0]\n",
    "        elif len(np.where(swift_data['GRBname '][i].strip()[3:]==\\\n",
    "                          weird_xrt_data['GRB '])[0])>0:\n",
    "            xrt_match=np.where(swift_data['GRBname '][i].strip()[3:]==\n",
    "                               weird_xrt_data['GRB '])[0][0]\n",
    "        #         xrt_trigger=xrt_data['Trigger Number'][xrt_match]\n",
    "#         test_pindex=swift_pindex['GRB'][xrt_match]\n",
    "#         xrt_flux=more_xrt_data[' Obs Flux_2 (pc) '][xrt_match]\n",
    "        #they're off becuase I downloaded them at different times.\n",
    "#         if xrt_flux==' N/A ' or xrt_flux=='N/A' or xrt_flux=='NaN':\n",
    "#             removals.append(i)\n",
    "        temporal_indices=np.zeros(6)\n",
    "        for l in range(0, 6):\n",
    "            flux_name=' alpha_{} '.format(l+1)\n",
    "            if more_xrt_data[flux_name][xrt_match]==' N/A ' \\\n",
    "                or more_xrt_data[flux_name][xrt_match]=='N/A' \\\n",
    "                or more_xrt_data[flux_name][xrt_match]=='NaN':\n",
    "                temporal_indices[l]=-100 #just throw it out of range\n",
    "            else:\n",
    "                temporal_indices[l]=more_xrt_data[flux_name][xrt_match]\n",
    "        if len(np.where((temporal_indices > -0.75) & (temporal_indices < 0.75))[0])>0:\n",
    "            tarjit=np.where((temporal_indices > -0.75) & (temporal_indices < 0.75))[0][0]\n",
    "            flux_catch, xrt_flux, tarjete, state=defining_the_flux(tarjit, temporal_indices)\n",
    "            slope_index=[]\n",
    "            slope_sum=0\n",
    "            for m in range(0, 6):\n",
    "                if m==tarjit-1:\n",
    "                    continue\n",
    "                elif temporal_indices[m]==-100:\n",
    "                    continue\n",
    "                else:\n",
    "                    slope_index=np.append(slope_index, temporal_indices[m])\n",
    "            if len(slope_index)>0:\n",
    "                slope_sum=np.average(slope_index)\n",
    "            else:\n",
    "                slope_sum=0\n",
    "#         elif (np.where(abs(temporal_indices)==min(abs(temporal_indices)))[0][0]>0) and \\\n",
    "#         min(abs(temporal_indices))<100:\n",
    "#             tarjit=np.where(abs(temporal_indices)==min(abs(temporal_indices)))[0][0]\n",
    "#             flux_catch, xrt_flux, tarjete, state=defining_the_flux(tarjit, temporal_indices)\n",
    "        else:\n",
    "            xrt_flux=' N/A '\n",
    "        if xrt_flux==' N/A ' or xrt_flux=='N/A' or xrt_flux=='NaN':\n",
    "            removals.append(i)\n",
    "            #anyway, we don't wnat the ones without flux right now\n",
    "#         elif test_pindex==' N/A ' or test_pindex=='N/A' or test_pindex=='NaN':\n",
    "#             removals.append(i)\n",
    "#         elif query!='Yes' and query!=' Yes ':\n",
    "#             #and add it to the second one if it didn't detect or it's not sure\n",
    "#             removals.append(i)\n",
    "        if test_flux==' N/A ':\n",
    "            removals.append(i)\n",
    "        elif test_direction==' N/A ' or test_direction=='N/A':\n",
    "            removals.append(i)\n",
    "        elif test_time==' N/A ' or test_time=='N/A' or test_time=='     N/A      ':\n",
    "            removals.append(i)\n",
    "#         elif xrt_trigger=='BAT/GUANO':\n",
    "            #These ones probably won't show up in the the data, but I don't want them\n",
    "            #because they aren't relevant to what I'm doing, being that they /probably/ \n",
    "            #aren't triggered by Fermi and the data ends up missing everything relevant\n",
    "#             removals.append(i)\n",
    "        else:\n",
    "            xrt_matches=np.append(xrt_matches,[[int(i),int(xrt_match)]], axis=0)\n",
    "            xrt_stages=np.append(xrt_stages,[[int(state),int(tarjete)]], axis=0)\n",
    "#             xrt_avg_slope=np.append(xrt_avg_slope,[[int(i),int(slope_sum)]], axis=0)\n",
    "            continue\n",
    "    else:\n",
    "        removals.append(i)\n",
    "if (len(swift_fluxes)-1)<(len(swift_data)-1):\n",
    "    for k in range(len(swift_fluxes)-1, len(swift_data)):\n",
    "        removals.append(k)\n",
    "edited_swift_data = swift_data.drop(index=removals)\n",
    "xrt_matches=xrt_matches[1:]\n",
    "xrt_stages=xrt_stages[1:]\n",
    "# xrt_avg_slope=xrt_avg_slope[1:]\n",
    "test_flux=[]\n",
    "for j in edited_swift_data.index:\n",
    "    test_flux.append(swift_fluxes.at[j,' 15_350kev '])\n",
    "red_swift_removals=[]\n",
    "r=0\n",
    "redshift_matches=np.zeros((1,2))\n",
    "redshift_xrt=np.zeros((1,2))\n",
    "redshift_stages=np.zeros((1,2))\n",
    "# redshift_avg_slope=np.zeros((1,2))\n",
    "for j in edited_swift_data.index:\n",
    "    for i in range(0, len(swift_redshifts)):\n",
    "        swift_string=edited_swift_data['GRBname '][j].strip()\n",
    "        redshift_string=swift_redshifts['GRBname '][i].strip()\n",
    "        redsweefer = swift_redshifts.at[i, ' z '] #I call a swiffer a sweefer and \n",
    "        #this error was going to be a serious issue unlike the stupid question marks\n",
    "        if swift_string==redshift_string:\n",
    "            redshift_matches=np.append(redshift_matches,[[int(i),int(j)]], axis=0)\n",
    "            row_match=int(np.where(xrt_matches[:, 0]==j)[0][0])\n",
    "            redshift_xrt=np.append(redshift_xrt,[[int(j),xrt_matches[row_match,1]]], \\\n",
    "                                       axis=0)\n",
    "            redshift_stages=np.append(redshift_stages,[[int(xrt_stages[row_match,0]),\n",
    "                                                        int(xrt_stages[row_match,1])]], \\\n",
    "                                      axis=0)\n",
    "#             redshift_avg_slope=np.append(redshift_avg_slope,[[int(i),\\\n",
    "#                                                     int(xrt_avg_slope[row_match, 1])]],\\\n",
    "#                                          axis=0)\n",
    "            if 'or' in str(redsweefer):\n",
    "#                 print(redsweefer)\n",
    "#                 print(redshift_string)\n",
    "                red_swift_removals.append(j)\n",
    "                redshift_xrt=redshift_xrt[:len(redshift_xrt)-1,:]\n",
    "                redshift_stages=redshift_stages[:len(redshift_stages)-1,:]\n",
    "#                 redshift_avg_slope=redshift_avg_slope[:len(redshift_stages)-1,:]\n",
    "            if '-' in str(redsweefer):\n",
    "                #whatever jerk did this one is okay in my book, not like ALL THE OTHER AWFUL\n",
    "                #NONNUMERIC CHARACTERS AHHHHHHHHH, jerks, all the rest of you\n",
    "                redswiffer=re.split(\"-\", redsweefer.strip())\n",
    "                red_broom = list(map(float, redswiffer))\n",
    "                swift_redshifts.at[i, ' z ']=np.mean([red_broom[0], red_broom[1]])\n",
    "            break\n",
    "        elif swift_string != redshift_string and i==len(swift_redshifts)-1:\n",
    "            r=r+1\n",
    "            red_swift_removals.append(j)\n",
    "        else: \n",
    "            continue\n",
    "other_redshift_matches=np.zeros((1,2))\n",
    "for j in edited_swift_data.index:\n",
    "    for i in range(0, len(second_redshifts)):\n",
    "        swift_string_2=edited_swift_data['GRBname '][j].strip()\n",
    "        redshift_string_2=second_redshifts['GRB'][i].strip()\n",
    "        redmop = second_redshifts.at[i, 'zc']\n",
    "        if swift_string_2==redshift_string_2:\n",
    "            other_redshift_matches=np.append(other_redshift_matches,[[int(i),int(j)]], axis=0)\n",
    "            if type(red_swift_removals)!=int:\n",
    "                if len(np.where(red_swift_removals==j)[0])>0:\n",
    "                    add_in=np.where(red_swift_removals==j)[0][0]\n",
    "                    red_swift_removals=np.delete(red_swift_removals,add_in)\n",
    "            elif type(red_swift_removals)==int and red_swift_removals==j:\n",
    "                red_swift_removals=[]\n",
    "            #I /think/ this will add the removed ones back in. Probably.\n",
    "            row_match=int(np.where(xrt_matches[:, 0]==j)[0][0])\n",
    "            redshift_xrt=np.append(redshift_xrt,[[int(j),xrt_matches[row_match,1]]],\\\n",
    "                                   axis=0)\n",
    "            redshift_stages=np.append(redshift_stages,[[int(xrt_stages[row_match,0]),\\\n",
    "                                                        int(xrt_stages[row_match,1])]],\\\n",
    "                                      axis=0)\n",
    "            break\n",
    "#         elif swift_string_2 != redshift_string_2 and i==len(second_redshifts)-1:\n",
    "#             red_swift_removals=np.append(red_swift_removals, j)\n",
    "#             break\n",
    "        else: \n",
    "            continue\n",
    "# weird_removals=list(set(red_swift_removals))\n",
    "redshift_matches=redshift_matches[1:]\n",
    "redshift_xrt=redshift_xrt[1:]\n",
    "redshift_stages=redshift_stages[1:]\n",
    "# redshift_avg_slope=redshift_avg_slope[1:]\n",
    "redshift_swift_data = edited_swift_data.drop(index=red_swift_removals)\n",
    "# print(len(edited_swift_data))\n",
    "# print(len(redshift_swift_data))\n",
    "edited_swift_data = swift_data.drop(index=removals)\n",
    "sample_1_data=edited_swift_data\n",
    "#For some reason I won't pretend to understand, creating sample 4 HERE prevents errors in \n",
    "#creating sample 3. Oy vey.\n",
    "sample_4_data=redshift_swift_data\n",
    "print(len(sample_1_data))\n",
    "print(len(sample_4_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9de855a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3527\n"
     ]
    }
   ],
   "source": [
    "##Creating Sample 2##\n",
    "sample_2_data=fermi_data\n",
    "print(len(sample_2_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e15428f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n",
      "['GRB111201599' 'GRB110319815']\n"
     ]
    }
   ],
   "source": [
    "##Creating Sample 3##\n",
    "##Data conversion##\n",
    "edited_indices=list(np.where(edited_swift_data.index!=0))\n",
    "t=Time(edited_swift_data.at[int(edited_swift_data.index[0]),\\\n",
    "                            '       Trig_time_UTC        '].strip(), \\\n",
    "       format='isot', scale='utc')\n",
    "gorp=t.jd; #honestly at this point I gave up on naming variables\n",
    "shoes=float(edited_swift_data.at[int(edited_swift_data.index[0]),'  RA_ground   '])\n",
    "sorks=float(edited_swift_data.at[int(edited_swift_data.index[0]),'     T90      '])\n",
    "gatorade=float(edited_swift_data.at[int(edited_swift_data.index[0]), ' Image_position_err '])\n",
    "helmet=float(edited_swift_data.at[int(edited_swift_data.index[0]),'  DEC_ground   '])\n",
    "nom=str(edited_swift_data.at[int(edited_swift_data.index[0]),'GRBname '].strip())\n",
    "for i in list(edited_swift_data.index):\n",
    "    if type(edited_swift_data.at[i,'       Trig_time_UTC        '])==str:\n",
    "        t=Time(edited_swift_data.at[i,'       Trig_time_UTC        '].strip(), \\\n",
    "               format='isot', scale='utc')\n",
    "        gorp=np.append(gorp, t.jd)\n",
    "        shoes=np.append(shoes, float(edited_swift_data.at[i,'  RA_ground   ']))\n",
    "        sorks=np.append(sorks, float(edited_swift_data.at[i,'     T90      ']))\n",
    "        gatorade=np.append(gatorade, float(edited_swift_data.at[i,' Image_position_err ']))\n",
    "        helmet=np.append(helmet, float(edited_swift_data.at[i,'  DEC_ground   ']))\n",
    "        nom=np.append(nom, str(edited_swift_data.at[i,'GRBname '].strip()))\n",
    "    else :\n",
    "        gorp=np.append(gorp, 1)\n",
    "        sorks=np.append(sorks, float(edited_swift_data.at[i,'     T90      ']))\n",
    "        shoes=np.append(shoes, float(edited_swift_data.at[i,'  RA_ground   ']))\n",
    "        gatorade=np.append(gatorade, float(edited_swift_data.at[i,' Image_position_err ']))\n",
    "        helmet=np.append(helmet, float(edited_swift_data.at[i,'  DEC_ground   ']))\n",
    "        nom=np.append(nom, str(edited_swift_data.at[i,'GRBname '].strip()))\n",
    "t0=fermi_data.at[0,\"trigger_time           \"]\n",
    "t0=re.split(\"/| |:\", t0)\n",
    "t0 = list(map(int, t0))\n",
    "t0=datetime.datetime(t0[2], t0[0], t0[1], t0[3], t0[4], t0[5], int(t0[6]))\n",
    "trail_mix = julian.to_jd(t0, fmt='jd') #honestly at this point I gave up on naming variables\n",
    "soles=fermi_data.at[0,'ra        ']\n",
    "soles=soles.split(' ')\n",
    "soles=list(map(float, soles)) \n",
    "boots=((soles[0]+(soles[1]+soles[2]/60)/60)*15)\n",
    "fabric=fermi_data.at[0,'dec      ']\n",
    "fabric=fabric.split(' ')\n",
    "fabric=list(map(float, fabric)) \n",
    "hat=(fabric[0]+(fabric[1]+fabric[2]/60)/60)\n",
    "socks=fermi_data.at[0,'t90_error']\n",
    "w0ter=fermi_data.at[0, 'error_radius']\n",
    "for i in range(1,len(fermi_data)):\n",
    "    ti83=fermi_data.at[i,\"trigger_time           \"]\n",
    "    ti83=re.split(\"/| |:\", ti83)\n",
    "    ti83 = list(map(int, ti83)) \n",
    "    ti83=datetime.datetime(ti83[2], ti83[0], ti83[1], ti83[3], ti83[4], ti83[5], \\\n",
    "                           int(ti83[6]))\n",
    "    trail_mix = np.append(trail_mix, julian.to_jd(ti83, fmt='jd'))\n",
    "    soles=fermi_data.at[i,'ra        ']\n",
    "    soles=soles.split(' ')\n",
    "    soles=list(map(float, soles)) \n",
    "    soles=((soles[0]+(soles[1]+soles[2]/60)/60)*15)\n",
    "    boots=np.append(boots, soles)\n",
    "    fabric=fermi_data.at[i,'dec      ']\n",
    "    fabric=fabric.split(' ')\n",
    "    fabric=list(map(float, fabric)) \n",
    "    fabric=(fabric[0]+(fabric[1]+fabric[2]/60)/60)\n",
    "    hat=np.append(hat, fabric)\n",
    "    socks=np.append(socks, fermi_data.at[i,'t90_error'])\n",
    "    w0ter=np.append(w0ter, fermi_data.at[i,'error_radius'])\n",
    "##match data##\n",
    "food = np.zeros((len(trail_mix),len(gorp)))\n",
    "feet_covers = np.zeros((len(trail_mix),len(gorp)))\n",
    "UV_protection = np.zeros((len(trail_mix),len(gorp)))\n",
    "k=0;\n",
    "for i in range(0, len(gorp)):\n",
    "    for j in range(0, len(trail_mix)):\n",
    "        food[j, i] = abs(trail_mix[j]-gorp[i]);\n",
    "        feet_covers[j, i] = abs(boots[j]-shoes[i]);\n",
    "        UV_protection[j, i] = abs(hat[j]-helmet[i]);\n",
    "        if food[j,i]<0.0035:\n",
    "            if w0ter[j]<0.1:\n",
    "                if feet_covers[j,i]<3*gatorade[i]:\n",
    "                    if UV_protection[j,i]<3*gatorade[i]:\n",
    "                        k=k+1;\n",
    "            else:\n",
    "                if feet_covers[j,i]<3*w0ter[j]:\n",
    "                    if UV_protection[j,i]<3*w0ter[j]:\n",
    "                        k=k+1;\n",
    "matches = np.zeros((k+1, 15))\n",
    "potential_matches=np.zeros((k,3))\n",
    "print(k)\n",
    "k=0;\n",
    "err=0;\n",
    "special_cases=[]\n",
    "for i in range(0, len(gorp)):\n",
    "    for j in range(0, len(trail_mix)):\n",
    "        if food[j,i]<0.0035: #time\n",
    "            if w0ter[j]<0.1:\n",
    "                if feet_covers[j,i]<3*gatorade[i]: #RA\n",
    "                    if UV_protection[j,i]<3*gatorade[i]: #dec\n",
    "                        potential_matches[k,0]=food[j,i]\n",
    "                        potential_matches[k,1]=w0ter[j]\n",
    "                        potential_matches[k,2]=gatorade[i]\n",
    "                        name=fermi_data.at[j,\"name        \"]\n",
    "                        matches[k,0] = int(name[3]+name[4]+name[5]+name[6]+\\\n",
    "                                           name[7]+name[8]+name[9]+name[10]+name[11])\n",
    "                        matches[k,1] = j\n",
    "                        matches[k,2] = edited_swift_data.index[i]\n",
    "                        if w0ter[j] != 0 and gatorade[i] != 0:\n",
    "                            matches[k,3] = 1-NormalDist(mu=boots[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=shoes[i], sigma=gatorade[i]))*\\\n",
    "                                        NormalDist(mu=hat[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=helmet[i], sigma=gatorade[i])) #alpha\n",
    "                            matches[k,4] = NormalDist(mu=boots[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=shoes[i], sigma=gatorade[i]))*\\\n",
    "                                        NormalDist(mu=hat[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=helmet[i], sigma=gatorade[i])) #beta\n",
    "                        else:\n",
    "                            matches[k,3]='NaN'\n",
    "                            matches[k,4]='NaN'\n",
    "                            err=err+1;\n",
    "                        matches[k,5] = fermi_data.at[j,\"t90     \"]\n",
    "                        matches[k,6] = fermi_data.at[j,\"t90_error\"]\n",
    "                        matches[k,7] = fermi_data.at[j,'flux_256 ']\n",
    "                        matches[k,8] = fermi_data.at[j,'fluence   ']\n",
    "                        matches[k,9] = fermi_data.at[j,'fluence_error']\n",
    "                        if swift_fluxes.at[edited_swift_data.index[i],\\\n",
    "                                                           ' 15_350kev '] != ' N/A ':\n",
    "                            matches[k,10] = swift_fluxes.at[edited_swift_data.index[i],\\\n",
    "                                                               ' 15_350kev ']\n",
    "                        else:\n",
    "                            matches[k,10] = 0\n",
    "                        if swift_fluences.at[edited_swift_data.index[i],\\\n",
    "                                                             ' 15_350kev '] != ' N/A ':\n",
    "                            matches[k,11] =  swift_fluences.at[edited_swift_data.index[i],\\\n",
    "                                                             ' 15_350kev ']\n",
    "                        else:\n",
    "                            matches[k,11] = 0\n",
    "                        if fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_plaw              ':\n",
    "                            matches[k,12] = 1\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_band              ':\n",
    "                            matches[k,12] = 2\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_comp              ':\n",
    "                            matches[k,12] = 3\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_sbpl              ':\n",
    "                            matches[k,12] = 4\n",
    "                        else:\n",
    "                            matches[k,12] = 0\n",
    "                        #pdb.set_trace()\n",
    "                        xrt_xcall=np.where(xrt_matches[:,0]==\\\n",
    "                                                 edited_swift_data.index[i-1])[0][0]\n",
    "                        matches[k,13]=int(xrt_matches[xrt_xcall, 1])\n",
    "                        matches[k,14] = int(xrt_stages[i-1,1])\n",
    "#     #                     matches[k, 11]=xrt_data.at[xrt_call,\\\n",
    "#     #                                         'XRT Early Flux (0.3-10 keV) [10^-11 erg/cm^2/s]']\n",
    "#     #                     print(i-1)\n",
    "#     #                     print(xrt_call)\n",
    "#                         if int(xrt_stages[i-1,0])==0:\n",
    "#                             flux_recall=' Obs Flux_{} (pc) '.\\\n",
    "#                                 format(int(xrt_stages[i-1,1]))\n",
    "#                             flux_change=' D_Obs Flux_{} (pc) '.\\\n",
    "#                                     format(int(xrt_stages[i-1,1]))\n",
    "#                         elif int(xrt_stages[i-1,0])==1:\n",
    "#                             flux_recall=' Obs Flux_{} (wt) '.\\\n",
    "#                                 format(int(xrt_stages[i-1,1]))\n",
    "#                             flux_change=' D_Obs Flux_{} (wt) '.\\\n",
    "#                                     format(int(xrt_stages[i-1,1]))\n",
    "#                         else:\n",
    "#                             print(\"error, this burst ({}) didn't get an assigned flux.\").\\\n",
    "#                             format(fermi_data.at[j,\"name        \"])\n",
    "#     #                     print(fermi_data.at[j,\"name        \"])\n",
    "#     #                     print(flux_recall)\n",
    "#     #                     print(more_xrt_data[flux_recall][xrt_call])\n",
    "#                         matches[k, 13]=more_xrt_data[flux_recall][xrt_call]\n",
    "#                         if more_xrt_data[flux_change][xrt_call]==' , ':\n",
    "#                             matches[k,14]=0.34*float(more_xrt_data[flux_recall][xrt_call])\n",
    "#                             matches[k,15]=0.34*float(more_xrt_data[flux_recall][xrt_call])\n",
    "#                             #this is about one standard deviation\n",
    "#                         elif ',' in str(more_xrt_data[flux_change][xrt_call]):\n",
    "#                             dual_input=re.split(\",\", str(more_xrt_data[flux_change][xrt_call])\\\n",
    "#                                                 .strip())\n",
    "#                             headphones = list(map(float, dual_input))\n",
    "#                             matches[k,14]=headphones[0]\n",
    "#                             matches[k,15]=headphones[1]\n",
    "#                             #I originally only left room for one value. That was a mistake.\n",
    "#                         else:\n",
    "#                             matches[k, 14]=more_xrt_data[flux_change][xrt_call]\n",
    "#                             matches[k, 15]=more_xrt_data[flux_change][xrt_call]\n",
    "#                         matches[k,16]=xrt_avg_slope[xrt_xcall, 1]\n",
    "                        k=k+1\n",
    "            else:\n",
    "                if feet_covers[j,i]<3*w0ter[j]: #RA\n",
    "                    if UV_protection[j,i]<3*w0ter[j]: #dec\n",
    "                        special_cases=np.append(special_cases,fermi_data.at[j,\"name        \"])\n",
    "            \n",
    "                        potential_matches[k,0]=food[j,i]\n",
    "                        potential_matches[k,1]=w0ter[j]\n",
    "                        potential_matches[k,2]=gatorade[i]\n",
    "                        name=fermi_data.at[j,\"name        \"]\n",
    "                        matches[k,0] = int(name[3]+name[4]+name[5]+name[6]+\\\n",
    "                                           name[7]+name[8]+name[9]+name[10]+name[11])\n",
    "                        matches[k,1] = j\n",
    "                        matches[k,2] = edited_swift_data.index[i]\n",
    "                        if w0ter[j] != 0 and gatorade[i] != 0:\n",
    "                            matches[k,3] = 1-NormalDist(mu=boots[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=shoes[i], sigma=gatorade[i]))*\\\n",
    "                                        NormalDist(mu=hat[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=helmet[i], sigma=gatorade[i])) #alpha\n",
    "                            matches[k,4] = NormalDist(mu=boots[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=shoes[i], sigma=gatorade[i]))*\\\n",
    "                                        NormalDist(mu=hat[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=helmet[i], sigma=gatorade[i])) #beta\n",
    "                        else:\n",
    "                            matches[k,3]='NaN'\n",
    "                            matches[k,4]='NaN'\n",
    "                            err=err+1;\n",
    "                        matches[k,5] = fermi_data.at[j,\"t90     \"]\n",
    "                        matches[k,6] = fermi_data.at[j,\"t90_error\"]\n",
    "                        matches[k,7] = fermi_data.at[j,'flux_256 ']\n",
    "                        matches[k,8] = fermi_data.at[j,'fluence   ']\n",
    "                        matches[k,9] = fermi_data.at[j,'fluence_error']\n",
    "                        if swift_fluxes.at[edited_swift_data.index[i],\\\n",
    "                                                           ' 15_350kev '] != ' N/A ':\n",
    "                            matches[k,10] = swift_fluxes.at[edited_swift_data.index[i],\\\n",
    "                                                               ' 15_350kev ']\n",
    "                        else:\n",
    "                            matches[k,10] = 0\n",
    "                        if swift_fluences.at[edited_swift_data.index[i],\\\n",
    "                                                             ' 15_350kev '] != ' N/A ':\n",
    "                            matches[k,11] = swift_fluences.at[edited_swift_data.index[i],\\\n",
    "                                                             ' 15_350kev ']\n",
    "                        else:\n",
    "                            matches[k,11] = 0\n",
    "                        if fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_plaw              ':\n",
    "                            matches[k,12] = 1\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_band              ':\n",
    "                            matches[k,12] = 2\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_comp              ':\n",
    "                            matches[k,12] = 3\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_sbpl              ':\n",
    "                            matches[k,12] = 4\n",
    "                        else:\n",
    "                            matches[k,12] = 0\n",
    "                        xrt_xcall=np.where(xrt_matches[:,0]==\\\n",
    "                                                 edited_swift_data.index[i-1])[0][0]\n",
    "                        matches[k,13]=int(xrt_matches[xrt_xcall, 1])\n",
    "                        matches[k,14] = int(xrt_stages[i-1,1])\n",
    "#                         if int(xrt_stages[i-1,0])==0:\n",
    "#                             flux_recall=' Obs Flux_{} (pc) '.\\\n",
    "#                                 format(int(xrt_stages[i-1,1]))\n",
    "#                             flux_change=' D_Obs Flux_{} (pc) '.\\\n",
    "#                                     format(int(xrt_stages[i-1,1]))\n",
    "#                         elif int(xrt_stages[i-1,0])==1:\n",
    "#                             flux_recall=' Obs Flux_{} (wt) '.\\\n",
    "#                                 format(int(xrt_stages[i-1,1]))\n",
    "#                             flux_change=' D_Obs Flux_{} (wt) '.\\\n",
    "#                                     format(int(xrt_stages[i-1,1]))\n",
    "#                         else:\n",
    "#                             print(\"error, this burst ({}) didn't get an assigned flux.\").\\\n",
    "#                             format(fermi_data.at[j,\"name        \"])\n",
    "#                         matches[k, 13]=more_xrt_data[flux_recall][xrt_call]\n",
    "#                         if more_xrt_data[flux_change][xrt_call]==' , ':\n",
    "#                             matches[k,14]=0.34*float(more_xrt_data[flux_recall][xrt_call])\n",
    "#                             matches[k,15]=0.34*float(more_xrt_data[flux_recall][xrt_call])\n",
    "#                             #this is about one standard deviation\n",
    "#                         elif ',' in str(more_xrt_data[flux_change][xrt_call]):\n",
    "#                             dual_input=re.split(\",\", str(more_xrt_data[flux_change][xrt_call])\\\n",
    "#                                                 .strip())\n",
    "#                             headphones = list(map(float, dual_input))\n",
    "#                             matches[k,14]=headphones[0]\n",
    "#                             matches[k,15]=headphones[1]\n",
    "#                             #I originally only left room for one value. That was a mistake.\n",
    "#                         else:\n",
    "#                             matches[k, 14]=more_xrt_data[flux_change][xrt_call]\n",
    "#                             matches[k, 15]=more_xrt_data[flux_change][xrt_call]\n",
    "#                         matches[k,16]=xrt_avg_slope[xrt_xcall, 1]\n",
    "                        k=k+1\n",
    "regular_matches=pd.DataFrame(matches, columns=['name', 'Fermi row', 'Swift row',\\\n",
    "                                               'Type I error', \\\n",
    "                                       'Type II error', 't90', 't90_error', 'GBM flux', \\\n",
    "                                       'GBM fluence', 'Fluence error',\\\n",
    "                                               'BAT flux', 'BAT fluence',\\\n",
    "                                               'Spectral Model', 'XRT row', \\\n",
    "                                               'Plateau Stage'])#,\\\n",
    "#                                                '\"Plateau\" X-Ray Flux', \\\n",
    "#                                                \"Pre-X-ray Flux Change\", \\\n",
    "#                                                \"Post-X-ray Flux Change\"])\n",
    "regular_matches=regular_matches[:-1]\n",
    "sample_3_data=regular_matches\n",
    "print(special_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5278b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Creating Sample 5##\n",
    "# fermi_redshift_matches=np.zeros((1,2))\n",
    "# for j in sample_2_data.index:\n",
    "#     for i in range(0, len(second_redshifts)):\n",
    "#         fermi_string_2=sample_2_data[\"name        \"][j].strip()\n",
    "#         redshift_string_2=second_redshifts['GRB'][i].strip()\n",
    "#         redmop = second_redshifts.at[i, 'zc']\n",
    "#         if swift_string_2==redshift_string_2:\n",
    "#             other_redshift_matches=np.append(other_redshift_matches,[[int(i),int(j)]], axis=0)\n",
    "#             if type(red_swift_removals)!=int:\n",
    "#                 if len(np.where(red_swift_removals==j)[0])>0:\n",
    "#                     add_in=np.where(red_swift_removals==j)[0][0]\n",
    "#                     red_swift_removals=np.delete(red_swift_removals,add_in)\n",
    "#             elif type(red_swift_removals)==int and red_swift_removals==j:\n",
    "#                 red_swift_removals=[]\n",
    "#             #I /think/ this will add the removed ones back in. Probably.\n",
    "#             row_match=int(np.where(xrt_matches[:, 0]==j)[0][0])\n",
    "#             redshift_xrt=np.append(redshift_xrt,[[int(j),xrt_matches[row_match,1]]],\\\n",
    "#                                    axis=0)\n",
    "# #             redshift_stages=np.append(redshift_stages,[[int(xrt_stages[row_match,0]),\\\n",
    "# #                                                         int(xrt_stages[row_match,1])]],\\\n",
    "# #                                       axis=0)\n",
    "#             break\n",
    "# #         elif swift_string_2 != redshift_string_2 and i==len(second_redshifts)-1:\n",
    "# #             red_swift_removals=np.append(red_swift_removals, j)\n",
    "# #             break\n",
    "#         else: \n",
    "#             continue\n",
    "# # weird_removals=list(set(red_swift_removals))\n",
    "# redshift_matches=redshift_matches[1:]\n",
    "# redshift_xrt=redshift_xrt[1:]\n",
    "# # redshift_stages=redshift_stages[1:]\n",
    "# # redshift_avg_slope=redshift_avg_slope[1:]\n",
    "# redshift_swift_data = edited_swift_data.drop(index=red_swift_removals)\n",
    "# # print(len(edited_swift_data))\n",
    "# # print(len(redshift_swift_data))\n",
    "# edited_swift_data = swift_data.drop(index=removals)\n",
    "# sample_1_data=edited_swift_data\n",
    "# #For some reason I won't pretend to understand, creating sample 4 HERE prevents errors in \n",
    "# #creating sample 3. Oy vey.\n",
    "# sample_4_data=redshift_swift_data\n",
    "# print(len(sample_1_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2ed9876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "##Creating Sample 6##\n",
    "##Data conversion fo the redshift data##\n",
    "start_index=redshift_swift_data.index[0]\n",
    "t2=Time(redshift_swift_data.at[start_index,'       Trig_time_UTC        '].strip(), \\\n",
    "               format='isot', scale='utc')\n",
    "gorp2=t2.jd; #honestly at this point I gave up on naming variables\n",
    "shoes2=float(redshift_swift_data.at[start_index,'  RA_ground   '])\n",
    "sorks2=float(redshift_swift_data.at[start_index,'     T90      '])\n",
    "gatorade2=float(redshift_swift_data.at[start_index, ' Image_position_err '])\n",
    "helmet2=float(redshift_swift_data.at[start_index,'  DEC_ground   '])\n",
    "nom2=str(redshift_swift_data.at[start_index,'GRBname '].strip())\n",
    "for i in list(redshift_swift_data.index):\n",
    "    if i !=redshift_swift_data.index[0]:\n",
    "        if type(redshift_swift_data.at[i,'       Trig_time_UTC        '])==str:\n",
    "            t2=Time(redshift_swift_data.at[i,'       Trig_time_UTC        '].strip(), \\\n",
    "               format='isot', scale='utc')\n",
    "            gorp2=np.append(gorp2, t2.jd)\n",
    "            shoes2=np.append(shoes2, float(redshift_swift_data.at[i,'  RA_ground   ']))\n",
    "            sorks2=np.append(sorks2, float(redshift_swift_data.at[i,'     T90      ']))\n",
    "            gatorade2=np.append(gatorade2, \\\n",
    "                            float(redshift_swift_data.at[i,' Image_position_err ']))\n",
    "            helmet2=np.append(helmet2, float(redshift_swift_data.at[i,'  DEC_ground   ']))\n",
    "            nom2=np.append(nom2, str(redshift_swift_data.at[i,'GRBname '].strip()))\n",
    "        else:\n",
    "            gorp2=np.append(gorp2, 1)\n",
    "            sorks2=np.append(sorks2, float(redshift_swift_data.at[i,'     T90      ']))\n",
    "            shoes2=np.append(shoes2, float(redshift_swift_data.at[i,'  RA_ground   ']))\n",
    "            gatorade2=np.append(gatorade2, \\\n",
    "                            float(redshift_swift_data.at[i,' Image_position_err ']))\n",
    "            helmet2=np.append(helmet2, float(redshift_swift_data.at[i,'  DEC_ground   ']))\n",
    "            nom2=np.append(nom2, str(redshift_swift_data.at[i,'GRBname '].strip()))\n",
    "        #Honestly, all the Fermi stuff already existed, so I deleted it\n",
    "    else:\n",
    "        continue\n",
    "##Match the Redshift Data too ##\n",
    "food_2 = np.zeros((len(trail_mix),len(gorp2)))\n",
    "feet_covers_2 = np.zeros((len(trail_mix),len(gorp2)))\n",
    "UV_protection_2 = np.zeros((len(trail_mix),len(gorp2)))\n",
    "l=0;\n",
    "for i in range(0, len(gorp2)):\n",
    "    for j in range(0, len(trail_mix)):\n",
    "        food_2[j, i] = abs(trail_mix[j]-gorp2[i]);\n",
    "        feet_covers_2[j, i] = abs(boots[j]-shoes2[i]);\n",
    "        UV_protection_2[j, i] = abs(hat[j]-helmet2[i]);\n",
    "        if food_2[j,i]<0.0035:\n",
    "            if w0ter[j]<0.1:\n",
    "                if feet_covers_2[j,i]<3*gatorade2[i]:\n",
    "                    if UV_protection_2[j,i]<3*gatorade2[i]:\n",
    "                        l=l+1;\n",
    "            else:\n",
    "                if feet_covers[j,i]<3*w0ter[j]:\n",
    "                    if UV_protection[j,i]<3*w0ter[j]:\n",
    "                        l=l+1;\n",
    "z_matches = np.zeros((l+1, 16))\n",
    "z_potential_matches=np.zeros((l+1,3))\n",
    "print(l)\n",
    "l=0;\n",
    "err=0;\n",
    "special_cases=[]\n",
    "for i in range(0, len(gorp2)-1):\n",
    "    for j in range(0, len(trail_mix)-1):\n",
    "        if food_2[j,i]<0.0035: #time\n",
    "            if w0ter[j]<0.1:\n",
    "                if feet_covers_2[j,i]<3*gatorade2[i]: #RA\n",
    "                    if UV_protection_2[j,i]<3*gatorade2[i]: #dec\n",
    "                        z_potential_matches[l,0]=food_2[j,i]\n",
    "                        z_potential_matches[l,1]=w0ter[j]\n",
    "                        z_potential_matches[l,2]=gatorade2[i]\n",
    "                        name=fermi_data.at[j,\"name        \"]\n",
    "                        z_matches[l,0] = int(name[3]+name[4]+name[5]+name[6]+\\\n",
    "                                           name[7]+name[8]+name[9]+name[10]+name[11])\n",
    "                        z_matches[l,1] = j\n",
    "                        z_matches[l,2] = redshift_swift_data.index[i]\n",
    "                        if w0ter[j] != 0 and gatorade2[i] != 0:\n",
    "                            z_matches[l,3] = 1-NormalDist(mu=boots[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=shoes2[i], sigma=gatorade2[i]))*\\\n",
    "                                        NormalDist(mu=hat[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=helmet2[i], sigma=gatorade2[i])) #alpha\n",
    "                            z_matches[l,4] = NormalDist(mu=boots[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=shoes2[i], sigma=gatorade2[i]))*\\\n",
    "                                        NormalDist(mu=hat[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=helmet2[i], sigma=gatorade2[i])) #beta\n",
    "                        else:\n",
    "                            z_matches[l,3]='NaN'\n",
    "                            z_matches[l,4]='NaN'\n",
    "                            err=err+1;\n",
    "                        z_matches[l,5] = fermi_data.at[j,\"t90     \"]\n",
    "                        z_matches[l,6] = fermi_data.at[j,\"t90_error\"]\n",
    "                        z_matches[l,7] = fermi_data.at[j,'flux_256 ']\n",
    "                        z_matches[l,8] = fermi_data.at[j,'fluence   ']\n",
    "                        z_matches[l,9] = fermi_data.at[j,'fluence_error']\n",
    "                        if swift_fluxes.at[redshift_swift_data.index[i],\\\n",
    "                                                           ' 15_350kev '] != ' N/A ':\n",
    "                            z_matches[l,10] = swift_fluxes.at[redshift_swift_data.index[i],\\\n",
    "                                                           ' 15_350kev ']\n",
    "                        else:\n",
    "                            z_matches[l,10] = 0\n",
    "                        if swift_fluences.at[redshift_swift_data.index[i],\\\n",
    "                                                             ' 15_350kev '] != ' N/A ':\n",
    "                            z_matches[l,11] = swift_fluences.at[redshift_swift_data.index[i],\\\n",
    "                                                             ' 15_350kev ']\n",
    "                        else:\n",
    "                            z_matches[l, 11] = 0\n",
    "                        if fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_plaw              ':\n",
    "                            z_matches[l,12] = 1\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_band              ':\n",
    "                            z_matches[l,12] = 2\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_comp              ':\n",
    "                            z_matches[l,12] = 3\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_sbpl              ':\n",
    "                            z_matches[l,12] = 4\n",
    "                        else:\n",
    "                            z_matches[l,12] = 0\n",
    "                        z_matches[l,13] = int(redshift_xrt[i, 1])\n",
    "                        z_matches[l,14] = int(redshift_stages[i,1])\n",
    "#                         if int(redshift_stages[i,0])==0:\n",
    "#                             flux_recall=' Obs Flux_{} (pc) '.\\\n",
    "#                                 format(int(redshift_stages[i,1]))\n",
    "#                             flux_change=' D_Obs Flux_{} (pc) '.\\\n",
    "#                                 format(int(redshift_stages[i,1]))\n",
    "#                         elif int(redshift_stages[i,0])==1:\n",
    "#                             flux_recall=' Obs Flux_{} (wt) '.\\\n",
    "#                                 format(int(redshift_stages[i,1]))\n",
    "#                             flux_change=' D_Obs Flux_{} (wt) '.\\\n",
    "#                                 format(int(redshift_stages[i,1]))\n",
    "#                         else:\n",
    "#                             print(\"error, this burst ({}) didn't get an assigned flux.\").\\\n",
    "#                             format(fermi_data.at[j,\"name        \"])\n",
    "#                         z_matches[l, 13]=more_xrt_data[flux_recall][xrt_call]\n",
    "#                         if more_xrt_data[flux_change][xrt_call]==' , ':\n",
    "#                             z_matches[l,14]=0.34*float(more_xrt_data[flux_recall][xrt_call])\n",
    "#                             z_matches[l,15]=0.34*float(more_xrt_data[flux_recall][xrt_call])\n",
    "#                             #this is about one standard deviation\n",
    "#                         elif ',' in str(more_xrt_data[flux_change][xrt_call]):\n",
    "#                             dual_input=re.split(\",\", str(more_xrt_data[flux_change][xrt_call])\\\n",
    "#                                                 .strip())\n",
    "#                             headphones = list(map(float, dual_input))\n",
    "#                             z_matches[l,14]=headphones[0]\n",
    "#                             z_matches[l,15]=headphones[1]\n",
    "#                             #I originally only left room for one value. That was a mistake.\n",
    "#                         else:\n",
    "#                             z_matches[l, 14]=more_xrt_data[flux_change][xrt_call]\n",
    "#                             z_matches[l, 15]=more_xrt_data[flux_change][xrt_call]\n",
    "#                         z_matches[l,16]=redshift_avg_slope[i, 1]\n",
    "                        if len(np.where(redshift_matches[:,1]==\\\n",
    "                                        redshift_swift_data.index[i])[0])>0:\n",
    "                            redshift_recall=np.where(redshift_matches[:,1]==\\\n",
    "                                                     redshift_swift_data.index[i])[0][0]\n",
    "                            redshift_call=redshift_matches[redshift_recall, 0]\n",
    "                            z_matches[l,15] = float(swift_redshifts.at[redshift_call, ' z ']\\\n",
    "                                                .strip().replace('(?)', '')\\\n",
    "                                                .replace('?', '').replace('<', '').\\\n",
    "                                               replace('>', ''))\n",
    "                            #z_matches[l, 15] = 0\n",
    "                        elif len(np.where(other_redshift_matches[:,1]==\\\n",
    "                                        redshift_swift_data.index[i])[0])>0:\n",
    "                            redshift_recall=np.where(other_redshift_matches[:,1]==\\\n",
    "                                                     redshift_swift_data.index[i])[0][0]\n",
    "                            redshift_call=redshift_matches[redshift_recall, 0]\n",
    "                            z_matches[l,15] = float(swift_redshifts.at[redshift_call, ' z ']\\\n",
    "                                                .strip().replace('(?)', '')\\\n",
    "                                                .replace('?', '').replace('<', '').\\\n",
    "                                               replace('>', ''))\n",
    "                            #z_matches[l, 15] = 1\n",
    "                        l=l+1;\n",
    "            else:\n",
    "                if feet_covers_2[j,i]<3*w0ter[j]: #RA\n",
    "                    if UV_protection_2[j,i]<3*w0ter[j]: #dec\n",
    "                        special_cases=np.append(special_cases,fermi_data.at[j,\"name        \"])\n",
    "                        z_potential_matches[l,0]=food_2[j,i]\n",
    "                        z_potential_matches[l,1]=w0ter[j]\n",
    "                        z_potential_matches[l,2]=gatorade2[i]\n",
    "                        name=fermi_data.at[j,\"name        \"]\n",
    "                        z_matches[l,0] = int(name[3]+name[4]+name[5]+name[6]+\\\n",
    "                                           name[7]+name[8]+name[9]+name[10]+name[11])\n",
    "                        z_matches[l,1] = j\n",
    "                        z_matches[l,2] = redshift_swift_data.index[i]\n",
    "                        if w0ter[j] != 0 and gatorade2[i] != 0:\n",
    "                            z_matches[l,3] = 1-NormalDist(mu=boots[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=shoes2[i], sigma=gatorade2[i]))*\\\n",
    "                                        NormalDist(mu=hat[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=helmet2[i], sigma=gatorade2[i])) #alpha\n",
    "                            z_matches[l,4] = NormalDist(mu=boots[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=shoes2[i], sigma=gatorade2[i]))*\\\n",
    "                                        NormalDist(mu=hat[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=helmet2[i], sigma=gatorade2[i])) #beta\n",
    "                        else:\n",
    "                            z_matches[l,3]='NaN'\n",
    "                            z_matches[l,4]='NaN'\n",
    "                            err=err+1;\n",
    "                        z_matches[l,5] = fermi_data.at[j,\"t90     \"]\n",
    "                        z_matches[l,6] = fermi_data.at[j,\"t90_error\"]\n",
    "                        z_matches[l,7] = fermi_data.at[j,'flux_256 ']\n",
    "                        z_matches[l,8] = fermi_data.at[j,'fluence   ']\n",
    "                        z_matches[l,9] = fermi_data.at[j,'fluence_error']\n",
    "                        z_matches[l,10] = swift_fluxes.at[redshift_swift_data.index[i],\\\n",
    "                                                           ' 15_350kev ']\n",
    "                        z_matches[l,11] = swift_fluences.at[redshift_swift_data.index[i],\\\n",
    "                                                             ' 15_350kev ']\n",
    "                        if fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_plaw              ':\n",
    "                            z_matches[l,12] = 1\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_band              ':\n",
    "                            z_matches[l,12] = 2\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_comp              ':\n",
    "                            z_matches[l,12] = 3\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_sbpl              ':\n",
    "                            z_matches[l,12] = 4\n",
    "                        else:\n",
    "                            z_matches[l,12] = 0\n",
    "#                         xrt_xcall=np.where(redshift_xrt[:,0]==i)[0][0]\n",
    "                        z_matches[l,13]=int(redshift_xrt[i, 1])\n",
    "                        z_matches[l,14] = int(redshift_stages[i,1])\n",
    "    #                     matches[k, 11]=xrt_data.at[xrt_call,\\\n",
    "    #                                         'XRT Early Flux (0.3-10 keV) [10^-11 erg/cm^2/s]']\n",
    "    #                     print(i)\n",
    "    #                     print(xrt_call)\n",
    "#                         if int(redshift_stages[i,0])==0:\n",
    "#                             flux_recall=' Obs Flux_{} (pc) '.\\\n",
    "#                                 format(int(redshift_stages[i,1]))\n",
    "#                             flux_change=' D_Obs Flux_{} (pc) '.\\\n",
    "#                                 format(int(redshift_stages[i,1]))\n",
    "#                         elif int(redshift_stages[i,0])==1:\n",
    "#                             flux_recall=' Obs Flux_{} (wt) '.\\\n",
    "#                                 format(int(redshift_stages[i,1]))\n",
    "#                             flux_change=' D_Obs Flux_{} (wt) '.\\\n",
    "#                                 format(int(redshift_stages[i,1]))\n",
    "#                         else:\n",
    "#                             print(\"error, this burst ({}) didn't get an assigned flux.\").\\\n",
    "#                             format(fermi_data.at[j,\"name        \"])\n",
    "    #                     print(fermi_data.at[j,\"name        \"])\n",
    "    #                     print(redshift_swift_data.at[redshift_swift_data.index[i], 'GRBname '])\n",
    "    #                     print(flux_recall)\n",
    "    #                     print(more_xrt_data[flux_recall][xrt_call])\n",
    "#                         z_matches[l, 13]=more_xrt_data[flux_recall][xrt_call]\n",
    "#                         if more_xrt_data[flux_change][xrt_call]==' , ':\n",
    "#                             z_matches[l,14]=0.34*float(more_xrt_data[flux_recall][xrt_call])\n",
    "#                             z_matches[l,15]=0.34*float(more_xrt_data[flux_recall][xrt_call])\n",
    "#                             #this is about one standard deviation\n",
    "#                         elif ',' in str(more_xrt_data[flux_change][xrt_call]):\n",
    "#                             dual_input=re.split(\",\", str(more_xrt_data[flux_change][xrt_call])\\\n",
    "#                                                 .strip())\n",
    "#                             headphones = list(map(float, dual_input))\n",
    "#                             z_matches[l,14]=headphones[0]\n",
    "#                             z_matches[l,15]=headphones[1]\n",
    "#                             #I originally only left room for one value. That was a mistake.\n",
    "#                         else:\n",
    "#                             z_matches[l, 14]=more_xrt_data[flux_change][xrt_call]\n",
    "#                             z_matches[l, 15]=more_xrt_data[flux_change][xrt_call]\n",
    "#                         z_matches[l,16]=redshift_avg_slope[i, 1]\n",
    "    #                     z_matches[l,15]=max(more_xrt_data[' Ave_obs_flux_WT '][xrt_call],\\\n",
    "    #                                       more_xrt_data[' Ave_obs_flux_PC '][xrt_call])\n",
    "    #                     avg_flux=np.where([more_xrt_data[' Ave_obs_flux_WT '][xrt_call],\\\n",
    "    #                                       more_xrt_data[' Ave_obs_flux_PC '][xrt_call]]==\\\n",
    "    #                             max(more_xrt_data[' Ave_obs_flux_WT '][xrt_call],\\\n",
    "    #                                       more_xrt_data[' Ave_obs_flux_PC '][xrt_call]))\n",
    "    #                     if avg_flux==0:\n",
    "    #                         z_matches[l, 16]=more_xrt_data[' d_Ave_obs_flux_WT '][xrt_call]\n",
    "    #                     elif avg_flux==1:\n",
    "    #                         z_matches[l, 16]=more_xrt_data[' d_Ave_obs_flux_PC '][xrt_call]\n",
    "                        if len(np.where(redshift_matches[:,1]==\\\n",
    "                                        redshift_swift_data.index[i])[0])>0:\n",
    "                            redshift_recall=np.where(redshift_matches[:,1]==\\\n",
    "                                                     redshift_swift_data.index[i])[0][0]\n",
    "                            redshift_call=redshift_matches[redshift_recall, 0]\n",
    "                            z_matches[l,15] = float(swift_redshifts.at[redshift_call, ' z ']\\\n",
    "                                                .strip().replace('(?)', '')\\\n",
    "                                                .replace('?', '').replace('<', '').\\\n",
    "                                               replace('>', ''))\n",
    "                            #z_matches[l, 15] = 0\n",
    "                        elif len(np.where(other_redshift_matches[:,1]==\\\n",
    "                                        redshift_swift_data.index[i])[0])>0:\n",
    "                            redshift_recall=np.where(other_redshift_matches[:,1]==\\\n",
    "                                                     redshift_swift_data.index[i])[0][0]\n",
    "                            redshift_call=redshift_matches[redshift_recall, 0]\n",
    "                            z_matches[l,15] = float(swift_redshifts.at[redshift_call, ' z ']\\\n",
    "                                                .strip().replace('(?)', '')\\\n",
    "                                                .replace('?', '').replace('<', '').\\\n",
    "                                               replace('>', ''))\n",
    "                            #z_matches[l, 15] = 1\n",
    "                        l=l+1;\n",
    "redshifted_matches=pd.DataFrame(z_matches, columns=['name', 'Fermi row', 'Swift row', \\\n",
    "                                                    'Type I error', \\\n",
    "                                       'Type II error', 't90', 't90_error', 'GBM flux', \\\n",
    "                                       'GBM fluence', 'Fluence error',\\\n",
    "                                                    'BAT flux', 'BAT fluence',\\\n",
    "                                                    'Spectral Model', 'XRT row', \\\n",
    "                                                    'Plateau Stage',\\\n",
    "#                                                '\"Plateau\" X-Ray Flux',\\\n",
    "#                                                \"Pre-X-ray Flux Change\", \\\n",
    "#                                                \"Post-X-ray Flux Change\",\\\n",
    "                                                    'Likely Redshift'])\n",
    "redshifted_matches=redshifted_matches[:-1]\n",
    "sample_6_data=redshifted_matches\n",
    "print(special_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8322d72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Sample 0 Diagnositics##\n",
    "# unknown_progenitor_HR=[]\n",
    "# unknown_progenitor_HR_err=np.zeros((1,2))\n",
    "# unknown_progenitor_t90=[]\n",
    "# unknown_progenitor_t90_err=[]\n",
    "# unknown_progenitor_Epeak_over_s=[]\n",
    "# long_merger_HR=[]\n",
    "# long_merger_HR_err=np.zeros((1,2))\n",
    "# long_merger_t90=[]\n",
    "# long_merger_t90_err=[]\n",
    "# long_merger_Epeak_over_s=[]\n",
    "# short_merger_HR=[]\n",
    "# short_merger_HR_err=np.zeros((1,2))\n",
    "# short_merger_t90=[]\n",
    "# short_merger_t90_err=[]\n",
    "# short_merger_Epeak_over_s=[]\n",
    "# long_collapsar_HR=[]\n",
    "# long_collapsar_HR_err=np.zeros((1,2))\n",
    "# long_collapsar_t90=[]\n",
    "# long_collapsar_t90_err=[]\n",
    "# long_collapsar_Epeak_over_s=[]\n",
    "# short_collapsar_HR=[]\n",
    "# short_collapsar_HR_err=np.zeros((1,2))\n",
    "# short_collapsar_t90=[]\n",
    "# short_collapsar_t90_err=[]\n",
    "# short_collapsar_Epeak_over_s=[]\n",
    "# exotic_HR=[]\n",
    "# exotic_HR_err=np.zeros((1,2))\n",
    "# exotic_t90=[]\n",
    "# exotic_t90_err=[]\n",
    "# exotic_Epeak_over_s=[]\n",
    "# isolated_HR=[]\n",
    "# isolated_HR_err=np.zeros((1,2))\n",
    "# isolated_t90=[]\n",
    "# isolated_t90_err=[]\n",
    "# isolated_Epeak_over_s=[]\n",
    "# actually_valid_fluences=[]\n",
    "# nbins=51\n",
    "# #\n",
    "# #time to kneecap the data\n",
    "# #sample_0_data_b=sample_0_data[:-2]\n",
    "# valid_fluences=swift_fluences.drop(index=tiny_removals[:-39])\n",
    "# actually_valid_mask=np.isin(valid_fluences.index, (sample_0_data.index))\n",
    "# actually_valid_fluences=valid_fluences[actually_valid_mask]\n",
    "# fluence_mask=np.isin(actually_valid_fluences[' 25_50kev '], (\" N/A\", \" N/A \", 0), \\\n",
    "#                      invert=True)\n",
    "# fluence_available_swift_data=sample_0_data[fluence_mask]\n",
    "# good_fluences=valid_fluences[fluence_mask]\n",
    "# half_flu_mask=np.isin(good_fluences[' 25_50kev_low '], (\" N/A\", \" N/A \", 0), invert=True)\n",
    "# almost_err_fluences=good_fluences[half_flu_mask]\n",
    "# other_flu_mask=np.isin(almost_err_fluences[' 25_50kev_hi '], (\" N/A\", \" N/A \", 0), invert=True)\n",
    "# complete_err_fluences=almost_err_fluences[other_flu_mask]\n",
    "# lc_mask=np.isin(fluence_available_swift_data[ \"GRBname \"], \\\n",
    "#                 Known_Precursors[\"Long Collapsars\"])\n",
    "# lc_edited_swift_data=fluence_available_swift_data[lc_mask]\n",
    "# for i in lc_edited_swift_data.index.to_list():\n",
    "#     if valid_fluences.at[i, ' 50_100kev '] != 'N/A' and \\\n",
    "#     valid_fluences.at[i, ' 50_100kev '] != ' N/A ':\n",
    "#         long_collapsar_HR=np.append(long_collapsar_HR, \\\n",
    "#             float(valid_fluences.at[i, ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[i, ' 25_50kev ']))\n",
    "#     else:\n",
    "#         long_collapsar_HR=np.NaN\n",
    "#     if valid_fluences.at[i, ' 15_350kev '] != 'N/A' and \\\n",
    "#     valid_fluences.at[i, ' 15_350kev '] != ' N/A ':\n",
    "#         long_collapsar_Epeak_over_s=np.append(long_collapsar_Epeak_over_s, \\\n",
    "#                         (getting_the_BAT_E_peak(i))/\\\n",
    "#                                     float(valid_fluences.at[i, ' 15_350kev ']))\n",
    "#     else:\n",
    "#         long_collapsar_Epeak_over_s=np.append(long_collapsar_Epeak_over_s, np.NaN)\n",
    "#     long_collapsar_t90=np.append(long_collapsar_t90, float(lc_edited_swift_data.at[i, \\\n",
    "#                                                                 '     T90      ']))\n",
    "#     long_collapsar_HR_err=np.append(long_collapsar_HR_err, \\\n",
    "#                                     [swift_error_calculator(i, valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "# long_collapsar_HR_err=long_collapsar_HR_err[1:]\n",
    "# long_collapsar_t90_err=np.where(lc_edited_swift_data[ '   T90_err    '] != 'N/A', \\\n",
    "#         lc_edited_swift_data['   T90_err    '], 0)\n",
    "# if len(long_collapsar_t90_err)>0:\n",
    "#     for j in range(0, len(long_collapsar_t90_err)):\n",
    "#         long_collapsar_t90_err[j]=float(long_collapsar_t90_err[j])\n",
    "\n",
    "# sc_mask=np.isin(fluence_available_swift_data[ \"GRBname \"], \\\n",
    "#                 Known_Precursors[\"Short Collapsars\"])\n",
    "# sc_edited_swift_data=fluence_available_swift_data[sc_mask]\n",
    "# for i in sc_edited_swift_data.index.to_list():\n",
    "#     if valid_fluences.at[i, ' 50_100kev '] != 'N/A' and \\\n",
    "#     valid_fluences.at[i, ' 50_100kev '] != ' N/A ':\n",
    "#         short_collapsar_HR=np.append(short_collapsar_HR, \\\n",
    "#             float(valid_fluences.at[i, ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[i, ' 25_50kev ']))\n",
    "#     else:\n",
    "#         short_collapsar_HR=np.NaN\n",
    "#     if valid_fluences.at[i, ' 15_350kev '] != 'N/A' and \\\n",
    "#     valid_fluences.at[i, ' 15_350kev '] != ' N/A ':\n",
    "#         short_collapsar_Epeak_over_s=np.append(short_collapsar_Epeak_over_s, \\\n",
    "#                         (getting_the_BAT_E_peak(i))/\\\n",
    "#                                     float(valid_fluences.at[i, ' 15_350kev ']))\n",
    "#     else:\n",
    "#         short_collapsar_Epeak_over_s=np.append(short_collapsar_Epeak_over_s, np.NaN)\n",
    "#     short_collapsar_t90=np.append(short_collapsar_t90, float(sc_edited_swift_data.at[i, \\\n",
    "#                                                                 '     T90      ']))\n",
    "#     short_collapsar_HR_err=np.append(short_collapsar_HR_err, \\\n",
    "#                                      [swift_error_calculator(i, valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "# short_collapsar_HR_err=short_collapsar_HR_err[1:]\n",
    "# short_collapsar_t90_err=np.where(sc_edited_swift_data[ '   T90_err    '] != 'N/A', \\\n",
    "#         sc_edited_swift_data['   T90_err    '], 0)\n",
    "# if len(short_collapsar_t90_err)>0:\n",
    "#     for j in range(0, len(short_collapsar_t90_err)):\n",
    "#         short_collapsar_t90_err[j]=float(short_collapsar_t90_err[j])\n",
    "# lm_mask=np.isin(fluence_available_swift_data[ \"GRBname \"], \\\n",
    "#                 Known_Precursors[\"Long Mergers\"])\n",
    "# lm_edited_swift_data=fluence_available_swift_data[lm_mask]\n",
    "# for i in lm_edited_swift_data.index.to_list():\n",
    "#     if valid_fluences.at[i, ' 50_100kev '] != 'N/A' and \\\n",
    "#     valid_fluences.at[i, ' 50_100kev '] != ' N/A ':\n",
    "#         long_merger_HR=np.append(long_merger_HR, \\\n",
    "#             float(valid_fluences.at[i, ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[i, ' 25_50kev ']))\n",
    "#     else:\n",
    "#         long_merger_HR=np.NaN\n",
    "#     if valid_fluences.at[i, ' 15_350kev '] != 'N/A' and \\\n",
    "#     valid_fluences.at[i, ' 15_350kev '] != ' N/A ':\n",
    "#         long_merger_Epeak_over_s=np.append(long_merger_Epeak_over_s, \\\n",
    "#                         (getting_the_BAT_E_peak(i))/\\\n",
    "#                                            float(valid_fluences.at[i, ' 15_350kev ']))\n",
    "#     else:\n",
    "#         long_merger_Epeak_over_s=np.append(long_merger_Epeak_over_s, np.NaN)\n",
    "#     long_merger_t90=np.append(long_merger_t90, float(lm_edited_swift_data.at[i, \\\n",
    "#                                                                 '     T90      ']))\n",
    "#     long_merger_HR_err=np.append(long_merger_HR_err, \\\n",
    "#                                  [swift_error_calculator(i, valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "# long_merger_HR_err=long_merger_HR_err[1:]\n",
    "# long_merger_t90_err=np.where(lm_edited_swift_data[ '   T90_err    '] != 'N/A', \\\n",
    "#         lm_edited_swift_data['   T90_err    '], 0)\n",
    "# if len(long_merger_t90_err)>0:\n",
    "#     for j in range(0, len(long_merger_t90_err)):\n",
    "#         long_merger_t90_err[j]=float(long_merger_t90_err[j])\n",
    "# sm_mask=np.isin(fluence_available_swift_data[ \"GRBname \"], \\\n",
    "#                 Known_Precursors[\"Short Mergers\"])\n",
    "# sm_edited_swift_data=fluence_available_swift_data[sm_mask]\n",
    "# for i in sm_edited_swift_data.index.to_list():\n",
    "#     if valid_fluences.at[i, ' 50_100kev '] != 'N/A' and \\\n",
    "#     valid_fluences.at[i, ' 50_100kev '] != ' N/A ':\n",
    "#         short_merger_HR=np.append(short_merger_HR, \\\n",
    "#             float(valid_fluences.at[i, ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[i, ' 25_50kev ']))\n",
    "#     else:\n",
    "#         short_merger_HR=np.NaN\n",
    "#     if valid_fluences.at[i, ' 15_350kev '] != 'N/A' and \\\n",
    "#     valid_fluences.at[i, ' 15_350kev '] != ' N/A ':\n",
    "#         short_merger_Epeak_over_s=np.append(short_merger_Epeak_over_s, \\\n",
    "#                         (getting_the_BAT_E_peak(i))/\\\n",
    "#                                             float(valid_fluences.at[i, ' 15_350kev ']))\n",
    "#     else:\n",
    "#         short_merger_Epeak_over_s=np.append(short_merger_Epeak_over_s, np.NaN)\n",
    "#     short_merger_t90=np.append(short_merger_t90, float(sm_edited_swift_data.at[i, \\\n",
    "#                                                                 '     T90      ']))\n",
    "#     short_merger_HR_err=np.append(short_merger_HR_err, \\\n",
    "#                                   [swift_error_calculator(i, valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "# short_merger_HR_err=short_merger_HR_err[1:]\n",
    "# short_merger_t90_err=np.where(sm_edited_swift_data[ '   T90_err    '] != 'N/A', \\\n",
    "#         sm_edited_swift_data['   T90_err    '], 0)\n",
    "# if len(short_merger_t90_err)>0:\n",
    "#     for j in range(0, len(short_merger_t90_err)):\n",
    "#         short_merger_t90_err[j]=float(short_merger_t90_err[j])\n",
    "# exo_mask=np.isin(fluence_available_swift_data[ \"GRBname \"], \\\n",
    "#                 Known_Precursors[\"Potentially Exotic\"])\n",
    "# exo_edited_swift_data=fluence_available_swift_data[exo_mask]\n",
    "# for i in exo_edited_swift_data.index.to_list():\n",
    "#     if valid_fluences.at[i, ' 50_100kev '] != 'N/A' and \\\n",
    "#     valid_fluences.at[i, ' 50_100kev '] != ' N/A ':\n",
    "#         exotic_HR=np.append(exotic_HR, \\\n",
    "#             float(valid_fluences.at[i, ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[i, ' 25_50kev ']))\n",
    "#     else:\n",
    "#         exotic_HR=np.NaN\n",
    "#     if valid_fluences.at[i, ' 15_350kev '] != 'N/A' and \\\n",
    "#     valid_fluences.at[i, ' 15_350kev '] != ' N/A ':\n",
    "#         exotic_Epeak_over_s=np.append(exotic_Epeak_over_s, \\\n",
    "#                         (getting_the_BAT_E_peak(i))/\\\n",
    "#                                       float(valid_fluences.at[i, ' 15_350kev ']))\n",
    "#     else:\n",
    "#         exotic_Epeak_over_s=np.append(exotic_Epeak_over_s, np.NaN)\n",
    "#     exotic_t90=np.append(exotic_t90, float(exo_edited_swift_data.at[i, \\\n",
    "#                                                                 '     T90      ']))\n",
    "#     exotic_HR_err=np.append(exotic_HR_err, [swift_error_calculator(i, valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "# exotic_HR_err=exotic_HR_err[1:]\n",
    "# exotic_t90_err=np.where(exo_edited_swift_data[ '   T90_err    '] != 'N/A', \\\n",
    "#         exo_edited_swift_data['   T90_err    '], 0)\n",
    "# if len(exotic_t90_err)>0:\n",
    "#     for j in range(0, len(exotic_t90_err)):\n",
    "#         exotic_t90_err[j]=float(exotic_t90_err[j])\n",
    "# gal_mask=np.isin(fluence_available_swift_data[ \"GRBname \"], \\\n",
    "#                 Known_Precursors[\"Galactic Detected\"])\n",
    "# iso_edited_swift_data=fluence_available_swift_data[gal_mask]\n",
    "# for i in iso_edited_swift_data.index.to_list():\n",
    "#     if valid_fluences.at[i, ' 50_100kev '] != 'N/A' and \\\n",
    "#     valid_fluences.at[i, ' 50_100kev '] != ' N/A ':\n",
    "#         isolated_HR=np.append(isolated_HR, \\\n",
    "#             float(valid_fluences.at[i, ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[i, ' 25_50kev ']))\n",
    "#     else:\n",
    "#         isolated_HR=np.NaN\n",
    "#     if valid_fluences.at[i, ' 15_350kev '] != 'N/A' and \\\n",
    "#     valid_fluences.at[i, ' 15_350kev '] != ' N/A ':\n",
    "#         isolated_Epeak_over_s=np.append(isolated_Epeak_over_s, \\\n",
    "#                         (getting_the_BAT_E_peak(i))/\\\n",
    "#                                       float(valid_fluences.at[i, ' 15_350kev ']))\n",
    "#     else:\n",
    "#         isolated_Epeak_over_s=np.append(isolated_Epeak_over_s, np.NaN)\n",
    "#     isolated_t90=np.append(isolated_t90, float(iso_edited_swift_data.at[i, \\\n",
    "#                                                                 '     T90      ']))\n",
    "#     isolated_HR_err=np.append(isolated_HR_err,\\\n",
    "#                                     [swift_error_calculator(i, valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "# isolated_HR_err=isolated_HR_err[1:]\n",
    "# isolated_t90_err=np.where(iso_edited_swift_data[ '   T90_err    '] != 'N/A', \\\n",
    "#         iso_edited_swift_data['   T90_err    '], 0)\n",
    "# if len(isolated_t90_err)>0:\n",
    "#     for j in range(0, len(isolated_t90_err)):\n",
    "#         isolated_t90_err[j]=float(isolated_t90_err[j])\n",
    "# unknown_progenitor_edited_swift_data=fluence_available_swift_data[~(lm_mask|lc_mask|sm_mask|sc_mask|\\\n",
    "#                                                          exo_mask)]\n",
    "# for i in unknown_progenitor_edited_swift_data.index.to_list():\n",
    "#     if valid_fluences.at[i, ' 50_100kev '] != 'N/A' and \\\n",
    "#     valid_fluences.at[i, ' 50_100kev '] != ' N/A ':\n",
    "#         unknown_progenitor_HR=np.append(unknown_progenitor_HR, \\\n",
    "#             float(valid_fluences.at[i, ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[i, ' 25_50kev ']))\n",
    "#     else:\n",
    "#         unknown_progenitor_HR=np.append(unknown_progenitor_HR, np.NaN)\n",
    "#     if unknown_progenitor_edited_swift_data.at[i, '     T90      '] != 'N/A' and \\\n",
    "#     unknown_progenitor_edited_swift_data.at[i, '     T90      '] != ' N/A ' and \\\n",
    "#     unknown_progenitor_edited_swift_data.at[i, '     T90      '] != '     N/A      ':\n",
    "#         unknown_progenitor_t90=np.append(unknown_progenitor_t90, float(unknown_progenitor_edited_swift_data.at[i, \\\n",
    "#                                                                 '     T90      ']))\n",
    "#     else:\n",
    "#         unknown_progenitor_t90= np.append(unknown_progenitor_t90, np.NaN)\n",
    "#     if valid_fluences.at[i, ' 15_350kev '] != 'N/A' and \\\n",
    "#     valid_fluences.at[i, ' 15_350kev '] != ' N/A ':\n",
    "#         unknown_progenitor_Epeak_over_s=np.append(unknown_progenitor_Epeak_over_s, \\\n",
    "#                         (getting_the_BAT_E_peak(i))/\\\n",
    "#                                        float(valid_fluences.at[i, ' 15_350kev ']))\n",
    "#     else:\n",
    "#         unknown_progenitor_Epeak_over_s=np.append(unknown_progenitor_Epeak_over_s, np.NaN)\n",
    "#     unknown_progenitor_HR_err=np.append(unknown_progenitor_HR_err, [swift_error_calculator(i, valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "# unknown_progenitor_HR_err=unknown_progenitor_HR_err[1:]\n",
    "# for i in unknown_progenitor_edited_swift_data.index.to_list():\n",
    "#     if unknown_progenitor_edited_swift_data.at[i, '   T90_err    '] == 'N/A' or \\\n",
    "#     unknown_progenitor_edited_swift_data.at[i, '   T90_err    '] == ' N/A ' or \\\n",
    "#     unknown_progenitor_edited_swift_data.at[i, '   T90_err    '] == '      N/A     ':\n",
    "#         unknown_progenitor_t90_err=np.append(unknown_progenitor_t90_err, 0)\n",
    "#     else:\n",
    "#         unknown_progenitor_t90_err=np.append(unknown_progenitor_t90_err,\\\n",
    "#                         float(unknown_progenitor_edited_swift_data.at[i, '   T90_err    ']))\n",
    "# # unknown_progenitor_t90_err=np.where(unknown_progenitor_edited_swift_data[ '   T90_err    '] != 'N/A', \\\n",
    "# #         unknown_progenitor_edited_swift_data['   T90_err    '], 0)\n",
    "# # unknown_progenitor_t90_err=np.where(unknown_progenitor_edited_swift_data[ '   T90_err    '] != ' N/A ', \\\n",
    "# #         unknown_progenitor_edited_swift_data['   T90_err    '], 0)\n",
    "# # unknown_progenitor_t90_err=np.where(unknown_progenitor_edited_swift_data[ '   T90_err    '] != '      N/A     ', \\\n",
    "# #         unknown_progenitor_edited_swift_data['   T90_err    '], 0)\n",
    "# if len(unknown_progenitor_t90_err)>0:\n",
    "#     for j in range(0, len(unknown_progenitor_t90_err)):\n",
    "#         unknown_progenitor_t90_err[j]=float(unknown_progenitor_t90_err[j])\n",
    "# bins=np.logspace(np.log10(0.01),np.log10(1000), nbins)\n",
    "# plt.hist(unknown_progenitor_t90, bins=bins)\n",
    "# plt.hist(long_collapsar_t90, bins=bins)\n",
    "# plt.hist(long_merger_t90, bins=bins)\n",
    "# # plt.hist(short_collapsar_t90, bins=bins)\n",
    "# plt.hist(short_merger_t90, bins=bins)\n",
    "# # plt.hist(exotic_t90, bins=bins)\n",
    "# plt.hist(isolated_t90, bins=bins)\n",
    "# plt.xscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.8')\n",
    "# plt.tick_params(axis='y', colors='0.8')\n",
    "# plt.legend(['Unknown Progenitor', 'Long Collapsars', 'Long Mergers', \\\n",
    "#             'Short Mergers', 'Isolated GRBs'])\n",
    "# plt.xlabel(\"t90 (s)\", color=\"0.8\")\n",
    "# plt.ylabel(\"Number of Bursts\", color=\"0.8\")\n",
    "# plt.show()\n",
    "# print(\"There are {} known long collapsars, {} known long \\\n",
    "# mergers, {} known short mergers, {} known short collapsars, \\\n",
    "# {} known exotic GRBs, and {} isolated GRBs in Sample 0.\".\\\n",
    "# format(len(long_collapsar_t90), len(long_merger_t90), \\\n",
    "#        len(short_merger_t90), len(short_collapsar_t90), len(exotic_t90), \\\n",
    "#        len(isolated_t90)))\n",
    "# print('There are {} bursts in total'.format(np.count_nonzero(~np.isnan(long_collapsar_t90))\\\n",
    "#         +np.count_nonzero(~np.isnan(long_merger_t90))+\\\n",
    "#         np.count_nonzero(~np.isnan(short_merger_t90))+\\\n",
    "#         np.count_nonzero(~np.isnan(short_collapsar_t90))+\\\n",
    "#         np.count_nonzero(~np.isnan(exotic_t90))+\\\n",
    "#         np.count_nonzero(~np.isnan(isolated_t90))+\\\n",
    "#         np.count_nonzero(~np.isnan(unknown_progenitor_t90))))\n",
    "# plt.errorbar(x=unknown_progenitor_t90, y=unknown_progenitor_HR, yerr=np.transpose(unknown_progenitor_HR_err), \\\n",
    "#              xerr=unknown_progenitor_t90_err, marker=\".\", color='k', ls='none')\n",
    "# plt.errorbar(x=long_collapsar_t90, y=long_collapsar_HR, \\\n",
    "#              yerr=np.transpose(long_collapsar_HR_err), xerr=long_collapsar_t90_err,\\\n",
    "#              marker=\"o\", ls='none')\n",
    "# plt.errorbar(x=long_merger_t90, y=long_merger_HR, yerr=np.transpose(long_merger_HR_err),\\\n",
    "#              xerr=long_merger_t90_err, marker=\"*\", ls='none')\n",
    "# # plt.errorbar(x=short_collapsar_t90, y=short_collapsar_HR, \\\n",
    "# #              yerr=np.transpose(short_collapsar_HR_err), xerr=short_collapsar_t90_err,\\\n",
    "# #              marker=\"^\", ls='none')\n",
    "# plt.errorbar(x=short_merger_t90, y=short_merger_HR, yerr=np.transpose(short_merger_HR_err), \\\n",
    "#              xerr=short_merger_t90_err, marker=\"+\", ls='none')\n",
    "# # plt.errorbar(x=exotic_t90, y=exotic_HR, yerr=np.transpose(exotic_HR_err), \\\n",
    "# #              xerr=exotic_t90_err, marker=\"o\", ls='none')\n",
    "# plt.errorbar(x=isolated_t90, y=isolated_HR, \\\n",
    "#              yerr=np.transpose(isolated_HR_err), \\\n",
    "#              xerr=isolated_t90_err, marker=\"+\", ls='none')\n",
    "# plt.axis([0.1, 1000, 0.25, 25])\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.8')\n",
    "# plt.tick_params(axis='y', colors='0.8')\n",
    "# plt.legend(['Unknown Progenitor', 'Long Collapsars', 'Long Mergers', \\\n",
    "#             'Short Mergers', \"isolated GRBs\"])\n",
    "# plt.xlabel(\"t90 (s)\", color=\"0.8\")\n",
    "# plt.ylabel(\"Hardness Ratio\", color=\"0.8\")\n",
    "# plt.show()\n",
    "\n",
    "# # new_bins=np.logspace(5,13, 81)\n",
    "# # plt.hist(unknown_progenitor_Epeak_over_s, bins=new_bins)\n",
    "# # plt.hist(long_collapsar_Epeak_over_s, bins=new_bins)\n",
    "# # plt.hist(long_merger_Epeak_over_s, bins=new_bins)\n",
    "# # # plt.hist(short_collapsar_Epeak_over_s, bins=new_bins)\n",
    "# # plt.hist(short_merger_Epeak_over_s, bins=new_bins)\n",
    "# # # plt.hist(exotic_Epeak_over_s, bins=new_bins)\n",
    "# # plt.xscale('log')\n",
    "# # plt.tick_params(axis='x', colors='0.8')\n",
    "# # plt.tick_params(axis='y', colors='0.8')\n",
    "# # plt.legend(['Unknown Progenitor', 'Long Collapsars', 'Long Mergers', \\\n",
    "# #             'Short Mergers'])\n",
    "# # plt.xlabel(r\"$E_{peak}$/$Fluence_{10-1000keV}$ cm^2\", color=\"0.8\")\n",
    "# # plt.ylabel(\"Number of Bursts\", color=\"0.8\")\n",
    "# # plt.show()\n",
    "# # print(np.log10(np.nanmin(unknown_progenitor_Epeak_over_s)))\n",
    "# # print(np.log10(np.nanmax(unknown_progenitor_Epeak_over_s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c49afc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Sample 1 Diagnositics##\n",
    "# unknown_progenitor_HR=[]\n",
    "# unknown_progenitor_HR_err=np.zeros((1,2))\n",
    "# unknown_progenitor_t90=[]\n",
    "# unknown_progenitor_t90_err=[]\n",
    "# long_merger_HR=[]\n",
    "# long_merger_HR_err=np.zeros((1,2))\n",
    "# long_merger_t90=[]\n",
    "# long_merger_t90_err=[]\n",
    "# short_merger_HR=[]\n",
    "# short_merger_HR_err=np.zeros((1,2))\n",
    "# short_merger_t90=[]\n",
    "# short_merger_t90_err=[]\n",
    "# long_collapsar_HR=[]\n",
    "# long_collapsar_HR_err=np.zeros((1,2))\n",
    "# long_collapsar_t90=[]\n",
    "# long_collapsar_t90_err=[]\n",
    "# short_collapsar_HR=[]\n",
    "# short_collapsar_HR_err=np.zeros((1,2))\n",
    "# short_collapsar_t90=[]\n",
    "# short_collapsar_t90_err=[]\n",
    "# exotic_HR=[]\n",
    "# exotic_HR_err=np.zeros((1,2))\n",
    "# exotic_t90=[]\n",
    "# exotic_t90_err=[]\n",
    "# isolated_HR=[]\n",
    "# isolated_HR_err=np.zeros((1,2))\n",
    "# isolated_t90=[]\n",
    "# isolated_t90_err=[]\n",
    "# isolated_Epeak_over_s=[]\n",
    "# nbins=51\n",
    "# #\n",
    "# valid_fluences=swift_fluences.drop(index=removals[:-39])\n",
    "# fluence_mask=np.isin(valid_fluences[' 25_50kev '], (\" N/A\", \" N/A \", 0), invert=True)\n",
    "# fluence_available_swift_data=edited_swift_data[fluence_mask]\n",
    "# good_fluences=valid_fluences[fluence_mask]\n",
    "# half_flu_mask=np.isin(good_fluences[' 25_50kev_low '], (\" N/A\", \" N/A \", 0), invert=True)\n",
    "# almost_err_fluences=good_fluences[half_flu_mask]\n",
    "# other_flu_mask=np.isin(almost_err_fluences[' 25_50kev_hi '], (\" N/A\", \" N/A \", 0), invert=True)\n",
    "# complete_err_fluences=almost_err_fluences[other_flu_mask]\n",
    "# lc_mask=np.isin(fluence_available_swift_data[ \"GRBname \"], \\\n",
    "#                 Known_Precursors[\"Long Collapsars\"])\n",
    "# lc_edited_swift_data=fluence_available_swift_data[lc_mask]\n",
    "# for i in lc_edited_swift_data.index.to_list():\n",
    "#     long_collapsar_HR=np.append(long_collapsar_HR, \\\n",
    "#             float(valid_fluences.at[i, ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[i, ' 25_50kev ']))\n",
    "#     long_collapsar_t90=np.append(long_collapsar_t90, float(lc_edited_swift_data.at[i, \\\n",
    "#                                                                 '     T90      ']))\n",
    "#     long_collapsar_HR_err=np.append(long_collapsar_HR_err, \\\n",
    "#                                     [swift_error_calculator(i, valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "# long_collapsar_HR_err=long_collapsar_HR_err[1:]\n",
    "# long_collapsar_t90_err=np.where(lc_edited_swift_data[ '   T90_err    '] != 'N/A', \\\n",
    "#         lc_edited_swift_data['   T90_err    '], 0)\n",
    "# if len(long_collapsar_t90_err)>0:\n",
    "#     for j in range(0, len(long_collapsar_t90_err)):\n",
    "#         long_collapsar_t90_err[j]=float(long_collapsar_t90_err[j])\n",
    "\n",
    "# sc_mask=np.isin(fluence_available_swift_data[ \"GRBname \"], \\\n",
    "#                 Known_Precursors[\"Short Collapsars\"])\n",
    "# sc_edited_swift_data=fluence_available_swift_data[sc_mask]\n",
    "# for i in sc_edited_swift_data.index.to_list():\n",
    "#     short_collapsar_HR=np.append(short_collapsar_HR, \\\n",
    "#             float(valid_fluences.at[i, ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[i, ' 25_50kev ']))\n",
    "#     short_collapsar_t90=np.append(short_collapsar_t90, float(sc_edited_swift_data.at[i, \\\n",
    "#                                                                 '     T90      ']))\n",
    "#     short_collapsar_HR_err=np.append(short_collapsar_HR_err, \\\n",
    "#                                      [swift_error_calculator(i, valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "# short_collapsar_HR_err=short_collapsar_HR_err[1:]\n",
    "# short_collapsar_t90_err=np.where(sc_edited_swift_data[ '   T90_err    '] != 'N/A', \\\n",
    "#         sc_edited_swift_data['   T90_err    '], 0)\n",
    "# if len(short_collapsar_t90_err)>0:\n",
    "#     for j in range(0, len(short_collapsar_t90_err)):\n",
    "#         short_collapsar_t90_err[j]=float(short_collapsar_t90_err[j])\n",
    "# lm_mask=np.isin(fluence_available_swift_data[ \"GRBname \"], \\\n",
    "#                 Known_Precursors[\"Long Mergers\"])\n",
    "# lm_edited_swift_data=fluence_available_swift_data[lm_mask]\n",
    "# for i in lm_edited_swift_data.index.to_list():\n",
    "#     long_merger_HR=np.append(long_merger_HR, \\\n",
    "#             float(valid_fluences.at[i, ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[i, ' 25_50kev ']))\n",
    "#     long_merger_t90=np.append(long_merger_t90, float(lm_edited_swift_data.at[i, \\\n",
    "#                                                                 '     T90      ']))\n",
    "#     long_merger_HR_err=np.append(long_merger_HR_err, \\\n",
    "#                                  [swift_error_calculator(i, valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "# long_merger_HR_err=long_merger_HR_err[1:]\n",
    "# long_merger_t90_err=np.where(lm_edited_swift_data[ '   T90_err    '] != 'N/A', \\\n",
    "#         lm_edited_swift_data['   T90_err    '], 0)\n",
    "# if len(long_merger_t90_err)>0:\n",
    "#     for j in range(0, len(long_merger_t90_err)):\n",
    "#         long_merger_t90_err[j]=float(long_merger_t90_err[j])\n",
    "# sm_mask=np.isin(fluence_available_swift_data[ \"GRBname \"], \\\n",
    "#                 Known_Precursors[\"Short Mergers\"])\n",
    "# sm_edited_swift_data=fluence_available_swift_data[sm_mask]\n",
    "# for i in sm_edited_swift_data.index.to_list():\n",
    "#     short_merger_HR=np.append(short_merger_HR, \\\n",
    "#             float(valid_fluences.at[i, ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[i, ' 25_50kev ']))\n",
    "#     short_merger_t90=np.append(short_merger_t90, float(sm_edited_swift_data.at[i, \\\n",
    "#                                                                 '     T90      ']))\n",
    "#     short_merger_HR_err=np.append(short_merger_HR_err, \\\n",
    "#                                   [swift_error_calculator(i, valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "# short_merger_HR_err=short_merger_HR_err[1:]\n",
    "# short_merger_t90_err=np.where(sm_edited_swift_data[ '   T90_err    '] != 'N/A', \\\n",
    "#         sm_edited_swift_data['   T90_err    '], 0)\n",
    "# if len(short_merger_t90_err)>0:\n",
    "#     for j in range(0, len(short_merger_t90_err)):\n",
    "#         short_merger_t90_err[j]=float(short_merger_t90_err[j])\n",
    "# exo_mask=np.isin(fluence_available_swift_data[ \"GRBname \"], \\\n",
    "#                 Known_Precursors[\"Potentially Exotic\"])\n",
    "# exo_edited_swift_data=fluence_available_swift_data[exo_mask]\n",
    "# for i in exo_edited_swift_data.index.to_list():\n",
    "#     exotic_HR=np.append(exotic_HR, \\\n",
    "#             float(valid_fluences.at[i, ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[i, ' 25_50kev ']))\n",
    "#     exotic_t90=np.append(exotic_t90, float(exo_edited_swift_data.at[i, \\\n",
    "#                                                                 '     T90      ']))\n",
    "#     exotic_HR_err=np.append(exotic_HR_err, [swift_error_calculator(i, valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "# exotic_HR_err=exotic_HR_err[1:]\n",
    "# exotic_t90_err=np.where(exo_edited_swift_data[ '   T90_err    '] != 'N/A', \\\n",
    "#         exo_edited_swift_data['   T90_err    '], 0)\n",
    "# if len(exotic_t90_err)>0:\n",
    "#     for j in range(0, len(exotic_t90_err)):\n",
    "#         exotic_t90_err[j]=float(exotic_t90_err[j])\n",
    "# gal_mask=np.isin(fluence_available_swift_data[ \"GRBname \"], \\\n",
    "#                 Known_Precursors[\"Galactic Detected\"])\n",
    "# iso_edited_swift_data=fluence_available_swift_data[gal_mask]\n",
    "# for i in iso_edited_swift_data.index.to_list():\n",
    "#     if valid_fluences.at[i, ' 50_100kev '] != 'N/A' and \\\n",
    "#     valid_fluences.at[i, ' 50_100kev '] != ' N/A ':\n",
    "#         isolated_HR=np.append(isolated_HR, \\\n",
    "#             float(valid_fluences.at[i, ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[i, ' 25_50kev ']))\n",
    "#     else:\n",
    "#         isolated_HR=np.NaN\n",
    "#     if valid_fluences.at[i, ' 15_350kev '] != 'N/A' and \\\n",
    "#     valid_fluences.at[i, ' 15_350kev '] != ' N/A ':\n",
    "#         isolated_Epeak_over_s=np.append(isolated_Epeak_over_s, \\\n",
    "#                         (getting_the_BAT_E_peak(i))/\\\n",
    "#                                       float(valid_fluences.at[i, ' 15_350kev ']))\n",
    "#     else:\n",
    "#         isolated_Epeak_over_s=np.append(isolated_Epeak_over_s, np.NaN)\n",
    "#     isolated_t90=np.append(isolated_t90, float(iso_edited_swift_data.at[i, \\\n",
    "#                                                                 '     T90      ']))\n",
    "#     isolated_HR_err=np.append(isolated_HR_err,\\\n",
    "#                                     [swift_error_calculator(i, valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "# isolated_HR_err=isolated_HR_err[1:]\n",
    "# isolated_t90_err=np.where(iso_edited_swift_data[ '   T90_err    '] != 'N/A', \\\n",
    "#         iso_edited_swift_data['   T90_err    '], 0)\n",
    "# if len(isolated_t90_err)>0:\n",
    "#     for j in range(0, len(isolated_t90_err)):\n",
    "#         isolated_t90_err[j]=float(isolated_t90_err[j])\n",
    "# unknown_progenitor_edited_swift_data=fluence_available_swift_data[~(lm_mask|lc_mask|sm_mask|sc_mask|\\\n",
    "#                                                          exo_mask)]\n",
    "# for i in unknown_progenitor_edited_swift_data.index.to_list():\n",
    "#     unknown_progenitor_HR=np.append(unknown_progenitor_HR, \\\n",
    "#             float(valid_fluences.at[i, ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[i, ' 25_50kev ']))\n",
    "#     unknown_progenitor_t90=np.append(unknown_progenitor_t90, float(unknown_progenitor_edited_swift_data.at[i, \\\n",
    "#                                                                 '     T90      ']))\n",
    "#     unknown_progenitor_HR_err=np.append(unknown_progenitor_HR_err, [swift_error_calculator(i, valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "# unknown_progenitor_HR_err=unknown_progenitor_HR_err[1:]\n",
    "# unknown_progenitor_t90_err=np.where(\\\n",
    "#             unknown_progenitor_edited_swift_data[ '   T90_err    '] != 'N/A', \\\n",
    "#         unknown_progenitor_edited_swift_data['   T90_err    '], 0)\n",
    "# unknown_progenitor_t90_err=np.where(\\\n",
    "#             unknown_progenitor_edited_swift_data[ '   T90_err    '] != ' N/A ', \\\n",
    "#         unknown_progenitor_edited_swift_data['   T90_err    '], 0)\n",
    "# if len(unknown_progenitor_t90_err)>0:\n",
    "#     for j in range(0, len(unknown_progenitor_t90_err)):\n",
    "#         unknown_progenitor_t90_err[j]=float(unknown_progenitor_t90_err[j])\n",
    "# bins=np.logspace(np.log10(0.01),np.log10(1000), nbins)\n",
    "# plt.hist(unknown_progenitor_t90, bins=bins)\n",
    "# plt.hist(long_collapsar_t90, bins=bins)\n",
    "# plt.hist(long_merger_t90, bins=bins)\n",
    "# #plt.hist(short_collapsar_t90, bins=bins)\n",
    "# plt.hist(short_merger_t90, bins=bins)\n",
    "# #plt.hist(exotic_t90, bins=bins)\n",
    "# plt.hist(isolated_t90, bins=bins)\n",
    "# plt.xscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.8')\n",
    "# plt.tick_params(axis='y', colors='0.8')\n",
    "# plt.legend(['Unknown Progenitor', 'Long Collapsars', 'Long Mergers', \\\n",
    "#             'Short Mergers', 'Isolated GRBs'])\n",
    "# plt.xlabel(\"t90 (s)\", color=\"0.8\")\n",
    "# plt.ylabel(\"Number of Bursts\", color=\"0.8\")\n",
    "# plt.show()\n",
    "# print(\"There are {} known long collapsars, {} known long \\\n",
    "# mergers, {} known short mergers, {} known short collapsars, \\\n",
    "# {} known exotic GRBs, and {} isolated GRBs in Sample 1.\".\\\n",
    "# format(len(long_collapsar_t90), len(long_merger_t90), \\\n",
    "#        len(short_merger_t90), len(short_collapsar_t90), len(exotic_t90), \\\n",
    "#        len(isolated_t90)))\n",
    "# print('There are {} bursts in total'.format(np.count_nonzero(~np.isnan(long_collapsar_t90))\\\n",
    "#         +np.count_nonzero(~np.isnan(long_merger_t90))+\\\n",
    "#         np.count_nonzero(~np.isnan(short_merger_t90))+\\\n",
    "#         np.count_nonzero(~np.isnan(short_collapsar_t90))+\\\n",
    "#         np.count_nonzero(~np.isnan(exotic_t90))+\\\n",
    "#         np.count_nonzero(~np.isnan(isolated_t90))+\\\n",
    "#         np.count_nonzero(~np.isnan(unknown_progenitor_t90))))\n",
    "# plt.errorbar(x=unknown_progenitor_t90, y=unknown_progenitor_HR, \\\n",
    "#              yerr=np.transpose(unknown_progenitor_HR_err), \\\n",
    "#              xerr=unknown_progenitor_t90_err, \\\n",
    "#              marker=\".\", color='k', ls='none')\n",
    "# plt.errorbar(x=long_collapsar_t90, y=long_collapsar_HR, \\\n",
    "# #              yerr=np.transpose(long_collapsar_HR_err), xerr=long_collapsar_t90_err,\\\n",
    "#              marker=\"o\", ls='none')\n",
    "# plt.errorbar(x=long_merger_t90, y=long_merger_HR, \\\n",
    "#              yerr=np.transpose(long_merger_HR_err),\\\n",
    "#              xerr=long_merger_t90_err, \\\n",
    "#              marker=\"*\", ls='none')\n",
    "# # plt.errorbar(x=short_collapsar_t90, y=short_collapsar_HR, \\\n",
    "# #              yerr=np.transpose(short_collapsar_HR_err), xerr=short_collapsar_t90_err,\\\n",
    "# #              marker=\"^\", ls='none')\n",
    "# plt.errorbar(x=short_merger_t90, y=short_merger_HR, \\\n",
    "#              yerr=np.transpose(short_merger_HR_err), \\\n",
    "#              xerr=short_merger_t90_err, \\\n",
    "#              marker=\"+\", ls='none')\n",
    "# # plt.errorbar(x=exotic_t90, y=exotic_HR, yerr=np.transpose(exotic_HR_err), \\\n",
    "# #              xerr=exotic_t90_err, marker=\"o\", ls='none')\n",
    "# plt.errorbar(x=isolated_t90, y=isolated_HR, \\\n",
    "#              yerr=np.transpose(isolated_HR_err), \\\n",
    "#              xerr=isolated_t90_err, \\\n",
    "#              marker=\"+\", ls='none')\n",
    "# plt.axis([0.1, 1000, 0.25, 25])\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.8')\n",
    "# plt.tick_params(axis='y', colors='0.8')\n",
    "# plt.legend(['Unknown Progenitor', 'Long Collapsars', 'Long Mergers', \\\n",
    "#             'Short Mergers', 'isolated GRBs'])\n",
    "# plt.xlabel(\"t90 (s)\", color=\"0.8\")\n",
    "# plt.ylabel(\"Hardness Ratio\", color=\"0.8\")\n",
    "# plt.show()\n",
    "# # min(unknown_progenitor_t90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90bf4747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Sample 2 Diagnositics##\n",
    "# #unknown_progenitor_edited_fermi_data=fermi_data\n",
    "# unknown_progenitor_HR=[]\n",
    "# unknown_progenitor_HR_err=np.zeros((1,2))\n",
    "# unknown_progenitor_t90=[]\n",
    "# unknown_progenitor_t90_err=[]\n",
    "# unknown_progenitor_Epeak_over_s=[]\n",
    "# long_merger_HR=[]\n",
    "# long_merger_HR_err=np.zeros((1,2))\n",
    "# long_merger_t90=[]\n",
    "# long_merger_t90_err=[]\n",
    "# long_merger_Epeak_over_s=[]\n",
    "# short_merger_HR=[]\n",
    "# short_merger_HR_err=np.zeros((1,2))\n",
    "# short_merger_t90=[]\n",
    "# short_merger_t90_err=[]\n",
    "# short_merger_Epeak_over_s=[]\n",
    "# long_collapsar_HR=[]\n",
    "# long_collapsar_HR_err=np.zeros((1,2))\n",
    "# long_collapsar_t90=[]\n",
    "# long_collapsar_t90_err=[]\n",
    "# long_collapsar_Epeak_over_s=[]\n",
    "# short_collapsar_HR=[]\n",
    "# short_collapsar_HR_err=np.zeros((1,2))\n",
    "# short_collapsar_t90=[]\n",
    "# short_collapsar_t90_err=[]\n",
    "# short_collapsar_Epeak_over_s=[]\n",
    "# exotic_HR=[]\n",
    "# exotic_HR_err=np.zeros((1,2))\n",
    "# exotic_t90=[]\n",
    "# exotic_t90_err=[]\n",
    "# exotic_Epeak_over_s=[]\n",
    "# Initial_Goldstein_Data=np.zeros((len(sample_2_data)+1,4))\n",
    "# p=0\n",
    "# nbins=51\n",
    "# lc_mask=np.isin(sample_2_data['name        '], Fermi_Precursors[\"Long Collapsars\"])\n",
    "# lc_sample_2_data=sample_2_data[lc_mask]\n",
    "# for i in lc_sample_2_data.index.to_list():\n",
    "#     long_collapsar_HR=np.append(long_collapsar_HR, Fermi_HR_func(sample_2_data, \\\n",
    "#                                 sample_2_data.at[i, 'flnc_best_fitting_model'], i))\n",
    "#     long_collapsar_t90=np.append(long_collapsar_t90, float(sample_2_data.at[i, 't90     ']))\n",
    "#     long_collapsar_Epeak_over_s=np.append(long_collapsar_Epeak_over_s, \\\n",
    "#                         (getting_the_GBM_E_peak(sample_2_data, \\\n",
    "#                                     sample_2_data.at[i, 'flnc_best_fitting_model'], i))/\\\n",
    "#                                        float(sample_2_data.at[i, 'fluence   ']))\n",
    "#     Initial_Goldstein_Data[p,0]=sample_2_data.at[i, 'name        '][3:]\n",
    "#     Initial_Goldstein_Data[p,1]=long_collapsar_Epeak_over_s[-1]\n",
    "#     Initial_Goldstein_Data[p,2]=long_collapsar_HR[-1]\n",
    "#     Initial_Goldstein_Data[p,3]=long_collapsar_t90[-1]\n",
    "#     p=p+1\n",
    "# print(p)\n",
    "# long_collapsar_t90_err=np.where(lc_sample_2_data['t90_error'] != 'N/A', \\\n",
    "#         lc_sample_2_data['t90_error'], 0)\n",
    "# if len(long_collapsar_t90_err)>0:\n",
    "#     for j in range(0, len(long_collapsar_t90_err)):\n",
    "#         long_collapsar_t90_err[j]=float(long_collapsar_t90_err[j])\n",
    "# sc_mask=np.isin(sample_2_data['name        '], \\\n",
    "#                 Fermi_Precursors[\"Short Collapsars\"])\n",
    "# sc_sample_2_data=sample_2_data[sc_mask]\n",
    "# for i in sc_sample_2_data.index.to_list():\n",
    "#     short_collapsar_HR=np.append(short_collapsar_HR, Fermi_HR_func(sample_2_data, \\\n",
    "#                                 sample_2_data.at[i, 'flnc_best_fitting_model'], i))\n",
    "#     short_collapsar_t90=np.append(short_collapsar_t90, \\\n",
    "#                                   float(sample_2_data.at[i, 't90     ']))\n",
    "#     short_collapsar_Epeak_over_s=np.append(short_collapsar_Epeak_over_s, \\\n",
    "#                         (getting_the_GBM_E_peak(sample_2_data, \\\n",
    "#                                 sample_2_data.at[i, 'flnc_best_fitting_model'], i))/\\\n",
    "#                                        float(sample_2_data.at[i, 'fluence   ']))\n",
    "#     Initial_Goldstein_Data[p,0]=sample_2_data.at[i, 'name        '][3:]\n",
    "#     Initial_Goldstein_Data[p,1]=short_collapsar_Epeak_over_s[-1]\n",
    "#     Initial_Goldstein_Data[p,2]=short_collapsar_HR[-1]\n",
    "#     Initial_Goldstein_Data[p,3]=short_collapsar_t90[-1]\n",
    "#     p=p+1\n",
    "# print(p)\n",
    "# short_collapsar_t90_err=np.where(sc_sample_2_data['t90_error'] != 'N/A', \\\n",
    "#         sc_sample_2_data['t90_error'], 0)\n",
    "# if len(short_collapsar_t90_err)>0:\n",
    "#     for j in range(0, len(short_collapsar_t90_err)):\n",
    "#         short_collapsar_t90_err[j]=float(short_collapsar_t90_err[j])\n",
    "# lm_mask=np.isin(sample_2_data['name        '], \\\n",
    "#                 Fermi_Precursors[\"Long Mergers\"])\n",
    "# lm_sample_2_data=sample_2_data[lm_mask]\n",
    "# for i in lm_sample_2_data.index.to_list():\n",
    "#     long_merger_HR=np.append(long_merger_HR, Fermi_HR_func(sample_2_data, \\\n",
    "#                                 sample_2_data.at[i, 'flnc_best_fitting_model'], i))\n",
    "#     long_merger_t90=np.append(long_merger_t90, float(sample_2_data.at[i, 't90     ']))\n",
    "#     long_merger_Epeak_over_s=np.append(long_merger_Epeak_over_s, \\\n",
    "#                         (getting_the_GBM_E_peak(sample_2_data, \\\n",
    "#                                 sample_2_data.at[i, 'flnc_best_fitting_model'], i))/\\\n",
    "#                                        float(sample_2_data.at[i, 'fluence   ']))\n",
    "#     Initial_Goldstein_Data[p,0]=sample_2_data.at[i, 'name        '][3:]\n",
    "#     Initial_Goldstein_Data[p,1]=long_merger_Epeak_over_s[-1]\n",
    "#     Initial_Goldstein_Data[p,2]=long_merger_HR[-1]\n",
    "#     Initial_Goldstein_Data[p,3]=long_merger_t90[-1]\n",
    "#     p=p+1\n",
    "# print(p)\n",
    "# long_merger_t90_err=np.where(lm_sample_2_data['t90_error'] != 'N/A', \\\n",
    "#         lm_sample_2_data['t90_error'], 0)\n",
    "# if len(long_merger_t90_err)>0:\n",
    "#     for j in range(0, len(long_merger_t90_err)):\n",
    "#         long_merger_t90_err[j]=float(long_merger_t90_err[j])\n",
    "# sm_mask=np.isin(sample_2_data['name        '], \\\n",
    "#                 Fermi_Precursors[\"Short Mergers\"])\n",
    "# sm_sample_2_data=sample_2_data[sm_mask]\n",
    "# for i in sm_sample_2_data.index.to_list():\n",
    "#     short_merger_HR=np.append(short_merger_HR, Fermi_HR_func(sample_2_data, \\\n",
    "#                                 sample_2_data.at[i, 'flnc_best_fitting_model'], i))\n",
    "#     short_merger_t90=np.append(short_merger_t90, float(sample_2_data.at[i, 't90     ']))\n",
    "#     short_merger_Epeak_over_s=np.append(short_merger_Epeak_over_s, \\\n",
    "#                        (getting_the_GBM_E_peak(sample_2_data, \n",
    "#                             sample_2_data.at[i, 'flnc_best_fitting_model'], i))/\\\n",
    "#                                        float(sample_2_data.at[i, 'fluence   ']))\n",
    "#     Initial_Goldstein_Data[p,0]=sample_2_data.at[i, 'name        '][3:]\n",
    "#     Initial_Goldstein_Data[p,1]=short_merger_Epeak_over_s[-1]\n",
    "#     Initial_Goldstein_Data[p,2]=short_merger_HR[-1]\n",
    "#     Initial_Goldstein_Data[p,3]=short_merger_t90[-1]\n",
    "#     p=p+1\n",
    "# print(p)\n",
    "# short_merger_t90_err=np.where(sm_sample_2_data['t90_error'] != 'N/A', \\\n",
    "#         sm_sample_2_data['t90_error'], 0)\n",
    "# if len(short_merger_t90_err)>0:\n",
    "#     for j in range(0, len(short_merger_t90_err)):\n",
    "#         short_merger_t90_err[j]=float(short_merger_t90_err[j])\n",
    "# exo_mask=np.isin(sample_2_data['name        '], \\\n",
    "#                 Fermi_Precursors[\"Potentially Exotic\"])\n",
    "# exo_sample_2_data=sample_2_data[exo_mask]\n",
    "# for i in exo_sample_2_data.index.to_list():\n",
    "#     exotic_HR=np.append(exotic_HR, Fermi_HR_func(sample_2_data, \\\n",
    "#                                 sample_2_data.at[i, 'flnc_best_fitting_model'], i))\n",
    "#     exotic_t90=np.append(exotic_t90, float(sample_2_data.at[i, 't90     ']))\n",
    "#     exotic_Epeak_over_s=np.append(exotic_Epeak_over_s, \\\n",
    "#                        (getting_the_GBM_E_peak(sample_2_data, sample_2_data.at[i, 'flnc_best_fitting_model'], i))/\\\n",
    "#                                        float(sample_2_data.at[i, 'fluence   ']))\n",
    "#     Initial_Goldstein_Data[p,0]=sample_2_data.at[i, 'name        '][3:]\n",
    "#     Initial_Goldstein_Data[p,1]=exotic_Epeak_over_s[-1]\n",
    "#     Initial_Goldstein_Data[p,2]=exotic_HR[-1]\n",
    "#     Initial_Goldstein_Data[p,3]=exotic_t90[-1]\n",
    "#     p=p+1\n",
    "# print(p)\n",
    "# exotic_t90_err=np.where(exo_sample_2_data['t90_error'] != 'N/A', \\\n",
    "#         exo_sample_2_data['t90_error'], 0)\n",
    "# if len(exotic_t90_err)>0:\n",
    "#     for j in range(0, len(exotic_t90_err)):\n",
    "#         exotic_t90_err[j]=float(exotic_t90_err[j])\n",
    "# unknown_progenitor_sample_2_data=sample_2_data[~(lm_mask|lc_mask|sm_mask|sc_mask|exo_mask)]\n",
    "# for i in unknown_progenitor_sample_2_data.index.to_list():\n",
    "#     unknown_progenitor_HR=np.append(unknown_progenitor_HR, Fermi_HR_func(sample_2_data, \\\n",
    "#                                 sample_2_data.at[i, 'flnc_best_fitting_model'], i))\n",
    "#     unknown_progenitor_t90=np.append(unknown_progenitor_t90, float(unknown_progenitor_sample_2_data.at[i, 't90     ']))\n",
    "#     unknown_progenitor_Epeak_over_s=np.append(unknown_progenitor_Epeak_over_s, \\\n",
    "#                        (getting_the_GBM_E_peak(sample_2_data, sample_2_data.at[i, 'flnc_best_fitting_model'], i))/\\\n",
    "#                                        float(sample_2_data.at[i, 'fluence   ']))\n",
    "#     Initial_Goldstein_Data[p,0]=sample_2_data.at[i, 'name        '][3:]\n",
    "#     Initial_Goldstein_Data[p,1]=unknown_progenitor_Epeak_over_s[-1]\n",
    "#     Initial_Goldstein_Data[p,2]=unknown_progenitor_HR[-1]\n",
    "#     Initial_Goldstein_Data[p,3]=unknown_progenitor_t90[-1]\n",
    "#     p=p+1\n",
    "# print(p)\n",
    "# unknown_progenitor_t90_err=np.where(unknown_progenitor_sample_2_data['t90_error'] != 'N/A', \\\n",
    "#         unknown_progenitor_sample_2_data['t90_error'], 0)\n",
    "# if len(unknown_progenitor_t90_err)>0:\n",
    "#     for j in range(0, len(unknown_progenitor_t90_err)):\n",
    "#         unknown_progenitor_t90_err[j]=float(unknown_progenitor_t90_err[j])\n",
    "# bins=np.logspace(np.log10(0.01),np.log10(1000), nbins)\n",
    "# plt.hist(unknown_progenitor_t90, bins=bins)\n",
    "# plt.hist(long_collapsar_t90, bins=bins)\n",
    "# plt.hist(long_merger_t90, bins=bins)\n",
    "# plt.hist(short_collapsar_t90, bins=bins)\n",
    "# plt.hist(short_merger_t90, bins=bins)\n",
    "# # plt.hist(exotic_t90, bins=bins)\n",
    "# plt.xscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.8')\n",
    "# plt.tick_params(axis='y', colors='0.8')\n",
    "# plt.legend(['Unknown Progenitor', 'Long Collapsars', 'Long Mergers', 'Short Collapsars',\\\n",
    "#             'Short Mergers'])#, 'Exotic'])\n",
    "# plt.xlabel(\"t90 (s)\", color=\"0.8\")\n",
    "# plt.ylabel(\"Number of Bursts\", color=\"0.8\")\n",
    "# plt.show()\n",
    "# print(\"There are {} known long collapsars, {} known long \\\n",
    "# mergers, {} known short mergers, {} known short collapsars, and \\\n",
    "# {} known exotic GRBs in Sample 2.\".\\\n",
    "# format(len(long_collapsar_t90), len(long_merger_t90), \\\n",
    "#        len(short_merger_t90), len(short_collapsar_t90), len(exotic_t90)))\n",
    "# print('There are {}/{} bursts in total'.format(np.count_nonzero(~np.isnan(long_collapsar_HR))\\\n",
    "#         +np.count_nonzero(~np.isnan(long_merger_HR))+\\\n",
    "#         np.count_nonzero(~np.isnan(short_merger_HR))+\\\n",
    "#         np.count_nonzero(~np.isnan(short_collapsar_HR))+\\\n",
    "#         np.count_nonzero(~np.isnan(exotic_HR))+np.count_nonzero(~np.isnan(unknown_progenitor_HR)), \\\n",
    "#                                               len(sample_2_data)))\n",
    "# plt.errorbar(x=unknown_progenitor_t90, y=unknown_progenitor_HR,\\\n",
    "# #              yerr=np.transpose(unknown_progenitor_HR_err),\\\n",
    "# #              xerr=unknown_progenitor_t90_err, \\\n",
    "#              marker=\".\", ls='none')\n",
    "# plt.errorbar(x=long_collapsar_t90, y=long_collapsar_HR, \\\n",
    "# #              yerr=np.transpose(long_collapsar_HR_err), \\\n",
    "# #              xerr=long_collapsar_t90_err,\\\n",
    "#              marker=\"o\",ls='none')\n",
    "# plt.errorbar(x=long_merger_t90, y=long_merger_HR, \\\n",
    "# #              yerr=np.transpose(long_merger_HR_err),\\\n",
    "# #              xerr=long_merger_t90_err,\\\n",
    "#              marker=\"*\", ls='none')\n",
    "# plt.errorbar(x=short_collapsar_t90, y=short_collapsar_HR, \\\n",
    "# #              yerr=np.transpose(short_collapsar_HR_err),\\\n",
    "# #              xerr=short_collapsar_t90_err,\\\n",
    "#              marker=\"^\", ls='none')\n",
    "# plt.errorbar(x=short_merger_t90, y=short_merger_HR, \\\n",
    "# #              yerr=np.transpose(short_merger_HR_err), \\\n",
    "# #              xerr=short_merger_t90_err, \\\n",
    "#              marker=\"+\", ls='none')\n",
    "# # plt.errorbar(x=exotic_t90, y=exotic_HR, yerr=np.transpose(exotic_HR_err), \\\n",
    "# #              xerr=exotic_t90_err, marker=\"o\", ls='none')\n",
    "# plt.axis([0.001, 1000, 1e-4, 10])\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.8')\n",
    "# plt.tick_params(axis='y', colors='0.8')\n",
    "# plt.legend(['Unknown Progenitor', 'Long Collapsars', 'Long Mergers', 'Short Collapsars', \\\n",
    "#             'Short Mergers'])\n",
    "# plt.xlabel(\"t90 (s)\", color=\"0.8\")\n",
    "# plt.ylabel(\"Hardness Ratio\", color=\"0.8\")\n",
    "# plt.show()\n",
    "\n",
    "# new_bins=np.logspace(5,13, 81)\n",
    "# plt.hist(unknown_progenitor_Epeak_over_s, bins=new_bins)\n",
    "# plt.hist(long_collapsar_Epeak_over_s, bins=new_bins)\n",
    "# plt.hist(long_merger_Epeak_over_s, bins=new_bins)\n",
    "# # plt.hist(short_collapsar_Epeak_over_s, bins=new_bins)\n",
    "# plt.hist(short_merger_Epeak_over_s, bins=new_bins)\n",
    "# # plt.hist(exotic_t90, bins=bins)\n",
    "# plt.xscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.8')\n",
    "# plt.tick_params(axis='y', colors='0.8')\n",
    "# plt.legend(['Unknown', 'Long Collapsars', 'Long Mergers', 'Short Mergers'])#, 'Exotic'])\n",
    "# plt.xlabel(r\"$E_{peak}$/$Fluence_{10-1000keV}$ cm^2\", color=\"0.8\")\n",
    "# plt.ylabel(\"Number of Bursts\", color=\"0.8\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(unknown_progenitor_t90, unknown_progenitor_Epeak_over_s, marker=\".\", ls='none')\n",
    "# plt.plot(long_collapsar_t90, long_collapsar_Epeak_over_s, marker=\".\", ls='none')\n",
    "# plt.plot(long_merger_t90, long_merger_Epeak_over_s, marker=\".\", ls='none')\n",
    "# plt.plot(short_collapsar_t90, short_collapsar_Epeak_over_s, marker=\".\", ls='none')\n",
    "# plt.plot(short_merger_t90, short_merger_Epeak_over_s, marker=\".\", ls='none')\n",
    "# # plt.plot(exotic_t90, bins=bins, marker=\".\", ls='none')\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.8')\n",
    "# plt.tick_params(axis='y', colors='0.8')\n",
    "# plt.legend(['Unknown Progenitor', 'Long Collapsars', 'Long Mergers',\\\n",
    "#             'Short  Collapsars', 'Short Mergers'])#, 'Exotic'])\n",
    "# plt.ylabel(r\"$E_{peak}$/$Fluence_{10-1000keV}$ cm^2\", color=\"0.8\")\n",
    "# plt.xlabel(\"t90 (s)\", color=\"0.8\")\n",
    "# plt.axis([0.001, 1000, 1e5, 1e13])\n",
    "# plt.show()\n",
    "# Goldstein_Sample_2_Data=pd.DataFrame(Initial_Goldstein_Data, columns=[\"Name\",\\\n",
    "#                                         \"Peak E. over Flue.\", \"Hardness Ratio\", \"t90\"])\n",
    "# Goldstein_Sample_2_Data.to_excel(\"Goldstein_Sample_2_Data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8164470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Sample 3 Diagnositics##\n",
    "# #unknown_progenitor_edited_fermi_data=fermi_data\n",
    "# swift_unknown_progenitor_HR=[]\n",
    "# swift_unknown_progenitor_HR_err=np.zeros((1,2))\n",
    "# fermi_unknown_progenitor_HR=[]\n",
    "# fermi_unknown_progenitor_HR_err=np.zeros((1,2))\n",
    "# swift_unknown_progenitor_t90=[]\n",
    "# swift_unknown_progenitor_t90_err=[]\n",
    "# unknown_progenitor_t90=[]\n",
    "# unknown_progenitor_t90_err=[]\n",
    "# unknown_progenitor_Epeak_over_s=[]\n",
    "# swift_long_merger_HR=[]\n",
    "# swift_long_merger_HR_err=np.zeros((1,2))\n",
    "# fermi_long_merger_HR=[]\n",
    "# fermi_long_merger_HR_err=np.zeros((1,2))\n",
    "# long_merger_t90=[]\n",
    "# long_merger_t90_err=[]\n",
    "# long_merger_Epeak_over_s=[]\n",
    "# swift_short_merger_HR=[]\n",
    "# swift_short_merger_HR_err=np.zeros((1,2))\n",
    "# fermi_short_merger_HR=[]\n",
    "# fermi_short_merger_HR_err=np.zeros((1,2))\n",
    "# swift_short_merger_t90=[]\n",
    "# swift_short_merger_t90_err=[]\n",
    "# short_merger_t90=[]\n",
    "# short_merger_t90_err=[]\n",
    "# short_merger_Epeak_over_s=[]\n",
    "# swift_long_collapsar_HR=[]\n",
    "# swift_long_collapsar_HR_err=np.zeros((1,2))\n",
    "# fermi_long_collapsar_HR=[]\n",
    "# fermi_long_collapsar_HR_err=np.zeros((1,2))\n",
    "# swift_long_collapsar_t90=[]\n",
    "# swift_long_collapsar_t90_err=[]\n",
    "# long_collapsar_t90=[]\n",
    "# long_collapsar_t90_err=[]\n",
    "# long_collapsar_Epeak_over_s=[]\n",
    "# swift_short_collapsar_HR=[]\n",
    "# swift_short_collapsar_HR_err=np.zeros((1,2))\n",
    "# fermi_short_collapsar_HR=[]\n",
    "# fermi_short_collapsar_HR_err=np.zeros((1,2))\n",
    "# short_collapsar_t90=[]\n",
    "# short_collapsar_t90_err=[]\n",
    "# short_collapsar_Epeak_over_s=[]\n",
    "# swift_exotic_HR=[]\n",
    "# swift_exotic_HR_err=np.zeros((1,2))\n",
    "# fermi_exotic_HR=[]\n",
    "# fermi_exotic_HR_err=np.zeros((1,2))\n",
    "# exotic_t90=[]\n",
    "# exotic_t90_err=[]\n",
    "# exotic_Epeak_over_s=[]\n",
    "# swift_isolated_HR=[]\n",
    "# swift_isolated_HR_err=np.zeros((1,2))\n",
    "# fermi_isolated_HR=[]\n",
    "# fermi_isolated_HR_err=np.zeros((1,2))\n",
    "# isolated_t90=[]\n",
    "# isolated_t90_err=[]\n",
    "# swift_isolated_t90=[]\n",
    "# swift_isolated_t90_err=[]\n",
    "# isolated_Epeak_over_s=[]\n",
    "# nbins=51\n",
    "# lc_mask=np.isin(sample_3_data['name'], \\\n",
    "#                 Overlap_Precursors[\"Long Collapsars\"])\n",
    "# lc_sample_3_data=sample_3_data[lc_mask]\n",
    "# for i in lc_sample_3_data.index.to_list():\n",
    "#     if valid_fluences.at[int(sample_3_data.at[i, 'Swift row']), ' 25_50kev '] != ' N/A '\\\n",
    "#         and valid_fluences.at[int(sample_3_data.at[i, 'Swift row']),' 25_50kev '] != ' N/A ':\n",
    "#         swift_long_collapsar_HR=np.append(swift_long_collapsar_HR, \\\n",
    "#             float(valid_fluences.at[int(sample_3_data.at[i, 'Swift row']), ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[int(sample_3_data.at[i, 'Swift row']),\\\n",
    "#                                                     ' 25_50kev ']))\n",
    "#         swift_long_collapsar_t90=np.append(swift_long_collapsar_t90, \\\n",
    "#                                            float(edited_swift_data.at[\\\n",
    "#                                         int(sample_3_data.at[i, 'Swift row']), \\\n",
    "#                                                                     '     T90      ']))\n",
    "#     else: \n",
    "#         swift_long_collapsar_HR=np.append(swift_long_collapsar_HR, np.NaN)\n",
    "#         swift_long_collapsar_t90=np.append(swift_long_collapsar_t90, np.NaN)\n",
    "#     if edited_swift_data.at[int(sample_3_data.at[i, 'Swift row']), '   T90_err    '] !=\\\n",
    "#     'N/A':\n",
    "#         swift_long_collapsar_t90_err = np.append(swift_long_collapsar_t90_err, \\\n",
    "#             edited_swift_data.at[int(sample_3_data.at[i, 'Swift row']), '   T90_err    '])\n",
    "#     else: \n",
    "#         swift_long_collapsar_t90_err = np.append(swift_long_collapsar_t90_err, 0)\n",
    "#     fermi_long_collapsar_HR=np.append(fermi_long_collapsar_HR, Fermi_HR_func(sample_2_data, \\\n",
    "#                                 sample_3_data.at[i, 'Spectral Model'], \\\n",
    "#                                             int(sample_3_data.at[i, 'Fermi row'])))\n",
    "#     long_collapsar_t90=np.append(long_collapsar_t90, \\\n",
    "#                                  float(lc_sample_3_data.at[i, 't90']))\n",
    "#     swift_long_collapsar_HR_err=np.append(swift_long_collapsar_HR_err,\\\n",
    "#         [swift_error_calculator(int(sample_3_data.at[i, 'Swift row']), valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "#     long_collapsar_Epeak_over_s=np.append(long_collapsar_Epeak_over_s, \\\n",
    "#                         (getting_the_GBM_E_peak(sample_2_data, \\\n",
    "#                                     sample_3_data.at[i, 'Spectral Model'], \\\n",
    "#                                                 sample_3_data.at[i, 'Fermi row']))/\\\n",
    "#                                        float(sample_3_data.at[i, 'GBM fluence']))\n",
    "# long_collapsar_t90_err=np.where(lc_sample_3_data['t90_error'] != 'N/A', \\\n",
    "#         lc_sample_3_data['t90_error'], 0)\n",
    "# # print(swift_long_collapsar_t90_err)\n",
    "# # print(long_collapsar_t90_err)\n",
    "# if len(long_collapsar_t90_err)>0:\n",
    "#     for j in range(0, len(long_collapsar_t90_err)):\n",
    "#         long_collapsar_t90_err[j]=float(long_collapsar_t90_err[j])\n",
    "#         hold_this=swift_long_collapsar_t90_err[j].strip()\n",
    "#         swift_long_collapsar_t90_err[j]=float(hold_this)\n",
    "# # print(swift_long_collapsar_t90_err)\n",
    "# # print(long_collapsar_t90_err)\n",
    "        \n",
    "# sc_mask=np.isin(sample_3_data['name'], \\\n",
    "#                 Overlap_Precursors[\"Short Collapsars\"])\n",
    "# sc_sample_3_data=sample_3_data[sc_mask]\n",
    "# for i in sc_sample_3_data.index.to_list():\n",
    "#     if valid_fluences.at[int(sample_3_data.at[i, 'Swift row']), ' 25_50kev '] != ' N/A '\\\n",
    "#         and valid_fluences.at[int(sample_3_data.at[i, 'Swift row']),' 25_50kev '] != ' N/A ':\n",
    "#         swift_short_collapsar_HR=np.append(swift_short_collapsar_HR, \\\n",
    "#             float(valid_fluences.at[int(sample_3_data.at[i, 'Swift row']), ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[int(sample_3_data.at[i, 'Swift row']),\\\n",
    "#                                                     ' 25_50kev ']))\n",
    "#         swift_short_collapsar_t90=np.append(swift_short_collapsar_t90, \\\n",
    "#                                            float(edited_swift_data.at[\\\n",
    "#                                         int(sample_3_data.at[i, 'Swift row']), \\\n",
    "#                                                                     '     T90      ']))\n",
    "#     else: \n",
    "#         swift_short_collapsar_HR=np.append(swift_short_collapsar_HR, np.NaN)\n",
    "#         swift_short_collapsar_t90=np.append(swift_short_collapsar_t90, np.NaN)\n",
    "#     if edited_swift_data.at[int(sample_3_data.at[i, 'Swift row']), '   T90_err    '] !=\\\n",
    "#     'N/A':\n",
    "#         swift_short_collapsar_t90_err = np.append(swift_short_collapsar_t90_err, \\\n",
    "#             edited_swift_data.at[int(sample_3_data.at[i, 'Swift row']), '   T90_err    '])\n",
    "#     else: \n",
    "#         swift_short_collapsar_t90_err = np.append(swift_short_collapsar_t90_err, 0)\n",
    "#     fermi_short_collapsar_HR=np.append(fermi_short_collapsar_HR, Fermi_HR_func(sample_2_data, \\\n",
    "#                                 sample_3_data.at[i, 'Spectral Model'], \\\n",
    "#                                             int(sample_3_data.at[i, 'Fermi row'])))\n",
    "#     short_collapsar_t90=np.append(short_collapsar_t90, \\\n",
    "#                                  float(sc_sample_3_data.at[i, 't90']))\n",
    "#     swift_short_collapsar_HR_err=np.append(swift_short_collapsar_HR_err,\\\n",
    "#         [swift_error_calculator(int(sample_3_data.at[i, 'Swift row']), valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "#     short_collapsar_Epeak_over_s=np.append(short_collapsar_Epeak_over_s, \\\n",
    "#                         (getting_the_GBM_E_peak(sample_2_data, \\\n",
    "#                                     sample_3_data.at[i, 'Spectral Model'], \\\n",
    "#                                                sample_3_data.at[i, 'Fermi row']))/\\\n",
    "#                                        float(sample_3_data.at[i, 'GBM fluence']))\n",
    "# short_collapsar_t90_err=np.where(sc_sample_3_data['t90_error'] != 'N/A', \\\n",
    "#         sc_sample_3_data['t90_error'], 0)\n",
    "# if len(short_collapsar_t90_err)>0:\n",
    "#     for j in range(0, len(short_collapsar_t90_err)):\n",
    "#         short_collapsar_t90_err[j]=float(short_collapsar_t90_err[j])\n",
    "#         swift_short_collapsar_t90_err[j]=float(swift_short_collapsar_t90_err[j])\n",
    "        \n",
    "# lm_mask=np.isin(sample_3_data['name'], \\\n",
    "#                 Overlap_Precursors[\"Long Mergers\"])\n",
    "# lm_sample_3_data=sample_3_data[lm_mask]\n",
    "# for i in lm_sample_3_data.index.to_list():\n",
    "#     if valid_fluences.at[int(sample_3_data.at[i, 'Swift row']), ' 25_50kev '] != ' N/A '\\\n",
    "#         and valid_fluences.at[int(sample_3_data.at[i, 'Swift row']),' 25_50kev '] != ' N/A ':\n",
    "#         swift_long_merger_HR=np.append(swift_long_merger_HR, \\\n",
    "#             float(valid_fluences.at[int(sample_3_data.at[i, 'Swift row']), ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[int(sample_3_data.at[i, 'Swift row']),\\\n",
    "#                                                     ' 25_50kev ']))\n",
    "#         swift_long_merger_t90=np.append(swift_long_merger_t90, \\\n",
    "#                                            float(edited_swift_data.at[\\\n",
    "#                                         int(sample_3_data.at[i, 'Swift row']), \\\n",
    "#                                                                     '     T90      ']))\n",
    "#     else: \n",
    "#         swift_long_merger_HR=np.append(swift_long_merger_HR, np.NaN)\n",
    "#         swift_long_merger_t90=np.append(swift_long_merger_t90, np.NaN)\n",
    "#     if edited_swift_data.at[int(sample_3_data.at[i, 'Swift row']), '   T90_err    '] !=\\\n",
    "#     'N/A':\n",
    "#         swift_long_merger_t90_err = np.append(swift_long_merger_t90_err, \\\n",
    "#             edited_swift_data.at[int(sample_3_data.at[i, 'Swift row']), '   T90_err    '])\n",
    "#     else: \n",
    "#         swift_long_merger_t90_err = np.append(swift_long_merger_t90_err, 0)\n",
    "#     fermi_long_merger_HR=np.append(fermi_long_merger_HR, Fermi_HR_func(sample_2_data, \\\n",
    "#                                 sample_3_data.at[i, 'Spectral Model'], \\\n",
    "#                                             int(sample_3_data.at[i, 'Fermi row'])))\n",
    "#     long_merger_t90=np.append(long_merger_t90, \\\n",
    "#                                  float(lm_sample_3_data.at[i, 't90']))\n",
    "#     swift_long_merger_HR_err=np.append(swift_long_merger_HR_err,\\\n",
    "#         [swift_error_calculator(int(sample_3_data.at[i, 'Swift row']), valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "#     long_merger_Epeak_over_s=np.append(long_merger_Epeak_over_s, \\\n",
    "#                         (getting_the_GBM_E_peak(sample_2_data, \\\n",
    "#                                     sample_3_data.at[i, 'Spectral Model'], \\\n",
    "#                                                sample_3_data.at[i, 'Fermi row']))/\\\n",
    "#                                        float(sample_3_data.at[i, 'GBM fluence']))\n",
    "#     long_merger_Epeak_over_s[-1]\n",
    "# long_merger_t90_err=np.where(lm_sample_3_data['t90_error'] != 'N/A', \\\n",
    "#         lm_sample_3_data['t90_error'], 0)\n",
    "# if len(long_merger_t90_err)>0:\n",
    "#     for j in range(0, len(long_merger_t90_err)):\n",
    "#         long_merger_t90_err[j]=float(long_merger_t90_err[j])\n",
    "#         swift_long_merger_t90_err[j]=float(swift_long_merger_t90_err[j])\n",
    "\n",
    "# sm_mask=np.isin(sample_3_data['name'], \\\n",
    "#                 Overlap_Precursors[\"Short Mergers\"])\n",
    "# sm_sample_3_data=sample_3_data[sm_mask]\n",
    "# for i in sm_sample_3_data.index.to_list():\n",
    "#     if valid_fluences.at[int(sample_3_data.at[i, 'Swift row']), ' 25_50kev '] != ' N/A '\\\n",
    "#         and valid_fluences.at[int(sample_3_data.at[i, 'Swift row']),' 25_50kev '] != ' N/A ':\n",
    "#         swift_short_merger_HR=np.append(swift_short_merger_HR, \\\n",
    "#             float(valid_fluences.at[int(sample_3_data.at[i, 'Swift row']), ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[int(sample_3_data.at[i, 'Swift row']),\\\n",
    "#                                                     ' 25_50kev ']))\n",
    "#         swift_short_merger_t90=np.append(swift_short_merger_t90, \\\n",
    "#                                            float(edited_swift_data.at[\\\n",
    "#                                         int(sample_3_data.at[i, 'Swift row']), \\\n",
    "#                                                                     '     T90      ']))\n",
    "#     else: \n",
    "#         swift_short_merger_HR=np.append(swift_short_merger_HR, np.NaN)\n",
    "#         swift_short_merger_t90=np.append(swift_short_merger_t90, np.NaN)\n",
    "#     if edited_swift_data.at[int(sample_3_data.at[i, 'Swift row']), '   T90_err    '] !=\\\n",
    "#     'N/A':\n",
    "#         swift_short_merger_t90_err = np.append(swift_short_merger_t90_err, \\\n",
    "#             edited_swift_data.at[int(sample_3_data.at[i, 'Swift row']), '   T90_err    '])\n",
    "#     else: \n",
    "#         swift_short_merger_t90_err = np.append(swift_short_merger_t90_err, 0)\n",
    "#     fermi_short_merger_HR=np.append(fermi_short_merger_HR, Fermi_HR_func(sample_2_data, \\\n",
    "#                                 sample_3_data.at[i, 'Spectral Model'], \\\n",
    "#                                             int(sample_3_data.at[i, 'Fermi row'])))\n",
    "#     short_merger_t90=np.append(short_merger_t90, \\\n",
    "#                                  float(sm_sample_3_data.at[i, 't90']))\n",
    "#     swift_short_merger_HR_err=np.append(swift_short_merger_HR_err,\\\n",
    "#         [swift_error_calculator(int(sample_3_data.at[i, 'Swift row']), valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "#     short_merger_Epeak_over_s=np.append(short_merger_Epeak_over_s, \\\n",
    "#                         (getting_the_GBM_E_peak(sample_2_data, \\\n",
    "#                                     sample_3_data.at[i, 'Spectral Model'], \\\n",
    "#                                                sample_3_data.at[i, 'Fermi row']))/\\\n",
    "#                                        float(sample_3_data.at[i, 'GBM fluence']))\n",
    "# short_merger_t90_err=np.where(sm_sample_3_data['t90_error'] != 'N/A', \\\n",
    "#         sm_sample_3_data['t90_error'], 0)\n",
    "# if len(short_merger_t90_err)>0:\n",
    "#     for j in range(0, len(short_merger_t90_err)):\n",
    "#         short_merger_t90_err[j]=float(short_merger_t90_err[j])\n",
    "#         swift_short_merger_t90_err[j]=float(swift_short_merger_t90_err[j])\n",
    "        \n",
    "# exo_mask=np.isin(sample_3_data['name'], \\\n",
    "#                 Overlap_Precursors[\"Potentially Exotic\"])\n",
    "\n",
    "# iso_mask=np.isin(sample_3_data['name'], \\\n",
    "#                 Overlap_Precursors[\"Galactic Detected\"])\n",
    "# iso_sample_3_data=sample_3_data[iso_mask]\n",
    "# for i in iso_sample_3_data.index.to_list():\n",
    "#     if valid_fluences.at[int(sample_3_data.at[i, 'Swift row']), ' 25_50kev '] != ' N/A '\\\n",
    "#         and valid_fluences.at[int(sample_3_data.at[i, 'Swift row']),' 25_50kev '] != ' N/A ':\n",
    "#         swift_isolated_HR=np.append(swift_isolated_HR, \\\n",
    "#             float(valid_fluences.at[int(sample_3_data.at[i, 'Swift row']), ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[int(sample_3_data.at[i, 'Swift row']),\\\n",
    "#                                                     ' 25_50kev ']))\n",
    "#         swift_isolated_t90=np.append(swift_isolated_t90, \\\n",
    "#                                            float(edited_swift_data.at[\\\n",
    "#                                         int(sample_3_data.at[i, 'Swift row']), \\\n",
    "#                                                                     '     T90      ']))\n",
    "#     else: \n",
    "#         swift_isolated_HR=np.append(swift_isolated_HR, np.NaN)\n",
    "#         swift_isolated_t90=np.append(swift_isolated_t90, np.NaN)\n",
    "#     if edited_swift_data.at[int(sample_3_data.at[i, 'Swift row']), '   T90_err    '] !=\\\n",
    "#     'N/A':\n",
    "#         swift_isolated_t90_err = np.append(swift_isolated_t90_err, \\\n",
    "#             edited_swift_data.at[int(sample_3_data.at[i, 'Swift row']), '   T90_err    '])\n",
    "#     else: \n",
    "#         swift_isolated_t90_err = np.append(swift_isolated_t90_err, 0)\n",
    "#     fermi_isolated_HR=np.append(fermi_isolated_HR, Fermi_HR_func(sample_2_data, \\\n",
    "#                                 sample_3_data.at[i, 'Spectral Model'], \\\n",
    "#                                             int(sample_3_data.at[i, 'Fermi row'])))\n",
    "#     isolated_t90=np.append(isolated_t90, \\\n",
    "#                                  float(iso_sample_3_data.at[i, 't90']))\n",
    "#     swift_isolated_HR_err=np.append(swift_isolated_HR_err,\\\n",
    "#         [swift_error_calculator(int(sample_3_data.at[i, 'Swift row']), valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "#     isolated_Epeak_over_s=np.append(isolated_Epeak_over_s, \\\n",
    "#                         (getting_the_GBM_E_peak(sample_2_data, \\\n",
    "#                                     sample_3_data.at[i, 'Spectral Model'], \\\n",
    "#                                                sample_3_data.at[i, 'Fermi row']))/\\\n",
    "#                                        float(sample_3_data.at[i, 'GBM fluence']))\n",
    "# isolated_t90_err=np.where(iso_sample_3_data['t90_error'] != 'N/A', \\\n",
    "#         iso_sample_3_data['t90_error'], 0)\n",
    "# if len(isolated_t90_err)>0:\n",
    "#     for j in range(0, len(isolated_t90_err)):\n",
    "#         isolated_t90_err[j]=float(isolated_t90_err[j])\n",
    "#         swift_isolated_t90_err[j]=float(swift_isolated_t90_err[j])\n",
    "        \n",
    "# unknown_progenitor_sample_3_data=sample_3_data[~(lm_mask|lc_mask|sm_mask|sc_mask|exo_mask)]\n",
    "# for i in unknown_progenitor_sample_3_data.index.to_list():\n",
    "#     if valid_fluences.at[int(sample_3_data.at[i, 'Swift row']), ' 25_50kev '] != ' N/A '\\\n",
    "#     and valid_fluences.at[int(sample_3_data.at[i, 'Swift row']),' 25_50kev '] != ' N/A ':\n",
    "#         swift_unknown_progenitor_HR=np.append(swift_unknown_progenitor_HR, \\\n",
    "#             float(valid_fluences.at[int(sample_3_data.at[i, 'Swift row']), ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[int(sample_3_data.at[i, 'Swift row']),\\\n",
    "#                                                     ' 25_50kev ']))\n",
    "#         swift_unknown_progenitor_t90=np.append(swift_unknown_progenitor_t90, float(edited_swift_data.at[\\\n",
    "#                                         int(sample_3_data.at[i, 'Swift row']), \\\n",
    "#                                                                     '     T90      ']))\n",
    "#     else: \n",
    "#         swift_unknown_progenitor_HR=np.append(swift_unknown_progenitor_HR, np.NaN)\n",
    "#         swift_unknown_progenitor_t90=np.append(swift_unknown_progenitor_t90, np.NaN)\n",
    "#     if edited_swift_data.at[int(sample_3_data.at[i, 'Swift row']), '   T90_err    '] !=\\\n",
    "#     'N/A':\n",
    "#         swift_unknown_progenitor_t90_err = np.append(swift_unknown_progenitor_t90_err, \\\n",
    "#             edited_swift_data.at[int(sample_3_data.at[i, 'Swift row']), '   T90_err    '])\n",
    "#     else: \n",
    "#         swift_unknown_progenitor_t90_err = np.append(swift_unknown_progenitor_t90_err, 0)\n",
    "#     fermi_unknown_progenitor_HR=np.append(fermi_unknown_progenitor_HR, Fermi_HR_func(sample_2_data, \\\n",
    "#                                 sample_3_data.at[i, 'Spectral Model'], \\\n",
    "#                                             int(sample_3_data.at[i, 'Fermi row'])))\n",
    "#     unknown_progenitor_t90=np.append(unknown_progenitor_t90, \\\n",
    "#                                      float(unknown_progenitor_sample_3_data.at[i, 't90']))\n",
    "    \n",
    "#     swift_unknown_progenitor_HR_err=np.append(swift_unknown_progenitor_HR_err, \\\n",
    "#         [swift_error_calculator(int(sample_3_data.at[i, 'Swift row']), valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "#     unknown_progenitor_Epeak_over_s=np.append(unknown_progenitor_Epeak_over_s, \\\n",
    "#                         (getting_the_GBM_E_peak(sample_2_data, \\\n",
    "#                                     sample_3_data.at[i, 'Spectral Model'], \\\n",
    "#                                                sample_3_data.at[i, 'Fermi row']))/\\\n",
    "#                                        float(sample_3_data.at[i, 'GBM fluence']))\n",
    "# unknown_progenitor_t90_err=np.where(\\\n",
    "#             unknown_progenitor_edited_swift_data[ '   T90_err    '] != 'N/A', \\\n",
    "#         unknown_progenitor_edited_swift_data['   T90_err    '], 0)\n",
    "# unknown_progenitor_t90_err=np.where(\\\n",
    "#             unknown_progenitor_edited_swift_data[ '   T90_err    '] != ' N/A ', \\\n",
    "#         unknown_progenitor_edited_swift_data['   T90_err    '], 0)\n",
    "# unknown_progenitor_t90_err=np.where(unknown_progenitor_sample_3_data['t90_error'] != 'N/A', \\\n",
    "#         unknown_progenitor_sample_3_data['t90_error'], 0)\n",
    "# if len(unknown_progenitor_t90_err)>0:\n",
    "#     for j in range(0, len(unknown_progenitor_t90_err)):\n",
    "#         unknown_progenitor_t90_err[j]=float(unknown_progenitor_t90_err[j])\n",
    "#         swift_unknown_progenitor_t90_err[j]=float(swift_unknown_progenitor_t90_err[j])\n",
    "# swift_unknown_progenitor_HR_err=swift_unknown_progenitor_HR_err[1:]\n",
    "# swift_long_collapsar_HR_err=swift_long_collapsar_HR_err[1:]\n",
    "# swift_short_merger_HR_err=swift_short_merger_HR_err[1:]\n",
    "# swift_isolated_HR_err=swift_isolated_HR_err[1:]\n",
    "# bins=np.logspace(np.log10(0.01),np.log10(1000), nbins)\n",
    "# plt.hist(unknown_progenitor_t90, bins=bins)\n",
    "# plt.hist(long_collapsar_t90, bins=bins)\n",
    "# # plt.hist(long_merger_t90, bins=bins)\n",
    "# # plt.hist(short_collapsar_t90, bins=bins)\n",
    "# plt.hist(short_merger_t90, bins=bins)\n",
    "# # plt.hist(exotic_t90, bins=bins)\n",
    "# plt.hist(isolated_t90, bins=bins)\n",
    "# plt.xscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.5')\n",
    "# plt.tick_params(axis='y', colors='0.5')\n",
    "# plt.legend(['Unknown Progenitor', 'Long Collapsars', 'Short Mergers', \"Isolated GRBs\"])\n",
    "# plt.xlabel(\"t90 (s)\", color=\"0.5\")\n",
    "# plt.ylabel(\"Number of Bursts\", color=\"0.5\")\n",
    "# plt.show()\n",
    "# print(\"There are {} known long collapsars, {} known long \\\n",
    "# mergers, {} known short mergers, {} known short collapsars, \\\n",
    "# {} known exotic, and {} known isolated GRBs in Sample 3.\".\\\n",
    "# format(len(long_collapsar_t90), len(long_merger_t90), \\\n",
    "#        len(short_merger_t90), len(short_collapsar_t90), len(exotic_t90),\\\n",
    "#        len(isolated_t90)))\n",
    "# print('There are {}/{} bursts in total'.format(np.count_nonzero(\\\n",
    "#                                                 ~np.isnan(fermi_long_collapsar_HR))\\\n",
    "#         +np.count_nonzero(~np.isnan(fermi_long_merger_HR))+\\\n",
    "#         np.count_nonzero(~np.isnan(fermi_short_merger_HR))+\\\n",
    "#         np.count_nonzero(~np.isnan(fermi_short_collapsar_HR))+\\\n",
    "#         np.count_nonzero(~np.isnan(fermi_exotic_HR))+\\\n",
    "#         np.count_nonzero(~np.isnan(fermi_isolated_HR))+\\\n",
    "#         np.count_nonzero(~np.isnan(fermi_unknown_progenitor_HR)), \\\n",
    "#                                               len(sample_3_data)))\n",
    "# plt.errorbar(x=swift_unknown_progenitor_t90, y=swift_unknown_progenitor_HR, \\\n",
    "#              yerr=np.transpose(swift_unknown_progenitor_HR_err), \\\n",
    "# #              xerr=unknown_progenitor_t90_err, \n",
    "#              marker=\"o\", color='k', ls='none')\n",
    "# plt.errorbar(x=swift_long_collapsar_t90, y=swift_long_collapsar_HR, \\\n",
    "#              yerr=np.transpose(swift_long_collapsar_HR_err), \\\n",
    "# #              xerr=swift_long_collapsar_t90_err, \n",
    "#              marker=\".\", color='r', ls='none')\n",
    "# plt.errorbar(x=swift_short_merger_t90, y=swift_short_merger_HR, \\\n",
    "#              yerr=np.transpose(swift_short_merger_HR_err), \\\n",
    "# #              xerr=swift_short_merger_t90_err,\n",
    "#              marker=\".\", color='b', ls='none')\n",
    "# plt.errorbar(x=swift_isolated_t90, y=swift_isolated_HR, \\\n",
    "#              yerr=np.transpose(swift_isolated_HR_err), \\\n",
    "# #              xerr=swift_short_merger_t90_err,\n",
    "#              marker=\".\", color='g', ls='none')\n",
    "# plt.axis([0.1, 1000, 1e-1, 10])\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.5')\n",
    "# plt.tick_params(axis='y', colors='0.5')\n",
    "# plt.legend(['Unknown Progenitor', 'Long Collapsar', 'Short Merger', \"Isolated GRBs\"])\n",
    "# plt.xlabel(\"t90 (s)\", color=\"0.5\")\n",
    "# plt.ylabel(\"BAT Hardness Ratio\", color=\"0.5\")\n",
    "# plt.show()\n",
    "# plt.errorbar(x=unknown_progenitor_t90, y=fermi_unknown_progenitor_HR, \\\n",
    "# #              yerr=np.transpose(unknown_progenitor_HR_err), \\\n",
    "#              xerr=unknown_progenitor_t90_err, \\\n",
    "#              marker=\"o\", color='k', ls='none')\n",
    "# plt.errorbar(x=long_collapsar_t90, y=fermi_long_collapsar_HR, \\\n",
    "# #              yerr=np.transpose(long_collapsar_HR_err),\n",
    "#              xerr=long_collapsar_t90_err,\\\n",
    "#              marker=\"o\", ls='none')\n",
    "# # plt.errorbar(x=long_merger_t90, y=long_merger_HR, \\\n",
    "# # #              yerr=np.transpose(long_merger_HR_err), xerr=long_merger_t90_err,\\\n",
    "# #              marker=\"*\", ls='none')\n",
    "# # plt.errorbar(x=short_collapsar_t90, y=short_collapsar_HR, \\\n",
    "# # #              yerr=np.transpose(short_collapsar_HR_err), xerr=short_collapsar_t90_err,\\\n",
    "# #              marker=\"^\", ls='none')\n",
    "# plt.errorbar(x=short_merger_t90, y=fermi_short_merger_HR, \\\n",
    "# #              yerr=np.transpose(short_merger_HR_err), xerr=short_merger_t90_err, \\\n",
    "#              marker=\"+\", ls='none')\n",
    "# # plt.errorbar(x=exotic_t90, y=exotic_HR, yerr=np.transpose(exotic_HR_err), \\\n",
    "# #              xerr=exotic_t90_err, marker=\"o\", ls='none')\n",
    "# plt.errorbar(x=isolated_t90, y=fermi_isolated_HR, \\\n",
    "# #              yerr=np.transpose(short_merger_HR_err), xerr=short_merger_t90_err, \\\n",
    "#              marker=\"*\", ls='none')\n",
    "# plt.axis([0.1, 1000, 0.00025, 250])\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.5')\n",
    "# plt.tick_params(axis='y', colors='0.5')\n",
    "# plt.legend(['Unknown Progenitor', 'Long Collapsar', 'Short Merger', \"Isolated GRBs\"])\n",
    "# plt.xlabel(\"t90 (s)\", color=\"0.5\")\n",
    "# plt.ylabel(\"Fermi Hardness Ratio\", color=\"0.5\")\n",
    "# plt.show()\n",
    "\n",
    "# new_bins=np.logspace(5,13, 81)\n",
    "# plt.hist(unknown_progenitor_Epeak_over_s, bins=new_bins)\n",
    "# plt.hist(long_collapsar_Epeak_over_s, bins=new_bins)\n",
    "# # plt.hist(long_merger_Epeak_over_s, bins=new_bins)\n",
    "# # plt.hist(short_collapsar_Epeak_over_s, bins=new_bins)\n",
    "# plt.hist(short_merger_Epeak_over_s, bins=new_bins)\n",
    "# # plt.hist(exotic_t90, bins=bins)\n",
    "# plt.hist(isolated_Epeak_over_s, bins=new_bins)\n",
    "# plt.xscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.8')\n",
    "# plt.tick_params(axis='y', colors='0.8')\n",
    "# plt.legend(['Unknown Progenitor', 'Long Collapsars', 'Short Merger', \"Isolated GRBs\"])\n",
    "# #, 'Long Collapsars', 'Long Mergers',\\\n",
    "# #             'Short  Collapsars', 'Short Mergers'])#, 'Exotic'])\n",
    "# plt.xlabel(r\"$E_{peak}$/$Fluence_{10-1000keV}$ cm^2\", color=\"0.8\")\n",
    "# plt.ylabel(\"Number of Bursts\", color=\"0.8\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b243f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Sample 4 Diagnositics##\n",
    "# unknown_progenitor_HR=[]\n",
    "# unknown_progenitor_HR_err=np.zeros((1,2))\n",
    "# unknown_progenitor_t90=[]\n",
    "# unknown_progenitor_t90_err=[]\n",
    "# long_merger_HR=[]\n",
    "# long_merger_HR_err=np.zeros((1,2))\n",
    "# long_merger_t90=[]\n",
    "# long_merger_t90_err=[]\n",
    "# short_merger_HR=[]\n",
    "# short_merger_HR_err=np.zeros((1,2))\n",
    "# short_merger_t90=[]\n",
    "# short_merger_t90_err=[]\n",
    "# long_collapsar_HR=[]\n",
    "# long_collapsar_HR_err=np.zeros((1,2))\n",
    "# long_collapsar_t90=[]\n",
    "# long_collapsar_t90_err=[]\n",
    "# short_collapsar_HR=[]\n",
    "# short_collapsar_HR_err=np.zeros((1,2))\n",
    "# short_collapsar_t90=[]\n",
    "# short_collapsar_t90_err=[]\n",
    "# exotic_HR=[]\n",
    "# exotic_HR_err=np.zeros((1,2))\n",
    "# exotic_t90=[]\n",
    "# exotic_t90_err=[]\n",
    "# nbins=51\n",
    "# #\n",
    "# valid_fluences=swift_fluences.drop(index=removals[:-2])\n",
    "# actually_valid_mask=np.isin(valid_fluences.index, (redshift_swift_data.index))\n",
    "# actually_valid_fluences=valid_fluences[actually_valid_mask]\n",
    "# fluence_mask=np.isin(actually_valid_fluences[' 25_50kev '], (\" N/A\", \" N/A \", 0), invert=True)\n",
    "# fluence_available_swift_data=redshift_swift_data[fluence_mask]\n",
    "# good_fluences=actually_valid_fluences[fluence_mask]\n",
    "# half_flu_mask=np.isin(good_fluences[' 25_50kev_low '], (\" N/A\", \" N/A \", 0), invert=True)\n",
    "# almost_err_fluences=good_fluences[half_flu_mask]\n",
    "# other_flu_mask=np.isin(almost_err_fluences[' 25_50kev_hi '], (\" N/A\", \" N/A \", 0), invert=True)\n",
    "# complete_err_fluences=almost_err_fluences[other_flu_mask]\n",
    "# lc_mask=np.isin(fluence_available_swift_data[ \"GRBname \"], \\\n",
    "#                 Known_Precursors[\"Long Collapsars\"])\n",
    "# lc_redshift_swift_data=fluence_available_swift_data[lc_mask]\n",
    "# for i in lc_redshift_swift_data.index.to_list():\n",
    "#     long_collapsar_HR=np.append(long_collapsar_HR, \\\n",
    "#             float(valid_fluences.at[i, ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[i, ' 25_50kev ']))\n",
    "#     long_collapsar_t90=np.append(long_collapsar_t90, float(lc_redshift_swift_data.at[i, \\\n",
    "#                                                                 '     T90      ']))\n",
    "#     long_collapsar_HR_err=np.append(long_collapsar_HR_err, \\\n",
    "#                                     [swift_error_calculator(i, valid_fluences)], axis=0)\n",
    "# long_collapsar_t90_err=np.where(lc_redshift_swift_data[ '   T90_err    '] != 'N/A', \\\n",
    "#         lc_redshift_swift_data['   T90_err    '], 0)\n",
    "# if len(long_collapsar_t90_err)>0:\n",
    "#     for j in range(0, len(long_collapsar_t90_err)):\n",
    "#         long_collapsar_t90_err[j]=float(long_collapsar_t90_err[j])\n",
    "# sc_mask=np.isin(fluence_available_swift_data[ \"GRBname \"], \\\n",
    "#                 Known_Precursors[\"Short Collapsars\"])\n",
    "# sc_redshift_swift_data=fluence_available_swift_data[sc_mask]\n",
    "# for i in sc_redshift_swift_data.index.to_list():\n",
    "#     short_collapsar_HR=np.append(short_collapsar_HR, \\\n",
    "#             float(valid_fluences.at[i, ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[i, ' 25_50kev ']))\n",
    "#     short_collapsar_t90=np.append(short_collapsar_t90, float(sc_redshift_swift_data.at[i, \\\n",
    "#                                                                 '     T90      ']))\n",
    "#     short_collapsar_HR_err=np.append(short_collapsar_HR_err, \\\n",
    "#                                     [swift_error_calculator(i, valid_fluences)], axis=0)\n",
    "# short_collapsar_t90_err=np.where(sc_redshift_swift_data[ '   T90_err    '] != 'N/A', \\\n",
    "#         sc_redshift_swift_data['   T90_err    '], 0)\n",
    "# if len(short_collapsar_t90_err)>0:\n",
    "#     for j in range(0, len(short_collapsar_t90_err)):\n",
    "#         short_collapsar_t90_err[j]=float(short_collapsar_t90_err[j])\n",
    "# lm_mask=np.isin(fluence_available_swift_data[ \"GRBname \"], \\\n",
    "#                 Known_Precursors[\"Long Mergers\"])\n",
    "# lm_redshift_swift_data=fluence_available_swift_data[lm_mask]\n",
    "# for i in lm_redshift_swift_data.index.to_list():\n",
    "#     long_merger_HR=np.append(long_merger_HR, \\\n",
    "#             float(valid_fluences.at[i, ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[i, ' 25_50kev ']))\n",
    "#     long_merger_t90=np.append(long_merger_t90, float(lm_redshift_swift_data.at[i, \\\n",
    "#                                                                 '     T90      ']))\n",
    "#     long_merger_HR_err=np.append(long_merger_HR_err, \\\n",
    "#                                     [swift_error_calculator(i, valid_fluences)], axis=0)\n",
    "# long_merger_t90_err=np.where(lm_redshift_swift_data[ '   T90_err    '] != 'N/A', \\\n",
    "#         lm_redshift_swift_data['   T90_err    '], 0)\n",
    "# if len(long_merger_t90_err)>0:\n",
    "#     for j in range(0, len(long_merger_t90_err)):\n",
    "#         long_merger_t90_err[j]=float(long_merger_t90_err[j])\n",
    "# sm_mask=np.isin(fluence_available_swift_data[ \"GRBname \"], \\\n",
    "#                 Known_Precursors[\"Short Mergers\"])\n",
    "# sm_redshift_swift_data=fluence_available_swift_data[sm_mask]\n",
    "# for i in sm_redshift_swift_data.index.to_list():\n",
    "#     short_merger_HR=np.append(short_merger_HR, \\\n",
    "#             float(valid_fluences.at[i, ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[i, ' 25_50kev ']))\n",
    "#     short_merger_t90=np.append(short_merger_t90, float(sm_redshift_swift_data.at[i, \\\n",
    "#                                                                 '     T90      ']))\n",
    "#     short_merger_HR_err=np.append(short_merger_HR_err, \\\n",
    "#                                     [swift_error_calculator(i, valid_fluences)], axis=0)\n",
    "# short_merger_t90_err=np.where(sm_redshift_swift_data[ '   T90_err    '] != 'N/A', \\\n",
    "#         sm_redshift_swift_data['   T90_err    '], 0)\n",
    "# if len(short_merger_t90_err)>0:\n",
    "#     for j in range(0, len(short_merger_t90_err)):\n",
    "#         short_merger_t90_err[j]=float(short_merger_t90_err[j])\n",
    "# exo_mask=np.isin(fluence_available_swift_data[ \"GRBname \"], \\\n",
    "#                 Known_Precursors[\"Potentially Exotic\"])\n",
    "# exo_redshift_swift_data=fluence_available_swift_data[exo_mask]\n",
    "# for i in exo_redshift_swift_data.index.to_list():\n",
    "#     exotic_HR=np.append(exotic_HR, \\\n",
    "#             float(valid_fluences.at[i, ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[i, ' 25_50kev ']))\n",
    "#     exotic_t90=np.append(exotic_t90, float(exo_redshift_swift_data.at[i, \\\n",
    "#                                                                 '     T90      ']))\n",
    "#     exotic_HR_err=np.append(exotic_HR_err, \\\n",
    "#                                     [swift_error_calculator(i, valid_fluences)], axis=0)\n",
    "# exotic_t90_err=np.where(exo_redshift_swift_data[ '   T90_err    '] != 'N/A', \\\n",
    "#         exo_redshift_swift_data['   T90_err    '], 0)\n",
    "# if len(exotic_t90_err)>0:\n",
    "#     for j in range(0, len(exotic_t90_err)):\n",
    "#         exotic_t90_err[j]=float(exotic_t90_err[j])\n",
    "# unknown_progenitor_redshift_swift_data=fluence_available_swift_data[~(lm_mask|lc_mask|sm_mask|sc_mask|\\\n",
    "#                                                          exo_mask)]\n",
    "# for i in unknown_progenitor_redshift_swift_data.index.to_list():\n",
    "#     unknown_progenitor_HR=np.append(unknown_progenitor_HR, \\\n",
    "#             float(valid_fluences.at[i, ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[i, ' 25_50kev ']))\n",
    "#     unknown_progenitor_t90=np.append(unknown_progenitor_t90, float(unknown_progenitor_redshift_swift_data.at[i, \\\n",
    "#                                                                 '     T90      ']))\n",
    "#     unknown_progenitor_HR_err=np.append(unknown_progenitor_HR_err, \\\n",
    "#                                     [swift_error_calculator(i, valid_fluences)], axis=0)\n",
    "# unknown_progenitor_t90_err=np.where(\\\n",
    "#             unknown_progenitor_edited_swift_data[ '   T90_err    '] != ' N/A ', \\\n",
    "#         unknown_progenitor_edited_swift_data['   T90_err    '], 0)\n",
    "# unknown_progenitor_t90_err=np.where(unknown_progenitor_sample_3_data['t90_error'] != 'N/A', \\\n",
    "#         unknown_progenitor_sample_3_data['t90_error'], 0)\n",
    "# if len(unknown_progenitor_t90_err)>0:\n",
    "#     for j in range(0, len(unknown_progenitor_t90_err)):\n",
    "#         unknown_progenitor_t90_err[j]=float(unknown_progenitor_t90_err[j])\n",
    "# long_collapsar_HR_err=long_collapsar_HR_err[1:]\n",
    "# short_collapsar_HR_err=short_collapsar_HR_err[1:]\n",
    "# long_merger_HR_err=long_merger_HR_err[1:]\n",
    "# short_merger_HR_err=short_merger_HR_err[1:]\n",
    "# exotic_HR_err=exotic_HR_err[1:]\n",
    "# unknown_progenitor_HR_err=unknown_progenitor_HR_err[1:]\n",
    "\n",
    "# bins=np.logspace(np.log10(0.01),np.log10(1000), nbins)\n",
    "# plt.hist(unknown_progenitor_t90, bins=bins)\n",
    "# plt.hist(long_collapsar_t90, bins=bins)\n",
    "# # plt.hist(long_merger_t90, bins=bins)\n",
    "# #plt.hist(short_collapsar_t90, bins=bins)\n",
    "# plt.hist(short_merger_t90, bins=bins)\n",
    "# #plt.hist(exotic_t90, bins=bins)\n",
    "# plt.xscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.5')\n",
    "# plt.tick_params(axis='y', colors='0.5')\n",
    "# plt.legend(['Unknown Progenitor', 'Long Collapsars', \\\n",
    "#             'Short Mergers'])\n",
    "# plt.xlabel(\"t90 (s)\", color=\"0.5\")\n",
    "# plt.ylabel(\"Number of Bursts\", color=\"0.5\")\n",
    "# plt.show()\n",
    "# print(\"There are {} known long collapsars, {} known long \\\n",
    "# mergers, {} known short mergers, {} known short collapsars, and \\\n",
    "# {} known exotic GRBs in Sample 4.\".\\\n",
    "# format(len(long_collapsar_t90), len(long_merger_t90), \\\n",
    "#        len(short_merger_t90), len(short_collapsar_t90), len(exotic_t90)))\n",
    "# print('There are {}/{} bursts in total'.format(np.count_nonzero(~np.isnan(long_collapsar_HR))\\\n",
    "#         +np.count_nonzero(~np.isnan(long_merger_HR))+\\\n",
    "#         np.count_nonzero(~np.isnan(short_merger_HR))+\\\n",
    "#         np.count_nonzero(~np.isnan(short_collapsar_HR))+\\\n",
    "#         np.count_nonzero(~np.isnan(exotic_HR))+np.count_nonzero(~np.isnan(unknown_progenitor_HR)), \\\n",
    "#                                               len(sample_4_data)))\n",
    "# plt.errorbar(x=unknown_progenitor_t90, y=unknown_progenitor_HR, \\\n",
    "#              yerr=np.transpose(unknown_progenitor_HR_err), \\\n",
    "# #              xerr=unknown_progenitor_t90_err, \\\n",
    "#              marker=\".\", color='k', ls='none')\n",
    "# plt.errorbar(x=long_collapsar_t90, y=long_collapsar_HR, \\\n",
    "#              yerr=np.transpose(long_collapsar_HR_err), xerr=long_collapsar_t90_err,\\\n",
    "#              marker=\"o\", ls='none')\n",
    "# # plt.errorbar(x=long_merger_t90, y=long_merger_HR, yerr=np.transpose(long_merger_HR_err),\\\n",
    "# #              xerr=long_merger_t90_err, marker=\"*\", ls='none')\n",
    "# # plt.errorbar(x=short_collapsar_t90, y=short_collapsar_HR, \\\n",
    "# #              yerr=np.transpose(short_collapsar_HR_err), xerr=short_collapsar_t90_err,\\\n",
    "# #              marker=\"^\", ls='none')\n",
    "# plt.errorbar(x=short_merger_t90, y=short_merger_HR, yerr=np.transpose(short_merger_HR_err), \\\n",
    "#              xerr=short_merger_t90_err, marker=\"+\", ls='none')\n",
    "# # plt.errorbar(x=exotic_t90, y=exotic_HR, yerr=np.transpose(exotic_HR_err), \\\n",
    "# #              xerr=exotic_t90_err, marker=\"o\", ls='none')\n",
    "# plt.axis([0.1, 1000, 0.25, 25])\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.5')\n",
    "# plt.tick_params(axis='y', colors='0.5')\n",
    "# plt.legend(['Unknown Progenitor', 'Long Collapsars', 'Short Mergers'])\n",
    "# plt.xlabel(\"t90 (s)\", color=\"0.5\")\n",
    "# plt.ylabel(\"Hardness Ratio\", color=\"0.5\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b13085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Sample 6 Diagnositics##\n",
    "# #unknown_progenitor_edited_fermi_data=fermi_data\n",
    "# swift_unknown_progenitor_HR=[]\n",
    "# swift_unknown_progenitor_HR_err=np.zeros((1,2))\n",
    "# fermi_unknown_progenitor_HR=[]\n",
    "# fermi_unknown_progenitor_HR_err=np.zeros((1,2))\n",
    "# swift_unknown_progenitor_t90=[]\n",
    "# swift_unknown_progenitor_t90_err=[]\n",
    "# unknown_progenitor_t90=[]\n",
    "# unknown_progenitor_t90_err=[]\n",
    "# unknown_progenitor_Epeak_over_s=[]\n",
    "# unknown_progenitor_E_Peak=[]\n",
    "# unknown_progenitor_fluence=[]\n",
    "# swift_long_merger_HR=[]\n",
    "# swift_long_merger_HR_err=np.zeros((1,2))\n",
    "# fermi_long_merger_HR=[]\n",
    "# fermi_long_merger_HR_err=np.zeros((1,2))\n",
    "# long_merger_t90=[]\n",
    "# long_merger_t90_err=[]\n",
    "# long_merger_Epeak_over_s=[]\n",
    "# swift_short_merger_HR=[]\n",
    "# swift_short_merger_HR_err=np.zeros((1,2))\n",
    "# fermi_short_merger_HR=[]\n",
    "# fermi_short_merger_HR_err=np.zeros((1,2))\n",
    "# swift_short_merger_t90=[]\n",
    "# swift_short_merger_t90_err=[]\n",
    "# short_merger_t90=[]\n",
    "# short_merger_t90_err=[]\n",
    "# short_merger_Epeak_over_s=[]\n",
    "# short_merger_E_Peak=[]\n",
    "# short_merger_fluence=[]\n",
    "# swift_long_collapsar_HR=[]\n",
    "# swift_long_collapsar_HR_err=np.zeros((1,2))\n",
    "# fermi_long_collapsar_HR=[]\n",
    "# fermi_long_collapsar_HR_err=np.zeros((1,2))\n",
    "# swift_long_collapsar_t90=[]\n",
    "# swift_long_collapsar_t90_err=[]\n",
    "# long_collapsar_t90=[]\n",
    "# long_collapsar_t90_err=[]\n",
    "# long_collapsar_Epeak_over_s=[]\n",
    "# long_collapsar_E_Peak=[]\n",
    "# long_collapsar_fluence=[]\n",
    "# swift_short_collapsar_HR=[]\n",
    "# swift_short_collapsar_HR_err=np.zeros((1,2))\n",
    "# fermi_short_collapsar_HR=[]\n",
    "# fermi_short_collapsar_HR_err=np.zeros((1,2))\n",
    "# short_collapsar_t90=[]\n",
    "# short_collapsar_t90_err=[]\n",
    "# short_collapsar_Epeak_over_s=[]\n",
    "# swift_exotic_HR=[]\n",
    "# swift_exotic_HR_err=np.zeros((1,2))\n",
    "# fermi_exotic_HR=[]\n",
    "# fermi_exotic_HR_err=np.zeros((1,2))\n",
    "# swift_isolated_HR=[]\n",
    "# swift_isolated_HR_err=np.zeros((1,2))\n",
    "# fermi_isolated_HR=[]\n",
    "# fermi_isolated_HR_err=np.zeros((1,2))\n",
    "# swift_isolated_t90=[]\n",
    "# swift_isolated_t90_err=[]\n",
    "# isolated_t90=[]\n",
    "# isolated_t90_err=[]\n",
    "# isolated_Epeak_over_s=[]\n",
    "# exotic_t90=[]\n",
    "# exotic_t90_err=[]\n",
    "# exotic_Epeak_over_s=[]\n",
    "# nbins=51\n",
    "# Initial_Goldstein_Data=np.zeros((len(sample_6_data),4))\n",
    "# p=0\n",
    "# #\n",
    "# lc_mask=np.isin(sample_6_data['name'], \\\n",
    "#                 Overlap_Precursors[\"Long Collapsars\"])\n",
    "# lc_sample_6_data=sample_6_data[lc_mask]\n",
    "# for i in lc_sample_6_data.index.to_list():\n",
    "#     if valid_fluences.at[int(sample_6_data.at[i, 'Swift row']), ' 25_50kev '] != ' N/A '\\\n",
    "#         and valid_fluences.at[int(sample_6_data.at[i, 'Swift row']),' 25_50kev '] != ' N/A ':\n",
    "#         swift_long_collapsar_HR=np.append(swift_long_collapsar_HR, \\\n",
    "#             float(valid_fluences.at[int(sample_6_data.at[i, 'Swift row']), ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[int(sample_6_data.at[i, 'Swift row']),\\\n",
    "#                                                     ' 25_50kev ']))\n",
    "#         swift_long_collapsar_t90=np.append(swift_long_collapsar_t90, \\\n",
    "#                                            float(edited_swift_data.at[\\\n",
    "#                                         int(sample_6_data.at[i, 'Swift row']), \\\n",
    "#                                                                     '     T90      ']))\n",
    "#     else: \n",
    "#         swift_long_collapsar_HR=np.append(swift_long_collapsar_HR, np.NaN)\n",
    "#         swift_long_collapsar_t90=np.append(swift_long_collapsar_t90, np.NaN)\n",
    "#     if edited_swift_data.at[int(sample_6_data.at[i, 'Swift row']), '   T90_err    '] !=\\\n",
    "#     'N/A':\n",
    "#         swift_long_collapsar_t90_err = np.append(swift_long_collapsar_t90_err, \\\n",
    "#             edited_swift_data.at[int(sample_6_data.at[i, 'Swift row']), '   T90_err    '])\n",
    "#     else: \n",
    "#         swift_long_collapsar_t90_err = np.append(swift_long_collapsar_t90_err, 0)\n",
    "#     fermi_long_collapsar_HR=np.append(fermi_long_collapsar_HR, Fermi_HR_func(sample_2_data, \\\n",
    "#                                 sample_6_data.at[i, 'Spectral Model'], \\\n",
    "#                                             int(sample_6_data.at[i, 'Fermi row'])))\n",
    "#     long_collapsar_t90=np.append(long_collapsar_t90, \\\n",
    "#                                  float(lc_sample_6_data.at[i, 't90']))\n",
    "#     swift_long_collapsar_HR_err=np.append(swift_long_collapsar_HR_err,\\\n",
    "#         [swift_error_calculator(int(sample_6_data.at[i, 'Swift row']), valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "#     long_collapsar_Epeak_over_s=np.append(long_collapsar_Epeak_over_s, \\\n",
    "#                         (getting_the_GBM_E_peak(sample_2_data, \\\n",
    "#                                     sample_6_data.at[i, 'Spectral Model'], \\\n",
    "#                                                sample_6_data.at[i, 'Fermi row']))/\\\n",
    "#                                        float(sample_6_data.at[i, 'GBM fluence']))\n",
    "#     long_collapsar_E_Peak=np.append(long_collapsar_E_Peak, \\\n",
    "#                                         getting_the_GBM_E_peak(sample_2_data, \\\n",
    "#                                     sample_6_data.at[i, 'Spectral Model'],\\\n",
    "#                                                 sample_6_data.at[i, 'Fermi row']))\n",
    "#     long_collapsar_fluence=np.append(long_collapsar_fluence, \\\n",
    "#                                          float(sample_6_data.at[i, 'GBM fluence']))\n",
    "#     Initial_Goldstein_Data[p,0]=sample_6_data.at[i, 'name']\n",
    "#     Initial_Goldstein_Data[p,1]=long_collapsar_Epeak_over_s[-1]\n",
    "#     Initial_Goldstein_Data[p,2]=fermi_long_collapsar_HR[-1]\n",
    "#     Initial_Goldstein_Data[p,3]=float(lc_sample_6_data.at[i, 't90'])\n",
    "#     p=p+1\n",
    "# long_collapsar_t90_err=np.where(lc_sample_6_data['t90_error'] != 'N/A', \\\n",
    "#         lc_sample_6_data['t90_error'], 0)\n",
    "# if len(long_collapsar_t90_err)>0:\n",
    "#     for j in range(0, len(long_collapsar_t90_err)):\n",
    "#         long_collapsar_t90_err[j]=float(long_collapsar_t90_err[j])\n",
    "#         swift_long_collapsar_t90_err[j]=float(swift_long_collapsar_t90_err[j])\n",
    "# sc_mask=np.isin(sample_6_data['name'], \\\n",
    "#                 Overlap_Precursors[\"Short Collapsars\"])\n",
    "# sc_sample_6_data=sample_6_data[sc_mask]\n",
    "# for i in sc_sample_6_data.index.to_list():\n",
    "#     if valid_fluences.at[int(sample_6_data.at[i, 'Swift row']), ' 25_50kev '] != ' N/A '\\\n",
    "#         and valid_fluences.at[int(sample_6_data.at[i, 'Swift row']),' 25_50kev '] != ' N/A ':\n",
    "#         swift_short_collapsar_HR=np.append(swift_short_collapsar_HR, \\\n",
    "#             float(valid_fluences.at[int(sample_6_data.at[i, 'Swift row']), ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[int(sample_6_data.at[i, 'Swift row']),\\\n",
    "#                                                     ' 25_50kev ']))\n",
    "#         swift_short_collapsar_t90=np.append(swift_short_collapsar_t90, \\\n",
    "#                                            float(edited_swift_data.at[\\\n",
    "#                                         int(sample_6_data.at[i, 'Swift row']), \\\n",
    "#                                                                     '     T90      ']))\n",
    "#     else: \n",
    "#         swift_short_collapsar_HR=np.append(swift_short_collapsar_HR, np.NaN)\n",
    "#         swift_short_collapsar_t90=np.append(swift_short_collapsar_t90, np.NaN)\n",
    "#     if edited_swift_data.at[int(sample_6_data.at[i, 'Swift row']), '   T90_err    '] !=\\\n",
    "#     'N/A':\n",
    "#         swift_short_collapsar_t90_err = np.append(swift_short_collapsar_t90_err, \\\n",
    "#             edited_swift_data.at[int(sample_6_data.at[i, 'Swift row']), '   T90_err    '])\n",
    "#     else: \n",
    "#         swift_short_collapsar_t90_err = np.append(swift_short_collapsar_t90_err, 0)\n",
    "#     fermi_short_collapsar_HR=np.append(fermi_short_collapsar_HR, Fermi_HR_func(sample_2_data, \\\n",
    "#                                 sample_6_data.at[i, 'Spectral Model'], \\\n",
    "#                                             int(sample_6_data.at[i, 'Fermi row'])))\n",
    "#     short_collapsar_t90=np.append(short_collapsar_t90, \\\n",
    "#                                  float(sc_sample_6_data.at[i, 't90']))\n",
    "#     swift_short_collapsar_HR_err=np.append(swift_short_collapsar_HR_err,\\\n",
    "#         [swift_error_calculator(int(sample_6_data.at[i, 'Swift row']), valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "#     short_collapsar_Epeak_over_s=np.append(short_collapsar_Epeak_over_s, \\\n",
    "#                         (getting_the_GBM_E_peak(sample_2_data, \\\n",
    "#                                     sample_6_data.at[i, 'Spectral Model'], \\\n",
    "#                                                sample_6_data.at[i, 'Fermi row']))/\\\n",
    "#                                        float(sample_6_data.at[i, 'GBM fluence']))\n",
    "#     Initial_Goldstein_Data[p,0]=sample_6_data.at[i, 'name']\n",
    "#     Initial_Goldstein_Data[p,1]=short_collapsar_Epeak_over_s[-1]\n",
    "#     Initial_Goldstein_Data[p,2]=fermi_short_collapsar_HR[-1]\n",
    "#     Initial_Goldstein_Data[p,3]=float(sc_sample_6_data.at[i, 't90'])\n",
    "#     p=p+1\n",
    "# short_collapsar_t90_err=np.where(sc_sample_6_data['t90_error'] != 'N/A', \\\n",
    "#         sc_sample_6_data['t90_error'], 0)\n",
    "# if len(short_collapsar_t90_err)>0:\n",
    "#     for j in range(0, len(short_collapsar_t90_err)):\n",
    "#         short_collapsar_t90_err[j]=float(short_collapsar_t90_err[j])\n",
    "#         swift_short_collapsar_t90_err[j]=float(swift_short_collapsar_t90_err[j])\n",
    "# lm_mask=np.isin(sample_6_data['name'], \\\n",
    "#                 Overlap_Precursors[\"Long Mergers\"])\n",
    "# lm_sample_6_data=sample_6_data[lm_mask]\n",
    "# for i in lm_sample_6_data.index.to_list():\n",
    "#     if valid_fluences.at[int(sample_6_data.at[i, 'Swift row']), ' 25_50kev '] != ' N/A '\\\n",
    "#         and valid_fluences.at[int(sample_6_data.at[i, 'Swift row']),' 25_50kev '] != ' N/A ':\n",
    "#         swift_long_merger_HR=np.append(swift_long_merger_HR, \\\n",
    "#             float(valid_fluences.at[int(sample_6_data.at[i, 'Swift row']), ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[int(sample_6_data.at[i, 'Swift row']),\\\n",
    "#                                                     ' 25_50kev ']))\n",
    "#         swift_long_merger_t90=np.append(swift_long_merger_t90, \\\n",
    "#                                            float(edited_swift_data.at[\\\n",
    "#                                         int(sample_6_data.at[i, 'Swift row']), \\\n",
    "#                                                                     '     T90      ']))\n",
    "#     else: \n",
    "#         swift_long_merger_HR=np.append(swift_long_merger_HR, np.NaN)\n",
    "#         swift_long_merger_t90=np.append(swift_long_merger_t90, np.NaN)\n",
    "#     if edited_swift_data.at[int(sample_6_data.at[i, 'Swift row']), '   T90_err    '] !=\\\n",
    "#     'N/A':\n",
    "#         swift_long_merger_t90_err = np.append(swift_long_merger_t90_err, \\\n",
    "#             edited_swift_data.at[int(sample_6_data.at[i, 'Swift row']), '   T90_err    '])\n",
    "#     else: \n",
    "#         swift_long_merger_t90_err = np.append(swift_long_merger_t90_err, 0)\n",
    "#     fermi_long_merger_HR=np.append(fermi_long_merger_HR, Fermi_HR_func(sample_2_data, \\\n",
    "#                                 sample_6_data.at[i, 'Spectral Model'], \\\n",
    "#                                             int(sample_6_data.at[i, 'Fermi row'])))\n",
    "#     long_merger_t90=np.append(long_merger_t90, \\\n",
    "#                                  float(lm_sample_6_data.at[i, 't90']))\n",
    "#     swift_long_merger_HR_err=np.append(swift_long_merger_HR_err,\\\n",
    "#         [swift_error_calculator(int(sample_6_data.at[i, 'Swift row']), valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "#     long_merger_Epeak_over_s=np.append(long_merger_Epeak_over_s, \\\n",
    "#                         (getting_the_GBM_E_peak(sample_2_data, \\\n",
    "#                                     sample_6_data.at[i, 'Spectral Model'], \\\n",
    "#                                                sample_6_data.at[i, 'Fermi row']))/\\\n",
    "#                                        float(sample_6_data.at[i, 'GBM fluence']))\n",
    "#     Initial_Goldstein_Data[p,0]=sample_6_data.at[i, 'name']\n",
    "#     Initial_Goldstein_Data[p,1]=long_merger_Epeak_over_s[-1]\n",
    "#     Initial_Goldstein_Data[p,2]=fermi_long_merger_HR[-1]\n",
    "#     Initial_Goldstein_Data[p,3]=float(lm_sample_6_data.at[i, 't90'])\n",
    "#     p=p+1\n",
    "# long_merger_t90_err=np.where(lm_sample_6_data['t90_error'] != 'N/A', \\\n",
    "#         lm_sample_6_data['t90_error'], 0)\n",
    "# if len(long_merger_t90_err)>0:\n",
    "#     for j in range(0, len(long_merger_t90_err)):\n",
    "#         long_merger_t90_err[j]=float(long_merger_t90_err[j])\n",
    "#         swift_long_merger_t90_err[j]=float(swift_long_merger_t90_err[j])\n",
    "# sm_mask=np.isin(sample_6_data['name'], \\\n",
    "#                 Overlap_Precursors[\"Short Mergers\"])\n",
    "# sm_sample_6_data=sample_6_data[sm_mask]\n",
    "# for i in sm_sample_6_data.index.to_list():\n",
    "#     if valid_fluences.at[int(sample_6_data.at[i, 'Swift row']), ' 25_50kev '] != ' N/A '\\\n",
    "#         and valid_fluences.at[int(sample_6_data.at[i, 'Swift row']),' 25_50kev '] != ' N/A ':\n",
    "#         swift_short_merger_HR=np.append(swift_short_merger_HR, \\\n",
    "#             float(valid_fluences.at[int(sample_6_data.at[i, 'Swift row']), ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[int(sample_6_data.at[i, 'Swift row']),\\\n",
    "#                                                     ' 25_50kev ']))\n",
    "#         swift_short_merger_t90=np.append(swift_short_merger_t90, \\\n",
    "#                                            float(edited_swift_data.at[\\\n",
    "#                                         int(sample_6_data.at[i, 'Swift row']), \\\n",
    "#                                                                     '     T90      ']))\n",
    "#     else: \n",
    "#         swift_short_merger_HR=np.append(swift_short_merger_HR, np.NaN)\n",
    "#         swift_short_merger_t90=np.append(swift_short_merger_t90, np.NaN)\n",
    "#     if edited_swift_data.at[int(sample_6_data.at[i, 'Swift row']), '   T90_err    '] !=\\\n",
    "#     'N/A':\n",
    "#         swift_short_merger_t90_err = np.append(swift_short_merger_t90_err, \\\n",
    "#             edited_swift_data.at[int(sample_6_data.at[i, 'Swift row']), '   T90_err    '])\n",
    "#     else: \n",
    "#         swift_short_merger_t90_err = np.append(swift_short_merger_t90_err, 0)\n",
    "#     fermi_short_merger_HR=np.append(fermi_short_merger_HR, Fermi_HR_func(sample_2_data, \\\n",
    "#                                 sample_6_data.at[i, 'Spectral Model'], \\\n",
    "#                                             int(sample_6_data.at[i, 'Fermi row'])))\n",
    "#     short_merger_t90=np.append(short_merger_t90, \\\n",
    "#                                  float(sm_sample_6_data.at[i, 't90']))\n",
    "#     swift_short_merger_HR_err=np.append(swift_short_merger_HR_err,\\\n",
    "#         [swift_error_calculator(int(sample_6_data.at[i, 'Swift row']), valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "#     short_merger_Epeak_over_s=np.append(short_merger_Epeak_over_s, \\\n",
    "#                         (getting_the_GBM_E_peak(sample_2_data, \\\n",
    "#                                     sample_6_data.at[i, 'Spectral Model'], \\\n",
    "#                                                sample_6_data.at[i, 'Fermi row']))/\\\n",
    "#                                        float(sample_6_data.at[i, 'GBM fluence']))\n",
    "#     short_merger_E_Peak=np.append(short_merger_E_Peak, \\\n",
    "#                                         getting_the_GBM_E_peak(sample_2_data, \\\n",
    "#                                     sample_6_data.at[i, 'Spectral Model'],\\\n",
    "#                                                 sample_6_data.at[i, 'Fermi row']))\n",
    "#     short_merger_fluence=np.append(short_merger_fluence, \\\n",
    "#                                          float(sample_6_data.at[i, 'GBM fluence']))\n",
    "#     Initial_Goldstein_Data[p,0]=sample_6_data.at[i, 'name']\n",
    "#     Initial_Goldstein_Data[p,1]=short_merger_Epeak_over_s[-1]\n",
    "#     Initial_Goldstein_Data[p,2]=fermi_short_merger_HR[-1]\n",
    "#     Initial_Goldstein_Data[p,3]=float(sm_sample_6_data.at[i, 't90'])\n",
    "#     p=p+1\n",
    "# short_merger_t90_err=np.where(sm_sample_6_data['t90_error'] != 'N/A', \\\n",
    "#         sm_sample_6_data['t90_error'], 0)\n",
    "# if len(short_merger_t90_err)>0:\n",
    "#     for j in range(0, len(short_merger_t90_err)):\n",
    "#         short_merger_t90_err[j]=float(short_merger_t90_err[j])\n",
    "#         swift_short_merger_t90_err[j]=float(swift_short_merger_t90_err[j])\n",
    "# exo_mask=np.isin(sample_6_data['name'], \\\n",
    "#                 Overlap_Precursors[\"Potentially Exotic\"])\n",
    "# exo_sample_6_data=sample_6_data[exo_mask]\n",
    "# for i in exo_sample_6_data.index.to_list():\n",
    "#     if valid_fluences.at[int(sample_6_data.at[i, 'Swift row']), ' 25_50kev '] != ' N/A '\\\n",
    "#         and valid_fluences.at[int(sample_6_data.at[i, 'Swift row']),' 25_50kev '] != ' N/A ':\n",
    "#         swift_exotic_HR=np.append(swift_exotic_HR, \\\n",
    "#             float(valid_fluences.at[int(sample_6_data.at[i, 'Swift row']), ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[int(sample_6_data.at[i, 'Swift row']),\\\n",
    "#                                                     ' 25_50kev ']))\n",
    "#         swift_exotic_t90=np.append(swift_exotic_t90, \\\n",
    "#                                            float(edited_swift_data.at[\\\n",
    "#                                         int(sample_6_data.at[i, 'Swift row']), \\\n",
    "#                                                                     '     T90      ']))\n",
    "#     else: \n",
    "#         swift_exotic_HR=np.append(swift_exotic_HR, np.NaN)\n",
    "#         swift_exotic_t90=np.append(swift_exotic_t90, np.NaN)\n",
    "#     if edited_swift_data.at[int(sample_6_data.at[i, 'Swift row']), '   T90_err    '] !=\\\n",
    "#     'N/A':\n",
    "#         swift_exotic_t90_err = np.append(swift_exotic_t90_err, \\\n",
    "#             edited_swift_data.at[int(sample_6_data.at[i, 'Swift row']), '   T90_err    '])\n",
    "#     else: \n",
    "#         swift_exotic_t90_err = np.append(swift_exotic_t90_err, 0)\n",
    "#     fermi_exotic_HR=np.append(fermi_exotic_HR, Fermi_HR_func(sample_2_data, \\\n",
    "#                                 sample_6_data.at[i, 'Spectral Model'], \\\n",
    "#                                             int(sample_6_data.at[i, 'Fermi row'])))\n",
    "#     exotic_t90=np.append(exotic_t90, \\\n",
    "#                                  float(exo_sample_6_data.at[i, 't90']))\n",
    "#     swift_exotic_HR_err=np.append(swift_exotic_HR_err,\\\n",
    "#          [swift_error_calculator(int(sample_6_data.at[i, 'Swift row']), valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "#     exotic_Epeak_over_s=np.append(exotic_Epeak_over_s, \\\n",
    "#                         (getting_the_GBM_E_peak(sample_2_data, \\\n",
    "#                                     sample_6_data.at[i, 'Spectral Model'], \\\n",
    "#                                                sample_6_data.at[i, 'Fermi row']))/\\\n",
    "#                                        float(sample_6_data.at[i, 'GBM fluence']))\n",
    "#     Initial_Goldstein_Data[p,0]=sample_6_data.at[i, 'name']\n",
    "#     Initial_Goldstein_Data[p,1]=exotic_Epeak_over_s[-1]\n",
    "#     Initial_Goldstein_Data[p,2]=fermi_exotic_HR[-1]\n",
    "#     Initial_Goldstein_Data[p,3]=float(sample_6_data.at[i, 't90'])\n",
    "#     p=p+1\n",
    "# exotic_t90_err=np.where(exo_sample_6_data['t90_error'] != 'N/A', \\\n",
    "#         exo_sample_6_data['t90_error'], 0)\n",
    "# if len(exotic_t90_err)>0:\n",
    "#     for j in range(0, len(exotic_t90_err)):\n",
    "#         exotic_t90_err[j]=float(exotic_t90_err[j])\n",
    "#         swift_exotic_t90_err[j]=float(swift_exotic_t90_err[j])\n",
    "        \n",
    "# iso_mask=np.isin(sample_6_data['name'], \\\n",
    "#                 Overlap_Precursors[\"Galactic Detected\"])\n",
    "# iso_sample_6_data=sample_6_data[iso_mask]\n",
    "# for i in iso_sample_6_data.index.to_list():\n",
    "#     if valid_fluences.at[int(sample_6_data.at[i, 'Swift row']), ' 25_50kev '] != ' N/A '\\\n",
    "#         and valid_fluences.at[int(sample_6_data.at[i, 'Swift row']),' 25_50kev '] != ' N/A ':\n",
    "#         swift_isolated_HR=np.append(swift_isolated_HR, \\\n",
    "#             float(valid_fluences.at[int(sample_6_data.at[i, 'Swift row']), ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[int(sample_6_data.at[i, 'Swift row']),\\\n",
    "#                                                     ' 25_50kev ']))\n",
    "#         swift_isolated_t90=np.append(swift_isolated_t90, \\\n",
    "#                                            float(edited_swift_data.at[\\\n",
    "#                                         int(sample_6_data.at[i, 'Swift row']), \\\n",
    "#                                                                     '     T90      ']))\n",
    "#     else: \n",
    "#         swift_isolated_HR=np.append(swift_isolated_HR, np.NaN)\n",
    "#         swift_isolated_t90=np.append(swift_isolated_t90, np.NaN)\n",
    "#     if edited_swift_data.at[int(sample_6_data.at[i, 'Swift row']), '   T90_err    '] !=\\\n",
    "#     'N/A':\n",
    "#         swift_isolated_t90_err = np.append(swift_isolated_t90_err, \\\n",
    "#             edited_swift_data.at[int(sample_6_data.at[i, 'Swift row']), '   T90_err    '])\n",
    "#     else: \n",
    "#         swift_isolated_t90_err = np.append(swift_isolated_t90_err, 0)\n",
    "#     fermi_isolated_HR=np.append(fermi_isolated_HR, Fermi_HR_func(sample_2_data, \\\n",
    "#                                 sample_6_data.at[i, 'Spectral Model'], \\\n",
    "#                                             int(sample_6_data.at[i, 'Fermi row'])))\n",
    "#     isolated_t90=np.append(isolated_t90, \\\n",
    "#                                  float(iso_sample_6_data.at[i, 't90']))\n",
    "#     swift_isolated_HR_err=np.append(swift_isolated_HR_err,\\\n",
    "#         [swift_error_calculator(int(sample_6_data.at[i, 'Swift row']), valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "#     isolated_Epeak_over_s=np.append(isolated_Epeak_over_s, \\\n",
    "#                         (getting_the_GBM_E_peak(sample_2_data, \\\n",
    "#                                     sample_6_data.at[i, 'Spectral Model'], \\\n",
    "#                                                sample_6_data.at[i, 'Fermi row']))/\\\n",
    "#                                        float(sample_6_data.at[i, 'GBM fluence']))\n",
    "#     Initial_Goldstein_Data[p,0]=sample_6_data.at[i, 'name']\n",
    "#     Initial_Goldstein_Data[p,1]=isolated_Epeak_over_s[-1]\n",
    "#     Initial_Goldstein_Data[p,2]=fermi_isolated_HR[-1]\n",
    "#     Initial_Goldstein_Data[p,3]=float(sample_6_data.at[i, 't90'])\n",
    "#     p=p+1\n",
    "# isolated_t90_err=np.where(iso_sample_6_data['t90_error'] != 'N/A', \\\n",
    "#         iso_sample_3_data['t90_error'], 0)\n",
    "# if len(isolated_t90_err)>0:\n",
    "#     for j in range(0, len(isolated_t90_err)):\n",
    "#         isolated_t90_err[j]=float(isolated_t90_err[j])\n",
    "#         swift_isolated_t90_err[j]=float(swift_isolated_t90_err[j])\n",
    "        \n",
    "# unknown_progenitor_sample_6_data=sample_6_data[~(lm_mask|lc_mask|sm_mask|sc_mask|exo_mask)]\n",
    "# for i in unknown_progenitor_sample_6_data.index.to_list():\n",
    "#     if valid_fluences.at[int(sample_6_data.at[i, 'Swift row']), ' 25_50kev '] != ' N/A '\\\n",
    "#         and valid_fluences.at[int(sample_6_data.at[i, 'Swift row']),' 25_50kev '] != ' N/A ':\n",
    "#         swift_unknown_progenitor_HR=np.append(swift_unknown_progenitor_HR, \\\n",
    "#             float(valid_fluences.at[int(sample_6_data.at[i, 'Swift row']), ' 50_100kev '])/\\\n",
    "#                             float(valid_fluences.at[int(sample_6_data.at[i, 'Swift row']),\\\n",
    "#                                                     ' 25_50kev ']))\n",
    "#         swift_unknown_progenitor_t90=np.append(swift_unknown_progenitor_t90, \\\n",
    "#                                            float(edited_swift_data.at[\\\n",
    "#                                         int(sample_6_data.at[i, 'Swift row']), \\\n",
    "#                                                                     '     T90      ']))\n",
    "#     else: \n",
    "#         swift_unknown_progenitor_HR=np.append(swift_unknown_progenitor_HR, np.NaN)\n",
    "#         swift_unknown_progenitor_t90=np.append(swift_unknown_progenitor_t90, np.NaN)\n",
    "#     if edited_swift_data.at[int(sample_6_data.at[i, 'Swift row']), '   T90_err    '] !=\\\n",
    "#     'N/A':\n",
    "#         swift_unknown_progenitor_t90_err = np.append(swift_unknown_progenitor_t90_err, \\\n",
    "#             edited_swift_data.at[int(sample_6_data.at[i, 'Swift row']), '   T90_err    '])\n",
    "#     else: \n",
    "#         swift_unknown_progenitor_t90_err = np.append(swift_unknown_progenitor_t90_err, 0)\n",
    "#     fermi_unknown_progenitor_HR=np.append(fermi_unknown_progenitor_HR, Fermi_HR_func(sample_2_data, \\\n",
    "#                                 sample_6_data.at[i, 'Spectral Model'], \\\n",
    "#                                             int(sample_6_data.at[i, 'Fermi row'])))\n",
    "#     unknown_progenitor_t90=np.append(unknown_progenitor_t90, \\\n",
    "#                                  float(unknown_progenitor_sample_6_data.at[i, 't90']))\n",
    "#     swift_unknown_progenitor_HR_err=np.append(swift_unknown_progenitor_HR_err,\\\n",
    "#         [swift_error_calculator(int(sample_6_data.at[i, 'Swift row']), valid_fluences)], \\\n",
    "#                                    axis=0)\n",
    "#     unknown_progenitor_Epeak_over_s=np.append(unknown_progenitor_Epeak_over_s, \\\n",
    "#                         (getting_the_GBM_E_peak(sample_2_data, \\\n",
    "#                                     sample_6_data.at[i, 'Spectral Model'],\\\n",
    "#                                                 sample_6_data.at[i, 'Fermi row']))/\\\n",
    "#                                        float(sample_6_data.at[i, 'GBM fluence']))\n",
    "#     unknown_progenitor_E_Peak=np.append(unknown_progenitor_E_Peak, \\\n",
    "#                                         getting_the_GBM_E_peak(sample_2_data, \\\n",
    "#                                     sample_6_data.at[i, 'Spectral Model'],\\\n",
    "#                                                 sample_6_data.at[i, 'Fermi row']))\n",
    "#     unknown_progenitor_fluence=np.append(unknown_progenitor_fluence, \\\n",
    "#                                          float(sample_6_data.at[i, 'GBM fluence']))\n",
    "#     Initial_Goldstein_Data[p,0]=sample_6_data.at[i, 'name']\n",
    "#     Initial_Goldstein_Data[p,1]=unknown_progenitor_Epeak_over_s[-1]\n",
    "#     Initial_Goldstein_Data[p,2]=fermi_unknown_progenitor_HR[-1]\n",
    "#     Initial_Goldstein_Data[p,3]=float(sample_6_data.at[i, 't90'])\n",
    "#     p=p+1\n",
    "# unknown_progenitor_t90_err=np.where(unknown_progenitor_sample_6_data['t90_error'] != 'N/A', \\\n",
    "#         unknown_progenitor_sample_6_data['t90_error'], 0)\n",
    "# if len(unknown_progenitor_t90_err)>0:\n",
    "#     for j in range(0, len(unknown_progenitor_t90_err)):\n",
    "#         unknown_progenitor_t90_err[j]=float(unknown_progenitor_t90_err[j])\n",
    "#         swift_unknown_progenitor_t90_err[j]=float(swift_unknown_progenitor_t90_err[j])\n",
    "# swift_long_merger_HR_err=swift_long_merger_HR_err[1:]\n",
    "# swift_long_collapsar_HR_err=swift_long_collapsar_HR_err[1:]\n",
    "# swift_short_merger_HR_err=swift_short_merger_HR_err[1:]\n",
    "# swift_short_collapsar_HR_err=swift_short_collapsar_HR_err[1:]\n",
    "# swift_exotic_HR_err=swift_exotic_HR_err[1:]\n",
    "# swift_isolated_HR_err=swift_isolated_HR_err[1:]\n",
    "# swift_unknown_progenitor_HR_err=swift_unknown_progenitor_HR_err[1:]\n",
    "# bins=np.logspace(np.log10(0.01),np.log10(1000), nbins)\n",
    "# plt.hist(unknown_progenitor_t90, bins=bins, color='k')\n",
    "# plt.hist(long_collapsar_t90, bins=bins, color='r')\n",
    "# # plt.hist(long_merger_t90, bins=bins)\n",
    "# # plt.hist(short_collapsar_t90, bins=bins)\n",
    "# plt.hist(short_merger_t90, bins=bins, color='b')\n",
    "# # plt.hist(exotic_t90, bins=bins)\n",
    "# plt.hist(isolated_t90, bins=bins, color='g')\n",
    "# plt.xscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.5')\n",
    "# plt.tick_params(axis='y', colors='0.5')\n",
    "# plt.legend(['Unknown Progenitor', 'Long Collapsars', 'Short Mergers'])#, 'Exotic'])\n",
    "# plt.xlabel(\"t90 (s)\", color=\"0.5\")\n",
    "# plt.ylabel(\"Number of Bursts\", color=\"0.5\")\n",
    "# plt.show()\n",
    "# print(\"There are {} known long collapsars, {} known long \\\n",
    "# mergers, {} known short mergers, {} known short collapsars, \\\n",
    "# {} known exotic, and {} known isolated GRBs in Sample 6.\".\\\n",
    "# format(len(long_collapsar_t90), len(long_merger_t90), \\\n",
    "#        len(short_merger_t90), len(short_collapsar_t90), len(exotic_t90), len(isolated_t90)))\n",
    "# print('There are {}/{} bursts in total'.format(np.count_nonzero(\\\n",
    "#                                                 ~np.isnan(swift_long_collapsar_HR))\\\n",
    "#         +np.count_nonzero(~np.isnan(fermi_long_merger_HR))+\\\n",
    "#         np.count_nonzero(~np.isnan(fermi_short_merger_HR))+\\\n",
    "#         np.count_nonzero(~np.isnan(fermi_short_collapsar_HR))+\\\n",
    "#         np.count_nonzero(~np.isnan(fermi_exotic_HR))+\\\n",
    "#         np.count_nonzero(~np.isnan(fermi_isolated_HR))+\\\n",
    "#                                         np.count_nonzero(~np.isnan(fermi_unknown_progenitor_HR)), \\\n",
    "#                                               len(sample_6_data)))\n",
    "# plt.errorbar(x=swift_unknown_progenitor_t90, y=swift_unknown_progenitor_HR, \\\n",
    "#              yerr=np.transpose(swift_unknown_progenitor_HR_err), \\\n",
    "#              xerr=unknown_progenitor_t90_err, \\\n",
    "#              marker=\".\", color='k', ls='none')\n",
    "# plt.errorbar(x=swift_long_collapsar_t90, y=swift_long_collapsar_HR, \\\n",
    "#              yerr=np.transpose(swift_long_collapsar_HR_err), \\\n",
    "# #              xerr=swift_long_collapsar_t90_err,\\\n",
    "#              marker=\"o\", color='r', ls='none')\n",
    "# plt.errorbar(x=swift_short_merger_t90, y=swift_short_merger_HR, \\\n",
    "#              yerr=np.transpose(swift_short_merger_HR_err), \\\n",
    "# #              xerr=swift_long_collapsar_t90_err,\\\n",
    "#              marker=\"o\", color='b', ls='none')\n",
    "# plt.errorbar(x=swift_isolated_t90, y=swift_isolated_HR, \\\n",
    "#              yerr=np.transpose(swift_isolated_HR_err), \\\n",
    "# #              xerr=swift_long_collapsar_t90_err,\\\n",
    "#              marker=\"o\", color='g', ls='none')\n",
    "# plt.axis([0.1, 1000, 0.25, 25])\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.5')\n",
    "# plt.tick_params(axis='y', colors='0.5')\n",
    "# plt.legend(['Unknown Progenitor', 'Long Collapsars', 'Short Mergers', \"Isolated GRBs\"])\n",
    "# plt.xlabel(\"t90 (s)\", color=\"0.5\")\n",
    "# plt.ylabel(\"Hardness Ratio\", color=\"0.5\")\n",
    "# plt.show()\n",
    "# plt.errorbar(x=unknown_progenitor_t90, y=fermi_unknown_progenitor_HR,\\\n",
    "# #              yerr=np.transpose(unknown_progenitor_HR_err), \\\n",
    "#              xerr=unknown_progenitor_t90_err, \\\n",
    "#              marker=\".\", color='k', ls='none')\n",
    "# plt.errorbar(x=long_collapsar_t90, y=fermi_long_collapsar_HR, \\\n",
    "# #              yerr=np.transpose(long_collapsar_HR_err),\n",
    "#              xerr=long_collapsar_t90_err,\\\n",
    "#              marker=\"o\", ls='none', color='r')\n",
    "# # plt.errorbar(x=long_merger_t90, y=long_merger_HR, \\\n",
    "# # #              yerr=np.transpose(long_merger_HR_err), xerr=long_merger_t90_err,\\\n",
    "# #              marker=\"*\", ls='none')\n",
    "# # plt.errorbar(x=short_collapsar_t90, y=short_collapsar_HR, \\\n",
    "# # #              yerr=np.transpose(short_collapsar_HR_err), xerr=short_collapsar_t90_err,\\\n",
    "# #              marker=\"^\", ls='none')\n",
    "# plt.errorbar(x=short_merger_t90, y=fermi_short_merger_HR, \\\n",
    "# #              yerr=np.transpose(short_merger_HR_err), xerr=short_merger_t90_err, \\\n",
    "#              marker=\"o\", ls='none', color='b')\n",
    "# # plt.errorbar(x=exotic_t90, y=exotic_HR, yerr=np.transpose(exotic_HR_err), \\\n",
    "# #              xerr=exotic_t90_err, marker=\"o\", ls='none')\n",
    "# plt.errorbar(x=isolated_t90, y=fermi_isolated_HR, \\\n",
    "# #              yerr=np.transpose(short_merger_HR_err), xerr=short_merger_t90_err, \\\n",
    "#              marker=\"*\", ls='none', color='g')\n",
    "# plt.axis([0.001, 1000, 1e-4, 10])\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.8')\n",
    "# plt.tick_params(axis='y', colors='0.8')\n",
    "# plt.legend(['Unknown Progenitor', 'Long Collapsars', 'Short Mergers', \"Isolated GRBs\"])\n",
    "# plt.xlabel(\"t90 (s)\", color=\"0.8\")\n",
    "# plt.ylabel(\"Hardness Ratio\", color=\"0.8\")\n",
    "# plt.show()\n",
    "\n",
    "# new_bins=np.logspace(5,13, 81)\n",
    "# plt.hist(unknown_progenitor_Epeak_over_s, bins=new_bins, color='k')\n",
    "# plt.hist(long_collapsar_Epeak_over_s, bins=new_bins, color='r')\n",
    "# # plt.hist(long_merger_Epeak_over_s, bins=new_bins)\n",
    "# # plt.hist(short_collapsar_Epeak_over_s, bins=new_bins)\n",
    "# plt.hist(short_merger_Epeak_over_s, bins=new_bins, color='b')\n",
    "# # plt.hist(exotic_t90, bins=bins)\n",
    "# plt.hist(isolated_Epeak_over_s, bins=new_bins, color='g')\n",
    "# plt.xscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.8')\n",
    "# plt.tick_params(axis='y', colors='0.8')\n",
    "# plt.legend(['Unknown Progenitor', 'Long Collapsars', 'Short Mergers', \"Isolated GRBs\"])\n",
    "# plt.xlabel(r\"$E_{peak}$/$Fluence_{10-1000keV}$ cm^2\", color=\"0.8\")\n",
    "# plt.ylabel(\"Number of Bursts\", color=\"0.8\")\n",
    "# plt.show()\n",
    "# Goldstein_Sample_6_Data=pd.DataFrame(Initial_Goldstein_Data, columns=[\"Name\",\\\n",
    "#                                         \"Peak E. over Flue.\", \"Hardness Ratio\", \"t90\"])\n",
    "# Goldstein_Sample_6_Data.to_excel(\"Goldstein_Sample_6_Data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a74cccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Hypothesis 1##\n",
    "# spectral_mask=np.isin(sample_6_data['Spectral Model'], 0.0)\n",
    "# spectral_sample_6_data=sample_6_data[~spectral_mask]\n",
    "# #not really \"necessary\", but I find it saves me a little time\n",
    "# speed_light=3e10 #now in cm/s\n",
    "# H_0=70*10**5/(3.086e24)\n",
    "# #km/s*Mpc times 1000m/km*100cm/m divided by 10**6 for Mega *3*10**16 m/pc *100 cm\n",
    "# Initial_1_Data=np.zeros((len(spectral_sample_6_data),5))\n",
    "# j=0\n",
    "# for i in spectral_sample_6_data.index:\n",
    "#     rs=spectral_sample_6_data['Likely Redshift'][i]\n",
    "#     flu=spectral_sample_6_data['GBM fluence'][i]\n",
    "#     d_lum=((2*speed_light)/H_0)*(1-np.sqrt(1/(1+rs)))*(1+rs)\n",
    "#     # print(d_lum)\n",
    "#     ghostie=spectral_sample_6_data['Spectral Model'][i]\n",
    "#     #get it, ghostie becuase it's the SPEC-trum. I guess code isn't the time to make jokes.\n",
    "#     fermi_placement= spectral_sample_6_data['Fermi row'][i]\n",
    "#     #at least this one is descriptive\n",
    "#     k=Fermi_k_func(sample_2_data, ghostie, fermi_placement, rs)\n",
    "#     #as is this one\n",
    "#     # print(k)\n",
    "#     E_iso=4*np.pi*((d_lum)**2)*flu*k/(1+rs)\n",
    "#     # print(L_iso)\n",
    "#     Initial_1_Data[j, 0]=spectral_sample_6_data['name'][i]\n",
    "#     Initial_1_Data[j, 1]=E_iso\n",
    "#     decay_pos=np.where(spectral_sample_6_data['name'][i]==\\\n",
    "#                        average_decay_data['Fermi name'])[0][0]\n",
    "#     #literally the position in the decay array\n",
    "#     if average_decay_data['average decay rate after rs 200s'][decay_pos] != \\\n",
    "#     0:\n",
    "#         Initial_1_Data[j, 2]=\\\n",
    "#         average_decay_data['average decay rate after rs 200s'][decay_pos]\n",
    "#     elif average_decay_data['average decay rate after data available'][decay_pos] != \\\n",
    "#     0:\n",
    "#         Initial_1_Data[j, 2]=\\\n",
    "#             average_decay_data['average decay rate after data available'][decay_pos]\n",
    "#     else:\n",
    "#         print(\"couldn't find a decay rate for GRB {}\").\\\n",
    "#         format(average_decay_data['name'][decay_pos])\n",
    "#     Initial_1_Data[j, 3]=spectral_sample_6_data['t90'][i]\n",
    "#     Initial_1_Data[j, 4]=spectral_sample_6_data['Likely Redshift'][i]\n",
    "#     j=j+1\n",
    "# Test_1_Data=pd.DataFrame(Initial_1_Data, columns=[\"Name\", \"Prompt Isotropic Energy\",\\\n",
    "#                                                  \"Avg. Afterglow Decay Rate\", \"t90\", \\\n",
    "#                                                  \"Redshift\"])\n",
    "# # outliers_mask=np.isin(Test_1_Data[\"Name\"], \\\n",
    "# #                 (150101641.0))\n",
    "# # No_Out_Test_1_Data=Test_1_Data[~outliers_mask]\n",
    "# No_Out_Test_1_Data=Test_1_Data\n",
    "# short_mask=np.where(No_Out_Test_1_Data[\"t90\"]<=2, True, False)\n",
    "# Short_Test_1_Data=No_Out_Test_1_Data[short_mask]\n",
    "# long_mask=np.where(No_Out_Test_1_Data[\"t90\"]>2, True, False)\n",
    "# Long_Test_1_Data=No_Out_Test_1_Data[long_mask]\n",
    "# coefficients = np.polyfit(np.log10(No_Out_Test_1_Data[\"Prompt Isotropic Energy\"]),\\\n",
    "#                           No_Out_Test_1_Data[\"Avg. Afterglow Decay Rate\"], 1)\n",
    "# polynomial = np.poly1d(coefficients)\n",
    "# log10_y_fit = polynomial(np.log10(No_Out_Test_1_Data[\"Prompt Isotropic Energy\"]))\n",
    "# plt.plot(Long_Test_1_Data[\"Prompt Isotropic Energy\"], \\\n",
    "#          Long_Test_1_Data[\"Avg. Afterglow Decay Rate\"], marker=\"*\", ls='none')\n",
    "# plt.plot(Short_Test_1_Data[\"Prompt Isotropic Energy\"], \\\n",
    "#          Short_Test_1_Data[\"Avg. Afterglow Decay Rate\"], marker=\"o\", ls='none')\n",
    "# plt.plot(No_Out_Test_1_Data[\"Prompt Isotropic Energy\"], log10_y_fit, '--')\n",
    "# plt.legend(['Long GRBs', 'Short GRBs'])\n",
    "# plt.xscale('log')\n",
    "# # plt.yscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.8')\n",
    "# plt.tick_params(axis='y', colors='0.8')\n",
    "# plt.xlabel(r\"Prompt Isotropic Energy (erg)\", color=\"0.8\")\n",
    "# plt.ylabel(\"Avg. Afterglow Decay Rate (photons/s)\", color=\"0.8\")\n",
    "# plt.show()\n",
    "# sm_mask=np.isin(No_Out_Test_1_Data['Name'], \\\n",
    "#                 Overlap_Precursors[\"Short Mergers\"])\n",
    "# lm_mask=np.isin(No_Out_Test_1_Data['Name'], \\\n",
    "#                 Overlap_Precursors[\"Long Mergers\"])\n",
    "# sc_mask=np.isin(No_Out_Test_1_Data['Name'], \\\n",
    "#                 Overlap_Precursors[\"Short Collapsars\"])\n",
    "# lc_mask=np.isin(No_Out_Test_1_Data['Name'], \\\n",
    "#                 Overlap_Precursors[\"Long Collapsars\"])\n",
    "# exo_mask=np.isin(No_Out_Test_1_Data['Name'], \\\n",
    "#                 Overlap_Precursors[\"Potentially Exotic\"])\n",
    "# iso_mask=np.isin(No_Out_Test_1_Data['Name'], \\\n",
    "#                 Overlap_Precursors[\"Galactic Detected\"])\n",
    "# Short_Test_1b_Data=No_Out_Test_1_Data[sm_mask|lm_mask|iso_mask]\n",
    "# Long_Test_1b_Data=No_Out_Test_1_Data[sc_mask|lc_mask]\n",
    "# Exotic_Test_1b_Data=No_Out_Test_1_Data[exo_mask]\n",
    "# Unknown_Test_1b_Data=No_Out_Test_1_Data[~(lm_mask|lc_mask|sm_mask|sc_mask|exo_mask|iso_mask)]\n",
    "# plt.plot(Long_Test_1b_Data[\"Prompt Isotropic Energy\"], \\\n",
    "#          abs(Long_Test_1b_Data[\"Avg. Afterglow Decay Rate\"]), marker=\"*\", ls='none')\n",
    "# # plt.plot(Short_Test_1b_Data[\"Prompt Luminosity\"], \\\n",
    "# #          abs(Short_Test_1b_Data[\"Avg. Afterglow Decay Rate\"]), marker=\"o\", ls='none')\n",
    "# # plt.plot(Exotic_Test_1b_Data[\"Prompt Luminosity\"], \\\n",
    "# #          abs(Exotic_Test_1b_Data[\"Avg. Afterglow Decay Rate\"]), marker=\"o\", ls='none')\n",
    "# plt.plot(Unknown_Test_1b_Data[\"Prompt Isotropic Energy\"], \\\n",
    "#          abs(Unknown_Test_1b_Data[\"Avg. Afterglow Decay Rate\"]), marker=\".\", ls='none')\n",
    "# plt.plot(No_Out_Test_1_Data[\"Prompt Isotropic Energy\"], log10_y_fit, '--')\n",
    "# plt.legend(['Collapsar GRBs', 'Merger GRBs' 'Unknown Progenitor'])\n",
    "# plt.xscale('log')\n",
    "# # plt.yscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.8')\n",
    "# plt.tick_params(axis='y', colors='0.8')\n",
    "# plt.xlabel(r\"Prompt Isotropic Energy (erg)\", color=\"0.8\")\n",
    "# plt.ylabel(\"Avg. Afterglow Decay Rate (photons/s)\", color=\"0.8\")\n",
    "# plt.show()\n",
    "# Test_1_Data.to_excel(\"Hypothesis_1_Data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b4cded8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nnuessle/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_minpack_py.py:175: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "/Users/nnuessle/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_minpack_py.py:175: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "/Users/nnuessle/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_minpack_py.py:175: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "<ipython-input-23-a764d28034c8>:204: RuntimeWarning: invalid value encountered in sqrt\n",
      "  AG_fluence_err=np.sqrt(\\\n",
      "<ipython-input-23-a764d28034c8>:186: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "  AG_fluence=integrate.quad(lambda t: doubly_broken_PL(Q, \\\n",
      "/Users/nnuessle/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_minpack_py.py:175: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Hypothesis 2a##\n",
    "spectral_mask=np.isin(sample_6_data['Spectral Model'], 0.0)\n",
    "spectral_sample_6_data=sample_6_data[~spectral_mask]\n",
    "#not really \"necessary\", but I find it saves me a little time\n",
    "Initial_2a_Data=np.zeros((len(spectral_sample_6_data.index),7))\n",
    "speed_light=3e10 #now in cm/s\n",
    "H_0=70*10**5/(3.086e24)\n",
    "nu=10**(18)\n",
    "j=0\n",
    "for i in spectral_sample_6_data.index:\n",
    "    rs=spectral_sample_6_data['Likely Redshift'][i]\n",
    "    flu=spectral_sample_6_data['GBM fluence'][i]\n",
    "    flu_err=sample_2_data.at[spectral_sample_6_data.at[i, 'Fermi row'], 'fluence_error']\n",
    "    d_lum=((2*speed_light)/H_0)*(1-np.sqrt(1/(1+rs)))*(1+rs)\n",
    "    ghostie=spectral_sample_6_data['Spectral Model'][i]\n",
    "    #get it, ghostie becuase it's the SPEC-trum. I guess code isn't the time to make jokes.\n",
    "    fermi_placement= spectral_sample_6_data['Fermi row'][i]\n",
    "    #at least this one is descriptive\n",
    "    k=Fermi_k_func(sample_2_data, ghostie, fermi_placement, rs)\n",
    "    E_iso=4*np.pi*((d_lum)**2)*flu*k/(1+rs)\n",
    "    Initial_2a_Data[j, 0]= spectral_sample_6_data['name'][i]\n",
    "    Initial_2a_Data[j, 1]= E_iso\n",
    "    E_iso_err=4*np.pi*((d_lum)**2)*flu_err*k/(1+rs)\n",
    "    Initial_2a_Data[j, 2]=E_iso_err\n",
    "    backstop=int(spectral_sample_6_data['Plateau Stage'][i])\n",
    "    row=spectral_sample_6_data['XRT row'][i]\n",
    "    model_selector=more_xrt_data[' #breaks '][row]\n",
    "    if model_selector>=1:\n",
    "        break_1=int(float(more_xrt_data[' break_1 '][row]))\n",
    "        split_err=re.split(\",\", more_xrt_data.at[i, ' D_break_1 '].strip())\n",
    "        if split_err and split_err[0] !='' and split_err[1] != '':\n",
    "            split_err= list(map(float, split_err))\n",
    "            err_break_1=np.mean([abs(split_err[0]), abs(split_err[1])])\n",
    "        elif split_err[0] !='':\n",
    "            err_break_1=float(split_err[0])\n",
    "        elif split_err[1] != '':\n",
    "            err_break_1=float(split_err[1])\n",
    "        else:\n",
    "            err_break_1=0\n",
    "        power_1=-float(more_xrt_data[' alpha_1 '][row])\n",
    "        power_2=-float(more_xrt_data[' alpha_2 '][row])\n",
    "        if backstop==1:\n",
    "            front=0\n",
    "            error_front=0\n",
    "            back=break_1\n",
    "            error_back=float(err_break_1)\n",
    "        if model_selector>=2:\n",
    "            break_2=int(float(more_xrt_data[' break_2 '][row]))\n",
    "            split_err=re.split(\",\", more_xrt_data.at[i, ' D_break_2 '].strip())\n",
    "            if split_err and split_err[0] !='' and split_err[1] != '':\n",
    "                split_err= list(map(float, split_err))\n",
    "                err_break_2=np.mean([abs(split_err[0]), abs(split_err[1])])\n",
    "            elif split_err[0] !='':\n",
    "                err_break_2=float(split_err[0])\n",
    "            elif split_err[1] != '':\n",
    "                err_break_2=float(split_err[1])\n",
    "            else:\n",
    "                err_break_2=0\n",
    "            power_3=-float(more_xrt_data[' alpha_3 '][row])\n",
    "            if backstop==2:\n",
    "                front=break_1\n",
    "                error_front=float(err_break_1)\n",
    "                back=break_2\n",
    "                error_back=float(err_break_2)\n",
    "            if model_selector>=3:\n",
    "                break_3=int(float(more_xrt_data[' break_3 '][row]))\n",
    "                split_err=re.split(\",\", more_xrt_data.at[i, ' D_break_3 '].strip())\n",
    "                if split_err and split_err[0] !='' and split_err[1] != '':\n",
    "                    split_err= list(map(float, split_err))\n",
    "                    err_break_3=np.mean([abs(split_err[0]), abs(split_err[1])])\n",
    "                elif split_err[0] !='':\n",
    "                    err_break_3=float(split_err[0])\n",
    "                elif split_err[1] != '':\n",
    "                    err_break_3=float(split_err[1])\n",
    "                else:\n",
    "                    err_break_3=0\n",
    "                power_4=-float(more_xrt_data[' alpha_4 '][row])\n",
    "                if backstop==3:\n",
    "                    front=break_2\n",
    "                    error_front=float(err_break_2)\n",
    "                    back=break_3\n",
    "                    error_back=float(err_break_3)\n",
    "                if model_selector>=4:\n",
    "                    break_4=int(float(more_xrt_data[' break_4 '][row]))\n",
    "                    split_err=re.split(\",\", more_xrt_data.at[i, ' D_break_4 '].strip())\n",
    "                    if split_err and split_err[0] !='' and split_err[1] != '':\n",
    "                        split_err= list(map(float, split_err))\n",
    "                        err_break_4=np.mean([abs(split_err[0]), abs(split_err[1])])\n",
    "                    elif split_err[0] !='':\n",
    "                        err_break_4=float(split_err[0])\n",
    "                    elif split_err[1] != '':\n",
    "                        err_break_4=float(split_err[1])\n",
    "                    else:\n",
    "                        err_break_4=0\n",
    "                    power_5=-float(more_xrt_data[' alpha_5 '][row])\n",
    "                    if backstop==4:\n",
    "                        front=break_3\n",
    "                        error_front=float(err_break_3)\n",
    "                        back=break_4\n",
    "                        error_back=float(err_break_4)\n",
    "                    if model_selector==5:\n",
    "                        break_5=int(float(more_xrt_data[' break_5 '][row]))\n",
    "                        split_err=re.split(\",\", more_xrt_data.at[i, ' D_break_5 '].strip())\n",
    "                        if split_err and split_err[0] !='' and split[1] != '':\n",
    "                            split_err= list(map(float, split_err))\n",
    "                            err_break_5=np.mean([abs(split_err[0]), abs(split_err[1])])\n",
    "                        elif split_err[0] !='':\n",
    "                            err_break_5=float(split_err[0])\n",
    "                        elif split_err[1] != '':\n",
    "                            err_break_5=float(split_err[1])\n",
    "                        else:\n",
    "                            err_break_5=0\n",
    "                        power_6=-float(more_xrt_data[' alpha_6 '][row]) \n",
    "                        if backstop==5:\n",
    "                            front=break_4\n",
    "                            error_back=float(err_break_4)\n",
    "                            back=break_5\n",
    "                            error_back=float(err_break_5)\n",
    "                        initial_value=quintuply_broken_PL(1, break_1, break_2, break_3, \\\n",
    "                                    break_4, break_5, power_1, power_2, power_3, power_4, \\\n",
    "                                        power_5, power_6, 0, 11*60*60)\n",
    "                        Q=fsolve(lambda A: A*initial_value-float(more_xrt_data[' Flux_11 '][row]),\\\n",
    "                         0.01)[0]\n",
    "                        if abs(quintuply_broken_PL(Q, break_1, break_2, break_3, break_4, \\\n",
    "                                break_5, power_1, power_2, power_3, power_4, power_5, power_6, \\\n",
    "                            0, 24*60*60)-float(more_xrt_data[' Flux_24 '][row]))/\\\n",
    "                        (float(more_xrt_data[' Flux_24 '][row]))<0.05:\n",
    "                            AG_fluence=integrate.quad(lambda t: quintuply_broken_PL(Q, \\\n",
    "                                break_1, break_2, break_3, break_4, break_5, power_1, \\\n",
    "                                power_2, power_3, power_4, power_5, power_6, 0, t), \\\n",
    "                                                      front, back)[0]\n",
    "                            AG_fluence_err=np.sqrt((\\\n",
    "                                quintuply_broken_PL_derivative(Q, break_1, break_2, break_3,\\\n",
    "                                break_4, break_5, power_1, power_2, power_3, power_4, power_5, \\\n",
    "                                power_6, 0, front)*error_front)**2+(\\\n",
    "                                quintuply_broken_PL_derivative(Q, break_1, break_2, break_3,\\\n",
    "                                break_4, break_5, power_1, power_2, power_3, power_4, power_5, \\\n",
    "                                power_6, 0, back)*error_back)**2)\n",
    "                    else:\n",
    "                        initial_value=quadruply_broken_PL(1, break_1, break_2, break_3, break_4, \\\n",
    "                                             power_1, power_2, power_3, power_4, power_5, \\\n",
    "                                             0, 11*60*60)\n",
    "                        Q=fsolve(lambda A: A*initial_value-float(\\\n",
    "                                    more_xrt_data[' Flux_11 '][row]),0.01)[0]\n",
    "                        if abs(quadruply_broken_PL(Q, break_1, break_2, break_3, break_4, \\\n",
    "                            power_1, power_2, power_3, power_4, power_5,\\\n",
    "                            0, 24*60*60)-float(more_xrt_data[' Flux_24 '][row]))/\\\n",
    "                        (float(more_xrt_data[' Flux_24 '][row]))<0.05:\n",
    "                            AG_fluence=integrate.quad(lambda t: quadruply_broken_PL(Q, \\\n",
    "                                break_1, break_2, break_3, break_4, power_1, power_2, \\\n",
    "                                power_3, power_4, power_5, 0, t), front, back)[0]\n",
    "                            AG_fluence_err=np.sqrt((quadruply_broken_PL_derivative(Q, \\\n",
    "                                break_1, break_2, break_3, break_4, power_1, power_2, \\\n",
    "                                power_3, power_4, power_5, 0, front)*error_front)**2+(\\\n",
    "                                quadruply_broken_PL_derivative(Q, \\\n",
    "                                break_1, break_2, break_3, break_4, power_1, power_2, \\\n",
    "                                power_3, power_4, power_5, 0, back)*error_back)**2)\n",
    "                else:\n",
    "                    initial_value=triply_broken_PL(1, break_1, break_2, break_3, \\\n",
    "                                             power_1, power_2, power_3, power_4, \\\n",
    "                                             0, 11*60*60)\n",
    "                    Q=fsolve(lambda A: A*initial_value-float(more_xrt_data[' Flux_11 '][row]),\\\n",
    "                     0.01)[0]\n",
    "                    if abs(triply_broken_PL(Q, break_1, break_2, break_3, \\\n",
    "                            power_1, power_2, power_3, power_4,\\\n",
    "                            0, 24*60*60)-float(more_xrt_data[' Flux_24 '][row]))/\\\n",
    "                        (float(more_xrt_data[' Flux_24 '][row]))<0.05:\n",
    "                        AG_fluence=integrate.quad(lambda t: triply_broken_PL(Q, \\\n",
    "                                break_1, break_2, break_3, power_1, power_2, \\\n",
    "                                power_3, power_4, 0, t), front, back)[0]\n",
    "                        AG_fluence_err=np.sqrt((triply_broken_PL_derivative(Q, \\\n",
    "                                break_1, break_2, break_3, power_1, power_2, \\\n",
    "                                power_3, power_4, 0, front)*error_front)**2+(\\\n",
    "                                triply_broken_PL_derivative(Q, \\\n",
    "                                break_1, break_2, break_3, power_1, power_2, \\\n",
    "                                power_3, power_4, 0, back)*error_back)**2)\n",
    "            else:\n",
    "                initial_value=doubly_broken_PL(1, break_1, break_2, \\\n",
    "                                             power_1, power_2, power_3, \\\n",
    "                                             0, 11*60*60)\n",
    "                Q=fsolve(lambda A: A*initial_value-float(more_xrt_data[' Flux_11 '][row]),\\\n",
    "                     0.01)[0]\n",
    "                if abs(doubly_broken_PL(Q, break_1, break_2, power_1, power_2, power_3, \\\n",
    "                            0, 24*60*60)-float(more_xrt_data[' Flux_24 '][row]))/\\\n",
    "                        (float(more_xrt_data[' Flux_24 '][row]))<0.05:\n",
    "                    AG_fluence=integrate.quad(lambda t: doubly_broken_PL(Q, \\\n",
    "                                break_1, break_2, power_1, power_2, \\\n",
    "                                power_3, 0, t), front, back)[0]\n",
    "                    AG_fluence_err=np.sqrt((doubly_broken_PL_derivative(Q, \\\n",
    "                                break_1, break_2, power_1, power_2, \\\n",
    "                                power_3, 0, front)*error_front)**2+(\\\n",
    "                                doubly_broken_PL_derivative(Q, \\\n",
    "                                break_1, break_2, power_1, power_2, \\\n",
    "                                power_3, 0, back)*error_back)**2)\n",
    "        else:\n",
    "            initial_value=singly_broken_PL(1, break_1, power_1, power_2, 0, 11*60*60)\n",
    "            Q=fsolve(lambda A: A*initial_value-float(more_xrt_data[' Flux_11 '][row]),\\\n",
    "                     0.01)[0]\n",
    "            if abs(singly_broken_PL(Q, break_1, power_1, power_2, \\\n",
    "                            0, 24*60*60)-float(more_xrt_data[' Flux_24 '][row]))/\\\n",
    "                        (float(more_xrt_data[' Flux_24 '][row]))<0.05:\n",
    "                AG_fluence=integrate.quad(lambda t: singly_broken_PL(Q, \\\n",
    "                                break_1, power_1, power_2, 0, t), front, back)[0]\n",
    "                AG_fluence_err=np.sqrt(\\\n",
    "                                (singly_broken_PL_derivative(1, break_1, power_1, power_2,\\\n",
    "                                0, front)*error_front**2\\\n",
    "                                 +(singly_broken_PL_derivative(1, break_1, power_1, \\\n",
    "                                power_2, 0, back)*error_back)**2))\n",
    "    else:\n",
    "        AG_fluence=np.NaN\n",
    "    if len(np.where(spectral_sample_6_data['name'][i]==\\\n",
    "                       average_decay_data['Fermi name'])[0])>0:\n",
    "        decay_pos=int(np.where(spectral_sample_6_data['name'][i]==\\\n",
    "                           average_decay_data['Fermi name'])[0][0])\n",
    "    else:\n",
    "        decay_pos=np.NaN\n",
    "    AG_k=XRT_k_func(average_decay_data, decay_pos, rs)\n",
    "    AG_E_iso=4*np.pi*((d_lum)**2)*AG_fluence*AG_k/(1+rs)\n",
    "    AG_E_iso_err=4*np.pi*((d_lum)**2)*AG_fluence_err*AG_k/(1+rs)\n",
    "    Initial_2a_Data[j, 3]= AG_E_iso\n",
    "    Initial_2a_Data[j, 4]= AG_E_iso_err\n",
    "    Initial_2a_Data[j, 5]=spectral_sample_6_data['t90'][i]\n",
    "    if average_decay_data['nuFnu0'][decay_pos] != 0:\n",
    "        nFn=average_decay_data['nuFnu0'][decay_pos]\n",
    "    elif average_decay_data['nuFnu1'][decay_pos] != 0:\n",
    "        nFn=average_decay_data['nuFnu1'][decay_pos]\n",
    "    else:\n",
    "        nFn=np.NaN\n",
    "    beta_stage=int(spectral_sample_6_data['Plateau Stage'][i])\n",
    "    beta_string=' Gamma_{} (pc) '.format(beta_stage)\n",
    "    if weird_xrt_data.at[0, beta_string] != ' N/A ':\n",
    "        beta=(abs(float(weird_xrt_data.at[0, beta_string])-1))\n",
    "    elif weird_xrt_data.at[0, ' Gamma_{} (wt) '.format(beta_stage)]\\\n",
    "    !=' N/A ':\n",
    "        beta_string=' Gamma_{} (wt) '.format(beta_stage)\n",
    "        beta=(abs(float(weird_xrt_data.at[0, beta_string])-1))\n",
    "    else: \n",
    "        beta=np.NaN\n",
    "    time_string=' break_{} '.format(beta_stage-1)\n",
    "    # print(d_lum)\n",
    "    if time_string==' break_0 ':\n",
    "        time=0\n",
    "    elif more_xrt_data[time_string][row] != ' N/A ':\n",
    "        time=int(float(more_xrt_data[time_string][row]))\n",
    "    else:\n",
    "        time=np.NaN\n",
    "    E_k=kinetic_energy(nFn, beta, d_lum, rs, time, nu)\n",
    "    if E_k !=0:\n",
    "        eta=efficiency(E_k*1e52, E_iso)\n",
    "    else:\n",
    "        eta=np.NaN\n",
    "    Initial_2a_Data[j, 6]=eta\n",
    "    j=j+1\n",
    "Test_2a_Data=pd.DataFrame(Initial_2a_Data, columns=[\"Name\", \"Prompt E_iso\", \"Prompt_E_err\",\\\n",
    "                                                 \"Plateau E_iso\", \"Plat_E_err\", \"t90\",\\\n",
    "                                                    \"Efficiency\"])\n",
    "# outliers_mask=np.isin(Test_2a_Data[\"Name\"], \\\n",
    "#                 (150101641.0))\n",
    "No_Out_Test_2a_Data=Test_2a_Data\n",
    "short_mask=np.where(No_Out_Test_2a_Data[\"t90\"]<=2, True, False)\n",
    "Short_Test_2a_Data=No_Out_Test_2a_Data[short_mask]\n",
    "long_mask=np.where(No_Out_Test_2a_Data[\"t90\"]>2, True, False)\n",
    "Long_Test_2a_Data=No_Out_Test_2a_Data[long_mask]\n",
    "coefficients = np.polyfit(np.log10(No_Out_Test_2a_Data[\"Prompt E_iso\"]), \\\n",
    "                          np.log10(abs(No_Out_Test_2a_Data[\"Plateau E_iso\"])), 1)\n",
    "polynomial = np.poly1d(coefficients)\n",
    "log10_y_fit = polynomial(np.log10(No_Out_Test_2a_Data[\"Prompt E_iso\"]))\n",
    "plt.plot(Long_Test_2a_Data[\"Prompt E_iso\"], \\\n",
    "         abs(Long_Test_2a_Data[\"Plateau E_iso\"]), marker=\"*\", ls='none')\n",
    "plt.plot(Short_Test_2a_Data[\"Prompt E_iso\"], \\\n",
    "         abs(Short_Test_2a_Data[\"Plateau E_iso\"]), marker=\"o\", ls='none')\n",
    "plt.plot(No_Out_Test_2a_Data[\"Prompt E_iso\"], 10**log10_y_fit, '--')\n",
    "plt.legend(['Long GRBs', 'Short GRBs'])\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.tick_params(axis='x', colors='0.8')\n",
    "plt.tick_params(axis='y', colors='0.8')\n",
    "plt.xlabel(r\"Prompt Isotropic Energy (erg)\", color=\"0.8\")\n",
    "plt.ylabel(r\"Plateau Afterglow Isotropic Energy (erg)\", color=\"0.8\")\n",
    "plt.show()\n",
    "sm_mask=np.isin(No_Out_Test_2a_Data['Name'], \\\n",
    "                Overlap_Precursors[\"Short Mergers\"])\n",
    "lm_mask=np.isin(No_Out_Test_2a_Data['Name'], \\\n",
    "                Overlap_Precursors[\"Long Mergers\"])\n",
    "sc_mask=np.isin(No_Out_Test_2a_Data['Name'], \\\n",
    "                Overlap_Precursors[\"Short Collapsars\"])\n",
    "lc_mask=np.isin(No_Out_Test_2a_Data['Name'], \\\n",
    "                Overlap_Precursors[\"Long Collapsars\"])\n",
    "exo_mask=np.isin(No_Out_Test_2a_Data['Name'], \\\n",
    "                Overlap_Precursors[\"Potentially Exotic\"])\n",
    "iso_mask=np.isin(No_Out_Test_2a_Data['Name'], \\\n",
    "                Overlap_Precursors[\"Galactic Detected\"])\n",
    "Short_Test_2ab_Data=No_Out_Test_2a_Data[sm_mask|lm_mask|iso_mask]\n",
    "Long_Test_2ab_Data=No_Out_Test_2a_Data[sc_mask|lc_mask]\n",
    "Exotic_Test_2ab_Data=No_Out_Test_2a_Data[exo_mask]\n",
    "Unknown_Test_2ab_Data=No_Out_Test_2a_Data[~(lm_mask|lc_mask|sm_mask|sc_mask|exo_mask|iso_mask)]\n",
    "plt.plot(Long_Test_2ab_Data[\"Prompt E_iso\"], \\\n",
    "         abs(Long_Test_2ab_Data[\"Plateau E_iso\"]), marker=\"o\", ls='none')\n",
    "# plt.plot(Short_Test_2ab_Data[\"Prompt Luminosity\"], \\\n",
    "#          abs(Short_Test_1b_Data[\"Avg. Afterglow Decay Rate\"]), marker=\"o\", ls='none')\n",
    "# plt.plot(Exotic_Test_1b_Data[\"Prompt Luminosity\"], \\\n",
    "#          abs(Exotic_Test_1b_Data[\"Avg. Afterglow Decay Rate\"]), marker=\"o\", ls='none')\n",
    "plt.plot(Unknown_Test_2ab_Data[\"Prompt E_iso\"], \\\n",
    "         abs(Unknown_Test_2ab_Data[\"Plateau E_iso\"]), marker=\"*\", ls='none')\n",
    "plt.plot(No_Out_Test_2a_Data[\"Prompt E_iso\"], 10**log10_y_fit, '--')\n",
    "plt.legend(['Collapsar GRBs', 'Unknown Progenitor'])\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.tick_params(axis='x', colors='0.8')\n",
    "plt.tick_params(axis='y', colors='0.8')\n",
    "plt.xlabel(r\"Prompt Isotropic Energy (erg)\", color=\"0.8\")\n",
    "plt.ylabel(r\"Plateau Afterglow Isotropic Energy (erg)\", color=\"0.8\")\n",
    "plt.show()\n",
    "plt.plot(Long_Test_2ab_Data['t90'], \\\n",
    "         abs(Long_Test_2ab_Data['Efficiency']), marker=\"o\", ls='none')\n",
    "plt.plot(Unknown_Test_2ab_Data['t90'], \\\n",
    "         abs(Unknown_Test_2ab_Data['Efficiency']), marker=\"*\", ls='none')\n",
    "plt.legend(['Collapsar GRBs', 'Unknown Progenitor'])\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.tick_params(axis='x', colors='0.8')\n",
    "plt.tick_params(axis='y', colors='0.8')\n",
    "plt.xlabel(r\"t90 (GBM, s)\", color=\"0.8\")\n",
    "plt.ylabel(r\"Efficiency (calcualted, unitless)\", color=\"0.8\")\n",
    "Test_2a_Data.to_excel(\"Hypothesis_2a_Data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "186ec9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Hypothesis 2b##\n",
    "# Initial_2b_Data=np.zeros((len(sample_3_data),4))\n",
    "# j=0\n",
    "# for i in sample_3_data.index:\n",
    "#     flu=sample_3_data['GBM fluence'][i]\n",
    "#     Initial_2b_Data[j, 0]= sample_3_data['name'][i]\n",
    "#     Initial_2b_Data[j, 1]= flu\n",
    "#     backstop=int(sample_3_data['Plateau Stage'][i])\n",
    "#     row=sample_3_data['XRT row'][i]\n",
    "#     model_selector=more_xrt_data[' #breaks '][row]\n",
    "#     if model_selector>=1:\n",
    "#         break_1=int(float(more_xrt_data[' break_1 '][row]))\n",
    "#         power_1=-float(more_xrt_data[' alpha_1 '][row])\n",
    "#         power_2=-float(more_xrt_data[' alpha_2 '][row])\n",
    "#         if backstop==1:\n",
    "#             back=break_1\n",
    "#         if model_selector>=2:\n",
    "#             break_2=int(float(more_xrt_data[' break_2 '][row]))\n",
    "#             power_3=-float(more_xrt_data[' alpha_3 '][row])\n",
    "#             if backstop==2:\n",
    "#                 back=break_2\n",
    "#             if model_selector>=3:\n",
    "#                 break_3=int(float(more_xrt_data[' break_3 '][row]))\n",
    "#                 power_4=-float(more_xrt_data[' alpha_4 '][row])\n",
    "#                 if backstop==3:\n",
    "#                     back=break_3\n",
    "#                 if model_selector>=4:\n",
    "#                     break_4=int(float(more_xrt_data[' break_4 '][row]))\n",
    "#                     power_5=-float(more_xrt_data[' alpha_5 '][row])\n",
    "#                     if backstop==4:\n",
    "#                         back=break_4\n",
    "#                     if model_selector==5:\n",
    "#                         break_5=int(float(more_xrt_data[' break_5 '][row]))\n",
    "#                         power_6=-float(more_xrt_data[' alpha_6 '][row]) \n",
    "#                         if backstop==5:\n",
    "#                             back=break_5\n",
    "#                         initial_value=quintuply_broken_PL(1, break_1, break_2, break_3, \\\n",
    "#                                     break_4, break_5, power_1, power_2, power_3, power_4, \\\n",
    "#                                         power_5, power_6, 0, 11*60*60)\n",
    "#                         if more_xrt_data[' Flux_11 '][row] != ' N/A ':\n",
    "#                             Q=fsolve(lambda A: A*initial_value-float(more_xrt_data[' Flux_11 ']\\\n",
    "#                                                                      [row]), 1e8)[0]\n",
    "#                             if abs(quintuply_broken_PL(Q, break_1, break_2, break_3, break_4, \\\n",
    "#                                 break_5, power_1, power_2, power_3, power_4, power_5, power_6, \\\n",
    "#                             0, 24*60*60)-float(more_xrt_data[' Flux_24 '][row]))/\\\n",
    "#                         (float(more_xrt_data[' Flux_24 '][row]))<0.05:\n",
    "#                                 AG_flux=quintuply_broken_PL(Q, break_1, break_2, break_3,\\\n",
    "#                                 break_4, break_5, power_1, power_2, power_3, power_4,\\\n",
    "#                                     power_5, power_6, 0, back)\n",
    "#                             else:\n",
    "#                                 Q=fsolve(lambda A: A*initial_value-float(\\\n",
    "#                                         more_xrt_data[' Flux_24 '][row]),1e8)[0]\n",
    "#                                 AG_flux=quintuply_broken_PL(Q, break_1, break_2, break_3,\\\n",
    "#                                     break_4, break_5, power_1, power_2, power_3, power_4,\\\n",
    "#                                         power_5, power_6, 0, back)\n",
    "#                         elif more_xrt_data[' Flux_24 '][row] != ' N/A ':\n",
    "#                             Q=fsolve(lambda A: A*initial_value-float(more_xrt_data[' Flux_24 ']\\\n",
    "#                                                                      [row]), 1e8)[0]\n",
    "#                             AG_flux=quintuply_broken_PL(Q, break_1, break_2, break_3,\\\n",
    "#                                     break_4, break_5, power_1, power_2, power_3, power_4,\\\n",
    "#                                         power_5, power_6, 0, back)\n",
    "#                         else:\n",
    "#                             AG_flux=np.NaN\n",
    "#                     else:\n",
    "#                         initial_value=quadruply_broken_PL(1, break_1, break_2, break_3, break_4, \\\n",
    "#                                              power_1, power_2, power_3, power_4, power_5, \\\n",
    "#                                              0, 11*60*60)\n",
    "#                         if more_xrt_data[' Flux_11 '][row] != ' N/A ':\n",
    "#                             Q=fsolve(lambda A: A*initial_value-float(more_xrt_data[' Flux_11 ']\\\n",
    "#                                                                      [row]), 1e8)[0]\n",
    "#                             if abs(quadruply_broken_PL(Q, break_1, break_2, break_3, break_4, \\\n",
    "#                             power_1, power_2, power_3, power_4, power_5,\\\n",
    "#                             0, 24*60*60)-float(more_xrt_data[' Flux_24 '][row]))/\\\n",
    "#                         (float(more_xrt_data[' Flux_24 '][row]))<0.05:\n",
    "#                                 AG_flux=quadruply_broken_PL(Q, \\\n",
    "#                                 break_1, break_2, break_3, break_4, power_1, power_2, \\\n",
    "#                                 power_3, power_4, power_5, 0, back)\n",
    "#                             else:\n",
    "#                                 Q=fsolve(lambda A: A*initial_value-float(\\\n",
    "#                                     more_xrt_data[' Flux_24 '][row]),1e8)[0]\n",
    "#                                 AG_flux=quadruply_broken_PL(Q, break_1, break_2, break_3, \\\n",
    "#                                         break_4, power_1, power_2, power_3, power_4, \\\n",
    "#                                                             power_5, 0, back)\n",
    "#                         elif more_xrt_data[' Flux_24 '][row] != ' N/A ':\n",
    "#                             Q=fsolve(lambda A: A*initial_value-float(more_xrt_data[' Flux_24 ']\\\n",
    "#                                                                      [row]), 1e8)[0]\n",
    "#                             AG_flux=quadruply_broken_PL(Q, break_1, break_2, break_3, \\\n",
    "#                                         break_4, power_1, power_2, power_3, power_4, \\\n",
    "#                                                             power_5, 0, back)\n",
    "#                         else:\n",
    "#                             AG_flux=np.NaN\n",
    "                        \n",
    "#                 else:\n",
    "#                     initial_value=triply_broken_PL(1, break_1, break_2, break_3, \\\n",
    "#                                              power_1, power_2, power_3, power_4, \\\n",
    "#                                              0, 11*60*60)\n",
    "#                     if more_xrt_data[' Flux_11 '][row] != ' N/A ':\n",
    "#                         Q=fsolve(lambda A: A*initial_value-float(more_xrt_data[' Flux_11 ']\\\n",
    "#                                                                      [row]), 1e8)[0]\n",
    "#                         if abs(triply_broken_PL(Q, break_1, break_2, break_3, \\\n",
    "#                             power_1, power_2, power_3, power_4,\\\n",
    "#                             0, 24*60*60)-float(more_xrt_data[' Flux_24 '][row]))/\\\n",
    "#                         (float(more_xrt_data[' Flux_24 '][row]))<0.05:\n",
    "#                             AG_flux=triply_broken_PL(Q, break_1, break_2, break_3, \\\n",
    "#                                     power_1, power_2, power_3, power_4, 0, back)\n",
    "#                         else:\n",
    "#                             Q=fsolve(lambda A: A*initial_value-float(\\\n",
    "#                                 more_xrt_data[' Flux_24 '][row]), 1e8)[0]\n",
    "#                             AG_flux=triply_broken_PL(Q, break_1, break_2, break_3, \\\n",
    "#                                     power_1, power_2, power_3, power_4, 0, back)\n",
    "#                     elif more_xrt_data[' Flux_24 '][row] != ' N/A ':\n",
    "#                         Q=fsolve(lambda A: A*initial_value-float(more_xrt_data[' Flux_24 ']\\\n",
    "#                                                                      [row]), 1e8)[0]\n",
    "#                         AG_flux=triply_broken_PL(Q, break_1, break_2, break_3, \\\n",
    "#                                     power_1, power_2, power_3, power_4, 0, back)\n",
    "#                     else:\n",
    "#                         AG_flux=np.NA\n",
    "#             else:\n",
    "#                 initial_value=doubly_broken_PL(1, break_1, break_2, \\\n",
    "#                                              power_1, power_2, power_3, \\\n",
    "#                                              0, 11*60*60)\n",
    "#                 if more_xrt_data[' Flux_11 '][row] != ' N/A ':\n",
    "#                     Q=fsolve(lambda A: A*initial_value-float(more_xrt_data[' Flux_11 ']\\\n",
    "#                                                                      [row]), 1e8)[0]\n",
    "#                     if abs(doubly_broken_PL(Q, break_1, break_2, power_1, power_2, power_3, \\\n",
    "#                             0, 24*60*60)-float(more_xrt_data[' Flux_24 '][row]))/\\\n",
    "#                         (float(more_xrt_data[' Flux_24 '][row]))<0.05:\n",
    "#                         AG_flux=doubly_broken_PL(Q, break_1, break_2, power_1, power_2, \\\n",
    "#                                     power_3, 0, back)\n",
    "#                     else:\n",
    "#                         Q=fsolve(lambda A: A*initial_value-float(more_xrt_data[' Flux_24 '][row]),\\\n",
    "#                          1e8)[0]\n",
    "#                         AG_flux=doubly_broken_PL(Q, break_1, break_2, power_1, power_2, \\\n",
    "#                                     power_3, 0, back)\n",
    "#                 elif more_xrt_data[' Flux_24 '][row] != ' N/A ':\n",
    "#                     Q=fsolve(lambda A: A*initial_value-float(more_xrt_data[' Flux_24 ']\\\n",
    "#                                                                      [row]), 1e8)[0]\n",
    "#                     AG_flux=doubly_broken_PL(Q, break_1, break_2, power_1, power_2, \\\n",
    "#                                     power_3, 0, back)\n",
    "#                 else:\n",
    "#                     AG_flux=np.NaN\n",
    "#         else:\n",
    "#             initial_value=singly_broken_PL(1, break_1, power_1, power_2, 0, 11*60*60)\n",
    "#             if more_xrt_data[' Flux_11 '][row] != ' N/A ':\n",
    "#                 Q=fsolve(lambda A: A*initial_value-float(more_xrt_data[' Flux_11 '][row]),\\\n",
    "#                          1e8)[0]\n",
    "#                 if abs(singly_broken_PL(Q, break_1, power_1, power_2, \\\n",
    "#                             0, 24*60*60)-float(more_xrt_data[' Flux_24 '][row]))/\\\n",
    "#                         (float(more_xrt_data[' Flux_24 '][row]))<0.05:\n",
    "#                     AG_flux=singly_broken_PL(Q, break_1, power_1, power_2, 0, back)\n",
    "#                 else:\n",
    "#                     Q=fsolve(lambda A: A*initial_value-float(more_xrt_data[' Flux_24 '][row]),\\\n",
    "#                          1e8)[0]\n",
    "#                     AG_flux=singly_broken_PL(Q, break_1, power_1, power_2, 0, back)\n",
    "#             elif more_xrt_data[' Flux_24 '][row] != ' N/A ':\n",
    "#                 Q=fsolve(lambda A: A*initial_value-float(more_xrt_data[' Flux_24 '][row]),\\\n",
    "#                          1e8)[0]\n",
    "#                 AG_flux=singly_broken_PL(Q, break_1, power_1, power_2, 0, back)\n",
    "#             else:\n",
    "#                 AG_flux=np.NaN\n",
    "#     else:\n",
    "#         AG_flux=np.NaN\n",
    "#     Initial_2b_Data[j, 2]= AG_flux\n",
    "#     Initial_2b_Data[j, 3]=sample_3_data['t90'][i]\n",
    "#     j=j+1\n",
    "# Test_2b_Data=pd.DataFrame(Initial_2b_Data, columns=[\"Name\", \"Prompt Fluence\",\\\n",
    "#                                                  \"End-Plateau Flux\", \"t90\"])\n",
    "# # outliers_mask=np.isin(Test_2a_Data[\"Name\"], \\\n",
    "# #                 (150101641.0))\n",
    "# # No_Out_Test_2b_Data=Test_2b_Data[~outliers_mask]\n",
    "# short_mask=np.where(Test_2b_Data[\"t90\"]<=2, True, False)\n",
    "# Short_Test_2b_Data=Test_2b_Data[short_mask]\n",
    "# long_mask=np.where(Test_2b_Data[\"t90\"]>2, True, False)\n",
    "# Long_Test_2b_Data=Test_2b_Data[long_mask]\n",
    "# plt.plot(Long_Test_2b_Data[\"Prompt Fluence\"], \\\n",
    "#          abs(Long_Test_2b_Data[\"End-Plateau Flux\"]), marker=\"*\", ls='none')\n",
    "# plt.plot(Short_Test_2b_Data[\"Prompt Fluence\"], \\\n",
    "#          abs(Short_Test_2b_Data[\"End-Plateau Flux\"]), marker=\"o\", ls='none')\n",
    "# plt.legend(['Long GRBs', 'Short GRBs'])\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.8')\n",
    "# plt.tick_params(axis='y', colors='0.8')\n",
    "# plt.xlabel(r\"Prompt Fluence (erg$cm^{-2}$)\", color=\"0.8\")\n",
    "# plt.ylabel(r\"End-Plateau Afterglow Flux (photons$s^{-1}$$cm^2$)\", color=\"0.8\")\n",
    "# plt.show()\n",
    "# sm_mask=np.isin(Test_2b_Data['Name'], \\\n",
    "#                 Overlap_Precursors[\"Short Mergers\"])\n",
    "# lm_mask=np.isin(Test_2b_Data['Name'], \\\n",
    "#                 Overlap_Precursors[\"Long Mergers\"])\n",
    "# sc_mask=np.isin(Test_2b_Data['Name'], \\\n",
    "#                 Overlap_Precursors[\"Short Collapsars\"])\n",
    "# lc_mask=np.isin(Test_2b_Data['Name'], \\\n",
    "#                 Overlap_Precursors[\"Long Collapsars\"])\n",
    "# exo_mask=np.isin(Test_2b_Data['Name'], \\\n",
    "#                 Overlap_Precursors[\"Potentially Exotic\"])\n",
    "# iso_mask=np.isin(Test_2b_Data['Name'], \\\n",
    "#                 Overlap_Precursors[\"Galactic Detected\"])\n",
    "# Short_Test_2bb_Data=Test_2b_Data[sm_mask|lm_mask|iso_mask]\n",
    "# Long_Test_2bb_Data=Test_2b_Data[sc_mask|lc_mask]\n",
    "# Exotic_Test_2bb_Data=Test_2b_Data[exo_mask]\n",
    "# Unknown_Test_2bb_Data=Test_2b_Data[~(lm_mask|lc_mask|sm_mask|sc_mask|exo_mask|iso_mask)]\n",
    "# plt.plot(Long_Test_2bb_Data[\"Prompt Fluence\"], \\\n",
    "#          abs(Long_Test_2bb_Data[\"End-Plateau Flux\"]), marker=\"o\", ls='none')\n",
    "# plt.plot(Short_Test_2bb_Data[\"Prompt Fluence\"], \\\n",
    "#          abs(Short_Test_2bb_Data[\"End-Plateau Flux\"]), marker=\"o\", ls='none')\n",
    "# # plt.plot(Exotic_Test_1b_Data[\"Prompt Luminosity\"], \\\n",
    "# #          abs(Exotic_Test_1b_Data[\"Avg. Afterglow Decay Rate\"]), marker=\"o\", ls='none')\n",
    "# plt.plot(Unknown_Test_2bb_Data[\"Prompt Fluence\"], \\\n",
    "#          abs(Unknown_Test_2bb_Data[\"End-Plateau Flux\"]), marker=\"*\", ls='none')\n",
    "# plt.legend(['Collapsar GRBs', 'Merger GRBs', 'Unknown Progenitor'])\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.8')\n",
    "# plt.tick_params(axis='y', colors='0.8')\n",
    "# plt.xlabel(r\"Prompt Fluence (erg$cm^{-2}$)\", color=\"0.8\")\n",
    "# plt.ylabel(r\"Plateau Afterglow Flux (photons$s^{-1}$$cm^2$)\", color=\"0.8\")\n",
    "# plt.show()\n",
    "# Test_2b_Data.to_excel(\"Hypothesis_2b_Data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3655b1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Gehrels Hypothesis##\n",
    "# # print(int(sample_6_data[\"XRT row\"][sample_6_data.index[0]]))\n",
    "# # print(int(sample_6_data[\"Plateau Stage\"][sample_6_data.index[0]]))\n",
    "# # read_string=\" Gamma_{} (pc) \".\\\n",
    "# # format(int(sample_6_data[\"Plateau Stage\"][sample_6_data.index[0]]))\n",
    "# # spectral_mask=np.isin(sample_3_data['Spectral Model'], 0.0)\n",
    "# # spectral_sample_3_data=sample_3_data[~spectral_mask]\n",
    "# #not really \"necessary\", but I find it saves me a little time\n",
    "# Initial_Gehrels_S3_Data=np.zeros((len(sample_3_data.index),4))\n",
    "# Initial_Gehrels_S6_Data=np.zeros((len(spectral_sample_6_data.index),4))\n",
    "# j=0\n",
    "# for i in spectral_sample_6_data.index:\n",
    "#     rs=spectral_sample_6_data['Likely Redshift'][i]\n",
    "#     flu=spectral_sample_6_data['GBM fluence'][i]\n",
    "#     d_lum=((2*speed_light)/H_0)*(1-np.sqrt(1/(1+rs)))*(1+rs)\n",
    "#     ghostie=spectral_sample_6_data['Spectral Model'][i]\n",
    "#     #get it, ghostie becuase it's the SPEC-trum. I guess code isn't the time to make jokes.\n",
    "#     fermi_placement= spectral_sample_6_data['Fermi row'][i]\n",
    "#     #at least this one is descriptive\n",
    "#     k=Fermi_k_func(sample_2_data, ghostie, fermi_placement, rs)\n",
    "#     E_iso=4*np.pi*((d_lum)**2)*flu*k/(1+rs)\n",
    "#     Initial_Gehrels_S6_Data[j, 0]= spectral_sample_6_data['name'][i]\n",
    "#     Initial_Gehrels_S6_Data[j, 1]= E_iso\n",
    "#     late_flux=more_xrt_data[' Flux_11 '][int(spectral_sample_6_data[\"XRT row\"][i])]\n",
    "#     if late_flux != ' N/A ':\n",
    "#         Initial_Gehrels_S6_Data[j, 2]=late_flux\n",
    "#     else:\n",
    "#         Initial_Gehrels_S6_Data[j, 2]=np.NaN\n",
    "#     Initial_Gehrels_S6_Data[j, 3]=spectral_sample_6_data['t90'][i]\n",
    "#     j=j+1\n",
    "# j=0\n",
    "# for i in sample_3_data.index:\n",
    "#     flu=sample_3_data['GBM fluence'][i]\n",
    "#     Initial_Gehrels_S3_Data[j, 0]= sample_3_data['name'][i]\n",
    "#     Initial_Gehrels_S3_Data[j, 1]= flu\n",
    "#     late_flux=more_xrt_data[' Flux_11 '][int(sample_3_data[\"XRT row\"][i])]\n",
    "#     if late_flux != ' N/A ':\n",
    "#         Initial_Gehrels_S3_Data[j, 2]=late_flux\n",
    "#     else:\n",
    "#         Initial_Gehrels_S3_Data[j, 2]=np.NaN\n",
    "#     Initial_Gehrels_S3_Data[j, 3]=sample_3_data['t90'][i]\n",
    "#     j=j+1\n",
    "# Gehrels_Sample_3_Data=pd.DataFrame(Initial_Gehrels_S3_Data, columns=[\"Name\", \"Prompt_Flu\",\\\n",
    "#                                                  \"X-ray_F11\", \"t90\"])\n",
    "# Gehrels_Sample_6_Data=pd.DataFrame(Initial_Gehrels_S6_Data, columns=[\"Name\", \"Prompt_E_iso\",\\\n",
    "#                                                 \"X-ray_F11\", \"t90\"])\n",
    "# short_mask=np.where(Gehrels_Sample_3_Data[\"t90\"]<=2, True, False)\n",
    "# Short_Gehrels_Sample_3=Gehrels_Sample_3_Data[short_mask]\n",
    "# long_mask=np.where(Gehrels_Sample_3_Data[\"t90\"]>2, True, False)\n",
    "# Long_Gehrels_Sample_3=Gehrels_Sample_3_Data[long_mask]\n",
    "# coefficients = np.polyfit(np.log10(Gehrels_Sample_3_Data[\"Prompt_Flu\"]), \\\n",
    "#                           np.log10(abs(Gehrels_Sample_3_Data[\"X-ray_F11\"])), 1)\n",
    "# polynomial = np.poly1d(coefficients)\n",
    "# log10_y_fit = polynomial(np.log10(Gehrels_Sample_3_Data[\"Prompt_Flu\"]))\n",
    "# plt.plot(Long_Gehrels_Sample_3[\"Prompt_Flu\"], \\\n",
    "#          abs(Long_Gehrels_Sample_3[\"X-ray_F11\"]), marker=\"*\", ls='none')\n",
    "# plt.plot(Short_Gehrels_Sample_3[\"Prompt_Flu\"], \\\n",
    "#          abs(Short_Gehrels_Sample_3[\"X-ray_F11\"]), marker=\"o\", ls='none')\n",
    "# plt.plot(Gehrels_Sample_3_Data[\"Prompt_Flu\"], 10**log10_y_fit, '--')\n",
    "# plt.legend(['Long GRBs', 'Short GRBs'])\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.8')\n",
    "# plt.tick_params(axis='y', colors='0.8')\n",
    "# plt.xlabel(r\"Prompt Fluence (erg $cm^{-2}$)\", color=\"0.8\")\n",
    "# plt.ylabel(r\"11-Hour Afterglow X-ray Flux ((erg $cm^{-2}$ $s^{-1}$)\", color=\"0.8\")\n",
    "# plt.show()\n",
    "# ##\n",
    "# sm_mask=np.isin(Gehrels_Sample_6_Data['Name'], \\\n",
    "#                 Overlap_Precursors[\"Short Mergers\"])\n",
    "# lm_mask=np.isin(Gehrels_Sample_6_Data['Name'], \\\n",
    "#                 Overlap_Precursors[\"Long Mergers\"])\n",
    "# sc_mask=np.isin(Gehrels_Sample_6_Data['Name'], \\\n",
    "#                 Overlap_Precursors[\"Short Collapsars\"])\n",
    "# lc_mask=np.isin(Gehrels_Sample_6_Data['Name'], \\\n",
    "#                 Overlap_Precursors[\"Long Collapsars\"])\n",
    "# exo_mask=np.isin(Gehrels_Sample_6_Data['Name'], \\\n",
    "#                 Overlap_Precursors[\"Potentially Exotic\"])\n",
    "# iso_mask=np.isin(Gehrels_Sample_6_Data['Name'], \\\n",
    "#                 Overlap_Precursors[\"Galactic Detected\"])\n",
    "# Short_Gehrels_Sample_6=Gehrels_Sample_6_Data[sm_mask|lm_mask|iso_mask]\n",
    "# Long_Gehrels_Sample_6=Gehrels_Sample_6_Data[sc_mask|lc_mask]\n",
    "# Exotic_Gehrels_Sample_6=Gehrels_Sample_6_Data[exo_mask]\n",
    "# Unknown_Gehrels_Sample_6=Gehrels_Sample_6_Data[~(lm_mask|lc_mask|sm_mask|sc_mask|exo_mask|iso_mask)]\n",
    "# coefficients = np.polyfit(np.log10(Gehrels_Sample_6_Data[\"Prompt_E_iso\"]), \\\n",
    "#                           np.log10(abs(Gehrels_Sample_6_Data[\"X-ray_F11\"])), 1)\n",
    "# polynomial = np.poly1d(coefficients)\n",
    "# log10_y_fit = polynomial(np.log10(Gehrels_Sample_6_Data[\"Prompt_E_iso\"]))\n",
    "# plt.plot(Long_Gehrels_Sample_6[\"Prompt_E_iso\"], \\\n",
    "#          abs(Long_Gehrels_Sample_6[\"X-ray_F11\"]), marker=\"*\", ls='none')\n",
    "# plt.plot(Short_Gehrels_Sample_6[\"Prompt_E_iso\"], \\\n",
    "#          abs(Short_Gehrels_Sample_6[\"X-ray_F11\"]), marker=\"o\", ls='none')\n",
    "# # plt.plot(Exotic_Test_1b_Data[\"Prompt Luminosity\"], \\\n",
    "# #          abs(Exotic_Test_1b_Data[\"Avg. Afterglow Decay Rate\"]), marker=\"o\", ls='none')\n",
    "# plt.plot(Unknown_Gehrels_Sample_6[\"Prompt_E_iso\"], \\\n",
    "#          abs(Unknown_Gehrels_Sample_6[\"X-ray_F11\"]), marker=\".\", ls='none')\n",
    "# plt.plot(Gehrels_Sample_6_Data[\"Prompt_E_iso\"], 10**log10_y_fit, '--')\n",
    "# plt.legend(['Collapsar GRBs', 'Merger GRBs', 'Unknown Progenitor'])\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.8')\n",
    "# plt.tick_params(axis='y', colors='0.8')\n",
    "# plt.xlabel(r\"Prompt $E_{iso}$ (erg $cm^{-2}$)\", color=\"0.8\")\n",
    "# plt.ylabel(r\"11-Hour Afterglow X-ray Flux ((erg $cm^{-2}$ $s^{-1}$)\", color=\"0.8\")\n",
    "# plt.show()\n",
    "# Gehrels_Sample_3_Data.to_excel(\"Gehrels_Sample_3_Data.xlsx\")\n",
    "# Gehrels_Sample_6_Data.to_excel(\"Gehrels_Sample_6_Data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cc29994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Hypothesis 4b##\n",
    "# from sklearn.cluster import KMeans\n",
    "# # from sklearn.cluster import DBSCAN\n",
    "# swift_every_HR=[]\n",
    "# swift_every_HR_err=np.zeros((1,2))\n",
    "# fermi_every_HR=[]\n",
    "# # swift_every_t90=[]\n",
    "# # swift_every_t90_err=[]\n",
    "# every_t90=[]\n",
    "# # every_t90_err=[]\n",
    "# every_Epeak_over_s=[]\n",
    "# every_E_Peak=[]\n",
    "# every_fluence=[]\n",
    "# for i in sample_2_data.index.to_list():\n",
    "#     every_t90=np.append(every_t90, float(sample_2_data.at[i, 't90     ']))\n",
    "#     every_Epeak_over_s=np.append(every_Epeak_over_s, \\\n",
    "#                         (getting_the_GBM_E_peak(sample_2_data, \\\n",
    "#                                     sample_2_data.at[i, 'flnc_best_fitting_model'], i))/\\\n",
    "#                                        float(sample_2_data.at[i, 'fluence   ']))\n",
    "# new_bins=np.logspace(5,13, 81)\n",
    "# plt.hist(every_Epeak_over_s, bins=new_bins)\n",
    "# plt.xscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.8')\n",
    "# plt.tick_params(axis='y', colors='0.8')\n",
    "# plt.xlabel(r\"$E_{peak}$/$Fluence_{10-1000keV}$ cm^2\", color=\"0.8\")\n",
    "# plt.ylabel(\"Number of Bursts\", color=\"0.8\")\n",
    "# plt.show()\n",
    "# E_p_S_data_0=np.column_stack((np.array(every_Epeak_over_s), np.array(every_t90)))\n",
    "# E_p_S_data_1=E_p_S_data_0[~np.isnan(E_p_S_data_0[:,0])]\n",
    "# plt.plot(E_p_S_data_1[:, 0], E_p_S_data_1[:, 1], ls='none', marker='o')\n",
    "# plt.xscale('log')\n",
    "# plt.xlabel(r\"$E_{peak}$/$Fluence_{10-1000keV}$ cm^2\", color=\"0.8\")\n",
    "# plt.yscale('log')\n",
    "# plt.ylabel(r\"$t_{90}$ (s) \", color=\"0.8\")\n",
    "# plt.show()\n",
    "# Kmean = KMeans(init=\"random\", n_clusters=3, n_init=10, max_iter=300, random_state=47)\n",
    "# Kmean.fit(E_p_S_data_1)\n",
    "# Kmean.cluster_centers_\n",
    "# # dbscan = DBSCAN(eps=1000, min_samples=5)\n",
    "# # dbscan.fit(E_p_S_data_1)\n",
    "# ##\n",
    "# from sklearn.metrics import silhouette_score\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# plt.scatter(unknown_progenitor_Epeak_over_s, unknown_progenitor_t90, marker='.', color='k')\n",
    "# plt.scatter(long_collapsar_Epeak_over_s, long_collapsar_t90, marker='o', color='r')\n",
    "# plt.scatter(short_merger_Epeak_over_s, short_merger_t90, marker='o', color='b')\n",
    "# plt.scatter(1.78748769e+09, 3.78496091e+01, s=100, color='g', marker='*')\n",
    "# plt.scatter(6.29797312e+11, 1.71841250e+01, s=100, color='orange', marker='*')\n",
    "# plt.scatter(5.40095095e+12, 5.91360000e+01, s=100, color='purple', marker='*')\n",
    "# plt.legend(['Unknown Progenitor', 'Long Collapsars', 'Short Mergers'])\n",
    "# plt.xscale('log')\n",
    "# plt.xlabel(r\"$E_{peak}$/$Fluence_{10-1000keV}$ cm^2\", color=\"0.8\")\n",
    "# plt.yscale('log')\n",
    "# plt.ylabel(r\"$t_{90}$ (s)\", color=\"0.8\")\n",
    "# plt.show()\n",
    "# scaler = StandardScaler()\n",
    "# scaled_features = scaler.fit_transform( E_p_S_data_1)\n",
    "# kmeans_silhouette = silhouette_score(E_p_S_data_1, Kmean.labels_).round(2)\n",
    "# # dbscan_silhouette = silhouette_score(E_p_S_data_1, dbscan.labels_).round(1)\n",
    "# fig, (ax1) = plt.subplots(1, figsize=(8, 6), sharex=True, sharey=True)\n",
    "# fig.suptitle(f\"Clustering Algorithm Comparison: E_p over Fluence v. t90\", fontsize=16,\\\n",
    "#              color=\"0.8\")\n",
    "# fte_colors = {0: \"#008fd5\", 1: \"#fc4f30\", 2: '#b163a3'}\n",
    "# km_colors = [fte_colors[label] for label in Kmean.labels_]\n",
    "# ax1.scatter(E_p_S_data_1[:, 0], E_p_S_data_1[:, 1], c=km_colors)\n",
    "# ax1.set_title(f\"k-means\\nSilhouette: {kmeans_silhouette}\", fontdict={\"fontsize\": 12})\n",
    "# # db_colors = [fte_colors[label] for label in dbscan.labels_]\n",
    "# # ax1.scatter(E_p_S_data_1[:, 0], E_p_S_data_1[:, 1], c=db_colors)\n",
    "# # ax1.set_title(f\"DBSCAN\\nSilhouette: {dbscan_silhouette}\", fontdict={\"fontsize\": 12})\n",
    "# plt.xscale('log')\n",
    "# plt.xlabel(r\"$E_{peak}$/$Fluence_{10-1000keV}$ cm^2\", color=\"0.8\")\n",
    "# plt.yscale('log')\n",
    "# plt.ylabel(r\"$t_{90}$ (s)\", color=\"0.8\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30d57e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b5cb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # valid_fluences=swift_fluences.drop(index=removals[:-2])\n",
    "# # actually_valid_mask=np.isin(valid_fluences.index, (redshift_swift_data.index))\n",
    "# # actually_valid_fluences=valid_fluences[actually_valid_mask]\n",
    "# # fluence_mask=np.isin(actually_valid_fluences[' 25_50kev '], (\" N/A\", \" N/A \", 0), invert=True)\n",
    "# # fluence_available_swift_data=redshift_swift_data[fluence_mask]\n",
    "# # valid_fluences=swift_fluences.drop(index=tiny_removals[:-2])\n",
    "# # actually_valid_mask=np.isin(valid_fluences.index, (sample_0_data.index))\n",
    "# # actually_valid_fluences=valid_fluences[actually_valid_mask]\n",
    "# # fluence_mask=np.isin(actually_valid_fluences[' 25_50kev '], (\" N/A\", \" N/A \", 0), \\\n",
    "# #                      invert=True)\n",
    "# # fluence_available_swift_data=sample_0_data[fluence_mask]\n",
    "# # inverted_mask=np.isin(Known_Precursors[\"Galactic Detected\"], \\\n",
    "# #                       fluence_available_swift_data['GRBname '])\n",
    "# inverted_mask=np.isin(Known_Precursors[\"Galactic Detected\"], \\\n",
    "#                       sample_0_data['GRBname '])\n",
    "# seen_precursors=np.array(Known_Precursors[\"Galactic Detected\"])[inverted_mask]\n",
    "# print(seen_precursors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba395feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(sample_6_data['name'].to_list())\n",
    "# print(sample_6_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc5ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy_listicle=range(10, 1000, 10)\n",
    "# PL_value=np.zeros(len(energy_listicle))\n",
    "# ZPL_value=np.zeros(len(energy_listicle))\n",
    "# CPL_value=np.zeros(len(energy_listicle))\n",
    "# Band_value=np.zeros(len(energy_listicle))\n",
    "# SBPL_value=np.zeros(len(energy_listicle))\n",
    "# for i in range(0, len(energy_listicle)):\n",
    "#     PL_value[i]=energy_listicle[i]*power_law(energy_listicle[i], -1.5)\n",
    "#     ZPL_value[i]=energy_listicle[i]*z_power_law(energy_listicle[i], -1.5, 10)\n",
    "#     CPL_value[i]=energy_listicle[i]*Compton_PL(energy_listicle[i], -1.5, 95)\n",
    "#     Band_value[i]=energy_listicle[i]*Band_function(energy_listicle[i], 71, -1, -2.8)\n",
    "#     SBPL_value[i]=energy_listicle[i]*\\\n",
    "#     Smoothly_Broken_PL(energy_listicle[i], 95, -1.5, -12, 0.8)\n",
    "# plt.plot(energy_listicle, PL_value)\n",
    "# plt.plot(energy_listicle, ZPL_value)\n",
    "# plt.plot(energy_listicle, CPL_value)\n",
    "# plt.plot(energy_listicle, Band_value)\n",
    "# plt.plot(energy_listicle, SBPL_value)\n",
    "# plt.legend(['Power Law', 'Redshifted Power Law', 'Comptonized Power Law', 'Band Function', \\\n",
    "#             'SBPL'])\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "# plt.tick_params(axis='x', colors='0.8')\n",
    "# plt.tick_params(axis='y', colors='0.8')\n",
    "# plt.xlabel(r\"Energy (keV)\", color=\"0.8\")\n",
    "# plt.ylabel(r\"E*f(E) (photons keV $cm^{-2} s^{-1}$)\", color=\"0.8\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fe3391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectral_mask=np.isin(sample_6_data['Spectral Model'], 0.0)\n",
    "# spectral_sample_6_data=sample_6_data[~spectral_mask]\n",
    "# print(spectral_sample_6_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bed2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(H_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdacc835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decay_pos=int(np.where(spectral_sample_6_data['name'][spectral_sample_6_data.index[0]]==\\\n",
    "#                        average_decay_data['Fermi name'])[0][0])\n",
    "# rs=spectral_sample_6_data['Likely Redshift'][spectral_sample_6_data.index[0]]\n",
    "# AG_k=XRT_k_func(average_decay_data, decay_pos, rs)\n",
    "# 4*np.pi*((d_lum)**2)*AG_fluence*AG_k/(1+rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39b6704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(No_Out_Test_1_Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2ec30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stripped_redshifts=[]\n",
    "# for i in range(0, len(swift_redshifts)):\n",
    "#     stripped_redshifts=np.append(stripped_redshifts, swift_redshifts['GRBname '][i].strip())\n",
    "# redshift_mask=np.isin(second_redshifts['GRB'], stripped_redshifts)\n",
    "# by_hand_redshifts=second_redshifts[~redshift_mask]\n",
    "# by_hand_redshifts['GRB'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1583d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edited_swift_data['GRBname '].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29392d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # np.where(edited_swift_data['GRBname ']==\"{}   \".format(second_redshifts['GRB'][16]))\n",
    "# # print(Short_Test_2bb_Data)\n",
    "# # spectral_sample_6_data.columns\n",
    "# # Goldstein_Sample_6_Data\n",
    "# # spectral_mask=np.isin(sample_6_data['Spectral Model'], 0.0)\n",
    "# # spectral_sample_6_data=sample_6_data[~spectral_mask]\n",
    "# # print(len(spectral_sample_6_data))\n",
    "\n",
    "# #literally the position in the decay array\n",
    "# # for i in spectral_sample_6_data.index:\n",
    "# #     if len(np.where(spectral_sample_6_data['name'][i]==\\\n",
    "# #                        average_decay_data['Fermi name'])[0])>0:\n",
    "# #         decay_pos=np.where(spectral_sample_6_data['name'][i]==\\\n",
    "# #                            average_decay_data['Fermi name'])[0][0]\n",
    "# #         if average_decay_data['nuFnu0'][decay_pos] != 0:\n",
    "# #             print(average_decay_data['nuFnu0'][decay_pos])\n",
    "# #         elif average_decay_data['nuFnu1'][decay_pos] != 0:\n",
    "# #             print(average_decay_data['nuFnu1'][decay_pos])\n",
    "# #         else:\n",
    "# #             print(\"couldn't find a flux density for GRB {}\".\\\n",
    "# #                   format(average_decay_data['name'][decay_pos]))\n",
    "# for i in spectral_sample_6_data.index:\n",
    "#     print(spectral_sample_6_data.at[spectral_sample_6_data.index[i], 'Plateau Stage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22028b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Goldstein_Sample_2_Data['Name'][-100:-1].to_list()\n",
    "# # mylist=Goldstein_Sample_2_Data['Name'].to_list()\n",
    "# # [i for i, x in enumerate(mylist) if mylist.count(x) > 1]\n",
    "# # \n",
    "# speed_light=3e10 #now in cm/s\n",
    "# H_0=70*10**5/(3.086e24)\n",
    "# for i in spectral_sample_6_data.index:\n",
    "#     decay_pos=np.where(spectral_sample_6_data['name'][i]==\\\n",
    "#                        average_decay_data['Fermi name'])[0][0]\n",
    "#     if average_decay_data['nuFnu0'][decay_pos] != 0:\n",
    "#         nFn=average_decay_data['nuFnu0'][decay_pos]\n",
    "#     elif average_decay_data['nuFnu1'][decay_pos] != 0:\n",
    "#         nFn=average_decay_data['nuFnu1'][decay_pos]\n",
    "#     else:\n",
    "#         nFn=np.NaN\n",
    "#     beta_stage=int(spectral_sample_6_data['Plateau Stage'][i])\n",
    "#     beta_string=' Gamma_{} (pc) '.format(beta_stage)\n",
    "#     if weird_xrt_data.at[0, beta_string] != ' N/A ':\n",
    "#         beta=(abs(float(weird_xrt_data.at[0, beta_string])-1))\n",
    "#     elif weird_xrt_data.at[0, ' Gamma_{} (wt) '.format(beta_stage)]\\\n",
    "#     !=' N/A ':\n",
    "#         beta_string=' Gamma_{} (wt) '.format(beta_stage)\n",
    "#         beta=(abs(float(weird_xrt_data.at[0, beta_string])-1))\n",
    "#     else: \n",
    "#         beta=np.NaN\n",
    "#     rs=spectral_sample_6_data['Likely Redshift'][i]\n",
    "#     flu=spectral_sample_6_data['GBM fluence'][i]\n",
    "#     d_lum=((2*speed_light)/H_0)*(1-np.sqrt(1/(1+rs)))*(1+rs)\n",
    "#     time_string=' break_{} '.format(beta_stage-1)\n",
    "#     # print(d_lum)\n",
    "#     if time_string==' break_0 ':\n",
    "#         time=0\n",
    "#     elif more_xrt_data[time_string][row] != ' N/A ':\n",
    "#         time=int(float(more_xrt_data[time_string][row]))\n",
    "#     else:\n",
    "#         time=np.NaN\n",
    "#     nu_low=10/(4.135e-12) #Wikipedia gives it as this value E-15 eV per Hz, and \n",
    "#     #fermi is most sensitive between 10 and 1,000 keV\n",
    "#     nu_high=(1000)/(4.135e-12)\n",
    "# #     E_k=integrate.quad(lambda nu: kinetic_energy(nFn, beta, d_lum, rs, time, nu), \\\n",
    "# #                          nu_low, nu_high)\n",
    "#     # print(integrate.quad(lambda nu: kinetic_energy(nFn, beta, d_lum, rs, time, nu), \\\n",
    "#     #                      nu_low, nu_high))\n",
    "#     nu=speed_light/(10**(18))\n",
    "#     E_k=kinetic_energy(nFn, beta, d_lum, rs, time, nu)\n",
    "#     # print(E_k)\n",
    "#     E_iso=4*np.pi*((d_lum)**2)*flu*k/(1+rs)\n",
    "#     # print(4*np.pi*((d_lum)**2)*flu*k/(1+rs))\n",
    "#     print(efficiency(E_k*1e52, E_iso))\n",
    "#     # print(spectral_sample_6_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
