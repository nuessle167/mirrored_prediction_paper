---
title: "Attempted fits to Hypotheses"
author: "Pi Nuessle and Judith Racusin"
date: '2023-06-09'
output: word_document
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(plotly)
library(tidyr)
library("scatterplot3d")
library(randomForest)
library(e1071)
library(misc3d)
library(plot3D)
library(scatterplot3d)
library(rgl)
library(data.table)
library(caret)
library(rfUtilities)
library(readr)
library(scales)
library(ggplot2)
# library(tidyverse)
set.seed(1729)
```

```{r defining the special bursts, echo=FALSE}
Collapsars = c(050416461.0, 50525002.0, 050824966.0, 060218148.0, 060729800.0, 060904104.0, 070419447.0, 071025172.0, 071112772.0, 080319258.0, 081007224.0, 090618353.0, 091127976.0, 100316531.0, 100418882.0, 101219686.0, 101225776.0, 111209300.0, 111211928.0, 111228656.0, 120422300.0, 120714888.0, 120729455.0, 130215063.0, 130427324.0, 130702003.0, 130831544.0, 140206303.0, 140606133.0, 150818483.0, 161219783.0, 161228552.0, 171010792.0, 171205306.0, 180720598.0, 180728728.0, 190114872.0, 190829830.0, 200826187.0, 210210083.0, 211023545.0, 221009553.0, 200826187.0, 150210935.0)
Mergers=c(070809807.0, 130603659.0, 150101641.0, 160624477.0, 160821936.0, 170817528.0, 200522487.0, 060614530.0, 111005336.0, 120304248.0, 211211549.0, 230307655.0, 050509166.0, 050709942.0, 051210240.0, 070714207.0, 071227842.0, 080503518.0, 080905499.0, 090515198.0, 160303454.0)
```


The chunk that follows does a linear fit of the prompt isotropic energy against the average decay rate (possibly with redshift). While it is successful, the fit may not be significantly different from fitting nothing. I can actually prove this.

```{r Hypothesis 1, echo=FALSE, eval=FALSE}
H_1_Data <- read_excel("/Users/nnuessle/Documents/Work/burst_matching_algorithm/actual_paper/prompt-and-afterglow-matching/Hypothesis_1_Data.xlsx", col_types = c("skip", "numeric", "numeric", "numeric", "numeric", "numeric"))
H_1_Data_copy<-data.frame(H_1_Data)
#names(H_1_Data_copy) <- NULL             # Delete column names
#H_1_Data_copy                            # Print updated data
# cat("we had to remove bursts ")
# # cat(toString(H_1_Data[16, 'Name']))
# # cat(', ')
# cat(toString(H_1_Data[21, 'Name']))
# cat(', and')
# cat(toString(H_1_Data[46, 'Name']))
# cat(", because they were outliers in the linear model.")
# H_1_Data_copy<-H_1_Data_copy[-c(10, 19, 27, 40, 43), ]
H_1_Data_copy<-H_1_Data_copy[-c(16), ]
H_1_Data_copy$Prompt.Isotropic.Energy<-log10(H_1_Data_copy$Prompt.Isotropic.Energy)
x<-H_1_Data_copy$Prompt.Isotropic.Energy
y<-H_1_Data_copy$Avg..Afterglow.Decay.Rate
z<-H_1_Data_copy$Redshift
mod1<-lm(y~x)
#mod1<-lm(y~x+z)
par(mfrow=c(2,2))
plot(mod1)
anova(mod1)
print(mod1)
newx <- seq(min(x), max(x), length.out=100)
# newz <- seq(min(z), max(z), length.out=100)
preds <- predict(mod1, newdata=data.frame(x=newx), interval='prediction')
# preds <- predict(mod1, newdata=data.frame(x=newx, z=newz), interval='confidence')
par(mar=c(5,5,5,5))
par(mfrow=c(1,1))
collapsar_mask=H_1_Data_copy$Name %in% Collapsars
merger_mask=H_1_Data_copy$Name %in% Mergers
H_1_Data_collapsars=H_1_Data_copy[collapsar_mask, ]
H_1_Data_mergers=H_1_Data_copy[merger_mask, ]
H_1_Data_unknown=H_1_Data_copy[!c(collapsar_mask+merger_mask), ]
plot(H_1_Data_unknown$Avg..Afterglow.Decay.Rate~H_1_Data_unknown$Prompt.Isotropic.Energy, xlab='Prompt Isotropic Energy 10kev-10MeV (erg, GBM)', ylab=paste(strwrap('Redshift-Corrected Afterglow Decay Rate 0.3-10 keV (photons s^-2, XRT)', width = 50), collapse = "\n"), main=paste(strwrap('Isotropic-Equivalent Energy and Average Afterglow Decay Lack of a Relationship', width = 50), collapse = "\n"), pch=20)
# points(H_1_Data_mergers$Avg..Afterglow.Decay.Rate~H_1_Data_mergers$Prompt.Isotropic.Energy, pch=4, col='red')
points(H_1_Data_collapsars$Avg..Afterglow.Decay.Rate~H_1_Data_collapsars$Prompt.Isotropic.Energy, pch=8, col='blue')
abline(mod1)
#add dashed lines for confidence bands
lines(newx, preds[ ,3], lty = 'dashed', col ='green')
lines(newx, preds[ ,2], lty = 'dashed', col = 'green')
legend("topleft",
       legend = c('Unknown', 'Collapsars'),
       col = c('black', 'blue'),
       pch = c(20, 8))
print("All the work done above is fitting the actual data. Below, I calculate a 99% confidence interval for the slope, (which is our significance level) to see if a linear relationship exists. If zero is in that interval, then the null hypothesis that no such relationship exists cannot be rejected, and I have to move on.")
cat("the upper limit for this interval is: ")
cat(mod1$coefficients[2]-qt(0.99, 48)*mod1$coefficients[1])
cat(" and the lower limit is ")
cat(mod1$coefficients[2]+qt(0.99, 48)*mod1$coefficients[1])
cat(", meaning that the null hypothesis cannot be rejected, and it is possible that no linear relationship exists between the GBM prompt isotropic energy and average XRT x-ray decay rate, despite the result in BAT.")
```

What follows is the plots for the efficiency hypothesis, linking the prompt and afterglow isotropic energies as derived in the python code. As one can see, this relationship does have good significance in addition to its clear physical relevance to both the burst mechanism and the circumburst environment.

```{r Hypothesis 2a, echo=FALSE}
H_2a_Data <- read_excel("/Users/nnuessle/Documents/Work/burst_matching_algorithm/actual_paper/prompt-and-afterglow-matching/Hypothesis_2a_Data.xlsx", col_types = c("skip", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric"))
H_2a_Data_copy<-data.frame(H_2a_Data)
# names(H_2a_Data_copy) <- NULL             # Delete column names
# H_2a_Data_copy<-H_2a_Data_copy[-c(15), ] # Print updated data
# cat("we had to remove burst GRB")
# cat(toString(H_2a_Data[15, 'Name']))
# cat(", because it was an outlier in the linear model.")
x<-log10(H_2a_Data_copy$Prompt.E_iso)
y<-log10(H_2a_Data_copy$Plateau.E_iso)
df <- data.frame(x = x, y = y)
mod2a<-lm(y~x)
plot(mod2a)
print(anova(mod2a))
print(summary(mod2a))
#get predicted y values using regression equation
newx <- seq(min(df$x), max(df$x), length.out=100)
preds <- predict(mod2a, newdata = data.frame(x=newx), interval = 'prediction')
par(mar=c(5,5,5,5))
par(mfrow=c(1,1))
collapsar_mask=H_2a_Data_copy$Name %in% Collapsars
merger_mask=H_2a_Data_copy$Name %in% Mergers
H_2a_Data_collapsars=H_2a_Data_copy[collapsar_mask, ]
H_2a_Data_mergers=H_2a_Data_copy[merger_mask, ]
H_2a_Data_unknown=H_2a_Data_copy[!c(collapsar_mask+merger_mask), ]
long_mask=which(H_2a_Data_unknown$t90>4.5)
short_mask=which(H_2a_Data_unknown$t90<=4.5)
H_2a_Data_Long=H_2a_Data_unknown[long_mask, ]
H_2a_Data_Short=H_2a_Data_unknown[short_mask, ]
plot(H_2a_Data_Long$Plateau.E_iso~H_2a_Data_Long$Prompt.E_iso, pch=20, xlab='Prompt Isotropic Energy 10kev-10MeV (erg, GBM)', ylab=paste(strwrap('Plateau Afterglow Isotropic Energy 0.3-10 keV (erg, XRT)', width = 50), collapse = "\n"), log="xy", col='black')
points(H_2a_Data_Short$Plateau.E_iso~H_2a_Data_Short$Prompt.E_iso, pch=20, col='grey')
# points(H_2a_Data_mergers$Plateau.E_iso~H_2a_Data_mergers$Prompt.E_iso, pch=4, col='red', log="xy")
points(H_2a_Data_collapsars$Plateau.E_iso~H_2a_Data_collapsars$Prompt.E_iso, pch=8, col='blue')
arrows(H_2a_Data_Long$Prompt.E_iso, H_2a_Data_Long$Plateau.E_iso-H_2a_Data_Long$Plat_E_err, H_2a_Data_Long$Prompt.E_iso, H_2a_Data_Long$Plateau.E_iso+H_2a_Data_Long$Plat_E_err, length=0.05, angle=90, code=3, col='black')
arrows(H_2a_Data_Short$Prompt.E_iso, H_2a_Data_Short$Plateau.E_iso-H_2a_Data_Short$Plat_E_err, H_2a_Data_Short$Prompt.E_iso, H_2a_Data_Short$Plateau.E_iso+H_2a_Data_Short$Plat_E_err, length=0.05, angle=90, code=3, col='grey')
# arrows(H_2a_Data_mergers$Prompt.E_iso, H_2a_Data_mergers$Plateau.E_iso-H_2a_Data_mergers$Plat_E_err, H_2a_Data_mergers$Prompt.E_iso, H_2a_Data_mergers$Plateau.E_iso+H_2a_Data_mergers$Plat_E_err, length=0.05, angle=90, code=3, col='red')
arrows(H_2a_Data_collapsars$Prompt.E_iso, H_2a_Data_collapsars$Plateau.E_iso-H_2a_Data_collapsars$Plat_E_err, H_2a_Data_collapsars$Prompt.E_iso, H_2a_Data_collapsars$Plateau.E_iso+H_2a_Data_collapsars$Plat_E_err, length=0.05, angle=90, code=3, col='blue')
arrows(H_2a_Data_Long$Prompt.E_iso-H_2a_Data_Long$Prompt_E_err, H_2a_Data_Long$Plateau.E_iso, H_2a_Data_Long$Prompt.E_iso+H_2a_Data_Long$Prompt_E_err, H_2a_Data_Long$Plateau.E_iso, length=0.05, angle=90, code=3, col='black')
arrows(H_2a_Data_Short$Prompt.E_iso-H_2a_Data_Short$Prompt_E_err, H_2a_Data_Short$Plateau.E_iso, H_2a_Data_Short$Prompt.E_iso+H_2a_Data_Short$Prompt_E_err, H_2a_Data_Short$Plateau.E_iso, length=0.05, angle=90, code=3, col='grey')
# arrows(H_2a_Data_mergers$Prompt.E_iso-H_2a_Data_mergers$Prompt_E_err, H_2a_Data_mergers$Plateau.E_iso, H_2a_Data_mergers$Prompt.E_iso+H_2a_Data_mergers$Prompt_E_err, H_2a_Data_mergers$Plateau.E_iso, length=0.05, angle=90, code=3, col='red')
arrows(H_2a_Data_collapsars$Prompt.E_iso-H_2a_Data_collapsars$Prompt_E_err, H_2a_Data_collapsars$Plateau.E_iso, H_2a_Data_collapsars$Prompt.E_iso+H_2a_Data_collapsars$Prompt_E_err, H_2a_Data_collapsars$Plateau.E_iso, length=0.05, angle=90, code=3, col='blue')
abline(mod2a)
#add dashed lines for confidence bands
lines(10^newx, 10^preds[ ,3], lty = 'dashed', col = 'green')
lines(10^newx, 10^preds[ ,2], lty = 'dashed', col = 'green')
legend("topleft",
       legend = c('Unknown Long', 'Unknown Short', 'Collapsars'),
       col = c('black', 'grey', 'blue'),
       pch = c(20, 20, 8))

print("What follows is a version of the model where the lowest-energy prompt emission is removed, to eliminate some of the quartile error. This isn't necessary to bring the model to our predetermined significance level of 1%, nor does it have any physical meaning. Therefore, it is not discussed in the results of the paper.")

new_df <- subset(df, x > 51.5) 
m=new_df$y
n=new_df$x
mod2a1<-lm(m~n)
par(mfrow=c(2,2))
plot(mod2a1)
print(anova(mod2a1))
print(summary(mod2a1))
#get predicted y values using regression equation
newx <- seq(min(n), max(n), length.out=100)
preds <- predict(mod2a1, newdata=data.frame(n=newx), interval='prediction')
par(mar=c(5,5,5,5))
par(mfrow=c(1,1))
H_2a_Data_collapsars_2=subset(H_2a_Data_collapsars, log10(H_2a_Data_collapsars$Prompt.E_iso) > 51.5)
H_2a_Data_unknown_2=subset(H_2a_Data_unknown, log10(H_2a_Data_unknown$Prompt.E_iso) > 51.5)
plot(H_2a_Data_unknown_2$Plateau.E_iso~H_2a_Data_unknown_2$Prompt.E_iso, pch=20, xlab='Prompt Isotropic Energy 10kev-10MeV (erg, GBM)', ylab=paste(strwrap('Plateau Afterglow Isotropic Energy 0.3-10 keV (erg, XRT)', width = 50), collapse = "\n"), log="xy")
# points(H_2a_Data_mergers$Plateau.E_iso~H_2a_Data_mergers$Prompt.E_iso, pch=4, col='red', log="xy")
points(H_2a_Data_collapsars_2$Plateau.E_iso~H_2a_Data_collapsars_2$Prompt.E_iso, pch=8, col='blue')
abline(mod2a1)
#add dashed lines for confidence bands
lines(10^newx, 10^preds[ ,3], lty = 'dashed', col = 'green')
lines(10^newx, 10^preds[ ,2], lty = 'dashed', col = 'green')
legend("topleft",
       legend = c('Unknown', 'Collapsars'),
       col = c('black', 'blue'),
       pch = c(20, 8))

s3d <-scatterplot3d(x=log10(H_2a_Data_unknown$Prompt.E_iso), y=log10(H_2a_Data_unknown$Plateau.E_iso), z=log10(H_2a_Data_unknown$t90), pch=20, color ='black', xlab='Prompt Isotropic Energy 10kev-10MeV (erg, GBM)', ylab=paste(strwrap('Plateau Afterglow Isotropic Energy 0.3-10 keV (erg, XRT)', width = 25), collapse = "\n"), zlab="t90 (s, GBM)") 
s3d$points3d(x=log10(H_2a_Data_collapsars$Prompt.E_iso), y=log10(H_2a_Data_collapsars$Plateau.E_iso), z=log10(H_2a_Data_collapsars$t90), pch=8, col ='blue')
# plot_ly(x=H_2a_Data_copy$Prompt.E_iso, y=H_2a_Data_copy$Plateau.E_iso, z=log10(H_2a_Data_copy$t90), color=log10(H_2a_Data_copy$t90), colors = c('green', 'blue'))
10^confint(mod2a, 'x', level=0.99)
predict(mod2a, data.frame(x=mean(x)) , interval="predict") 
```

```{r Hypothesis 2b, echo=FALSE, warning=FALSE, eval=FALSE}
H_2b_Data <- read_excel("/Users/nnuessle/Documents/Work/burst_matching_algorithm/actual_paper/prompt-and-afterglow-matching/Hypothesis_2b_Data.xlsx", col_types = c("skip", "numeric", "numeric", "numeric", "numeric"))
H_2b_Data_copy<-data.frame(H_2b_Data)
#names(H_2b_Data_copy) <- NULL             # Delete column names
long_list<-which(H_2b_Data_copy[[4]]>4.2)
short_list<-which(H_2b_Data_copy[[4]]<=4.2)
long_H_2b<-H_2b_Data_copy[long_list,]
short_H_2b<-H_2b_Data_copy[short_list,]
collapsar_mask<-long_H_2b$Name %in% Collapsars
merger_mask<-long_H_2b$Name %in% Mergers
H_2b_Data_long_collapsars<-long_H_2b[collapsar_mask, ]
H_2b_Data_long_mergers<-long_H_2b[merger_mask, ]
H_2b_Data_long_unknown<-long_H_2b[!c(collapsar_mask+merger_mask), ]
collapsar_mask<-short_H_2b$Name %in% Collapsars
merger_mask<-short_H_2b$Name %in% Mergers
H_2b_Data_short_collapsars<-short_H_2b[collapsar_mask, ]
H_2b_Data_short_mergers<-short_H_2b[merger_mask, ]
H_2b_Data_short_unknown<-short_H_2b[!c(collapsar_mask+merger_mask), ]
# long_x<-log10(long_H_2b[[2]])
# long_y<-log10(long_H_2b[[3]])
# short_x<-log10(short_H_2b[[2]])
# short_y<-log10(short_H_2b[[3]])
plot(H_2b_Data_long_unknown$End.Plateau.Flux~H_2b_Data_long_unknown$Prompt.Fluence, col='black', pch=20, xlab="Prompt Fluence, 10keV-1MeV (erg cm^-2, GBM)", ylab="End Plateau Flux, 0.3-10 keV (erg s^-1 cm^-2, XRT)", log = "xy", main="The Long Burst Prompt Fluence versus End-Plateau Flux", xlim=c(5e-8, 5e-3))
points(H_2b_Data_long_mergers$End.Plateau.Flux~H_2b_Data_long_mergers$Prompt.Fluence, col='red', pch=4)
points(H_2b_Data_long_collapsars$End.Plateau.Flux~H_2b_Data_long_collapsars$Prompt.Fluence, col='blue', pch=8)
legend("topleft",
       legend = c('Unknown', 'Mergers', 'Collapsars'),
       col = c('black','red', 'blue'),
       pch = c(20, 4, 8))
plot(H_2b_Data_short_unknown$End.Plateau.Flux~H_2b_Data_short_unknown$Prompt.Fluence, col='black', pch=20, xlab="Prompt Fluence, 10keV-1MeV (erg cm^-2, GBM)", ylab="End Plateau Flux, 0.3-10 keV (erg s^-1 cm^-2, XRT)", log = "xy", main="The Short Burst Prompt Fluence versus End-Plateau Flux")
points(H_2b_Data_short_mergers$End.Plateau.Flux~H_2b_Data_short_mergers$Prompt.Fluence, col='red', pch=4)
points(H_2b_Data_short_collapsars$End.Plateau.Flux~H_2b_Data_short_collapsars$Prompt.Fluence, col='blue', pch=8)
legend("topleft",
       legend = c('Unknown'),
       col = c('black'),
       pch = c(20, 4, 8))
plot(c(H_2b_Data_long_unknown$End.Plateau.Flux,H_2b_Data_short_unknown$End.Plateau.Flux)~c(H_2b_Data_long_unknown$Prompt.Fluence,H_2b_Data_short_unknown$Prompt.Fluence), col='black', pch=20, xlab="Prompt Fluence, 10keV-1MeV (erg cm^-2, GBM)", ylab="End Plateau Flux, 0.3-10 keV (erg s^-1 cm^-2, XRT)", log = "xy", main="All Burst Prompt Fluences versus End-Plateau Fluxes", xlim=c(5e-8, 5e-3))
points(c(H_2b_Data_long_mergers$End.Plateau.Flux,H_2b_Data_short_mergers$End.Plateau.Flux)~c(H_2b_Data_long_mergers$Prompt.Fluence,H_2b_Data_short_mergers$Prompt.Fluence), col='red', pch=4)
points(c(H_2b_Data_long_collapsars$End.Plateau.Flux,H_2b_Data_short_collapsars$End.Plateau.Flux)~c(H_2b_Data_long_collapsars$Prompt.Fluence,H_2b_Data_short_collapsars$Prompt.Fluence), col='blue', pch=8)
legend("topleft",
       legend = c('Unknown', 'Mergers', 'Collapsars'),
       col = c('black','red', 'blue'),
       pch = c(20, 4, 8))
s3d <-scatterplot3d(x=log10(H_2b_Data_long_unknown$End.Plateau.Flux), y=log10(H_2b_Data_long_unknown$End.Plateau.Flux), z=log10(H_2b_Data_long_unknown$t90), color="black", pch=20, xlab="Prompt Fluence, 10keV-1MeV (erg cm^-2, GBM)", ylab=paste(strwrap("End Plateau Flux, 0.3-10 keV (erg s^-1 cm^-2, XRT)", width = 25), collapse = "\n"), zlab="t90 (s, GBM)", main = paste(strwrap("Three-Dimensional Plot of all Data points Motivating Machine Learning by Separation of Long and Short Bursts, Though Not Progenitors", width = 50), collapse = "\n"), xlim = c(-14, -3), zlim = c(-1, 3))
s3d$points3d(x=log10(H_2b_Data_short_unknown$Prompt.Fluence), y=log10(H_2b_Data_short_unknown$End.Plateau.Flux), z=log10(H_2b_Data_short_unknown$t90), col="grey", pch=20)
s3d$points3d(x=c(log10(H_2b_Data_long_mergers$Prompt.Fluence),log10(H_2b_Data_short_mergers$Prompt.Fluence)), y=c(log10(H_2b_Data_long_mergers$End.Plateau.Flux),log10(H_2b_Data_short_mergers$End.Plateau.Flux)), z=c(log10(H_2b_Data_long_mergers$t90),log10(H_2b_Data_short_mergers$t90)), col="red", pch=4)
s3d$points3d(x=c(log10(H_2b_Data_long_collapsars$Prompt.Fluence),log10(H_2b_Data_short_collapsars$Prompt.Fluence)), y=c(log10(H_2b_Data_long_collapsars$End.Plateau.Flux),log10(H_2b_Data_short_collapsars$End.Plateau.Flux)), z=c(log10(H_2b_Data_long_collapsars$t90),log10(H_2b_Data_short_collapsars$t90)), col="blue", pch=8)
legend("topleft",
       legend = c('Unknown (Long)', 'Unknown (Short)', 'Mergers', 'Collapsars'),
       col = c('black','grey','red', 'blue'),
       pch = c(20,20, 4, 8))
missing<-which(!complete.cases(H_2b_Data_copy))
no_NA_H_2b_Data<- H_2b_Data_copy[-missing, ]
collapsar_mask<-no_NA_H_2b_Data$Name %in% Collapsars
merger_mask<-no_NA_H_2b_Data$Name %in% Mergers
short_list<-which(no_NA_H_2b_Data$t90<4.2)
long_list<-which(no_NA_H_2b_Data$t90>4.2)
Classification<-rep("Unknown", nrow(no_NA_H_2b_Data))
Classification[short_list]<-"merger"
Classification[long_list]<-"collapsar" 
Classification[collapsar_mask]<-"collapsar" #It kinda looks like an explosion I guess IDK
Classification[merger_mask]<-"merger" #and this can be the jet of the merger
new_H_2b_Data<-data.frame(cbind(log10(no_NA_H_2b_Data$Prompt.Fluence), log10(no_NA_H_2b_Data$End.Plateau.Flux), log10(no_NA_H_2b_Data$t90), as.factor(Classification)))
colnames(new_H_2b_Data)<-c("Prompt.Fluence", "End.Plateau.Flux", "t90", "as.factor.Classification.")
# model <- randomForest(formula = no_NA_H_2b_Data$Classification ~ ., data = no_NA_H_2b_Data)
svmfit<-svm(new_H_2b_Data$as.factor.Classification. ~ ., data = new_H_2b_Data, type = "C-classification", cost = 1.0, kernel = "linear")
print(svmfit)
plot(svmfit, new_H_2b_Data, End.Plateau.Flux~Prompt.Fluence, slice = list(t90 = 0.5, t90 = 1), xlab="Prompt Fluence, 10keV-1MeV (erg cm^-2, GBM)", ylab=paste(strwrap("End Plateau Flux, 0.3-10 keV (erg s^-1 cm^-2, XRT)", width = 25), collapse = "\n"))
plot(svmfit, new_H_2b_Data, End.Plateau.Flux~t90, slice = list(Prompt.Fluence = -5.5, Prompt.Fluence = -4.5), xlab="t90 (s, GBM)", ylab=paste(strwrap("End Plateau Flux, 0.3-10 keV (erg s^-1 cm^-2, XRT)", width = 25), collapse = "\n"))
plot(svmfit, new_H_2b_Data, Prompt.Fluence~t90, slice = list(End.Plateau.Flux = -10, End.Plateau.Flux  = -9), xlab="Prompt Fluence, 10keV-1MeV (erg cm^-2, GBM)",  ylab="t90 (s, GBM)",)
# Simulate some data
n    = 100
nnew = 50
set.seed(12345)
group = sample(2, n, replace=T)
dat   = data.frame(group=factor(group), matrix(rnorm(n*3, rep(group, each=3)), ncol=3, byrow=T))

# # Fit SVM
# fit = svm(group ~ ., data=dat)
# 
# # Plot original data
# plot3d(dat[,-1], col=dat$group)

# Get decision values for a new data grid
newdat.list = lapply(new_H_2b_Data, function(x) seq(min(x), max(x), len=nnew))
newdat      = expand.grid(newdat.list)
names(newdat) <- c("Prompt.Fluence", "End.Plateau.Flux", "t90")
newdat.pred = predict(svmfit, newdata=newdat, decision.values=T)
newdat.dv   = attr(newdat.pred, 'decision.values')
newdat.dv   = array(newdat.dv, dim=rep(nnew, 3))

# Fit/plot an isosurface to the decision boundary
plot3d(x=new_H_2b_Data$Prompt.Fluence, y=new_H_2b_Data$End.Plateau.Flux, z=new_H_2b_Data$t90, xlab="Prompt Fluence, 10keV-1MeV (erg cm^-2, GBM)", ylab=paste(strwrap("End Plateau Flux, 0.3-10 keV (erg s^-1 cm^-2, XRT)", width = 25), collapse = "\n"), zlab="t90 (s, GBM)")
contour3d(newdat.dv, level=0, x=newdat.list$Prompt.Fluence, y=newdat.list$End.Plateau.Flux, z=newdat.list$t90, add=T)
```

```{r Goldstein Hypothesis Defunct, echo=FALSE, eval=FALSE}
Goldstein_S2_Data <- read_excel("/Users/nnuessle/Documents/Work/burst_matching_algorithm/actual_paper/prompt-and-afterglow-matching/Goldstein_Sample_2_Data.xlsx", col_types = c("skip", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric")) [-c(3), ]
par(mar=c(5,5,5,5))
collapsar_mask=Goldstein_S2_Data$Name %in% Collapsars
merger_mask=Goldstein_S2_Data$Name %in% Mergers
Goldstein_S2_collapsars=Goldstein_S2_Data[collapsar_mask, ]
Goldstein_S2_mergers=Goldstein_S2_Data[merger_mask, ]
Goldstein_S2_unknown=Goldstein_S2_Data[!c(collapsar_mask+merger_mask), ]
long_mask=which(Goldstein_S2_unknown$t90>4.2)
short_mask=which(Goldstein_S2_unknown$t90<=4.2)
Goldstein_S2_Long=Goldstein_S2_unknown[long_mask, ]
Goldstein_S2_Short=Goldstein_S2_unknown[short_mask, ]
plot(Goldstein_S2_Long$t90, Goldstein_S2_Long$`Peak E. over Flue.`, pch=20, ylab=expression(E[p]/S[prompt]~' 10kev-10MeV ('~erg ~ cm^{2} ~ erg^{-1} ~ ', GBM)'), xlab='t90 (s, GBM)', log="xy", xlim=c(1e-2, 1e3))
points(Goldstein_S2_Short$t90, Goldstein_S2_Short$`Peak E. over Flue.`, pch=20, col='grey')
points(Goldstein_S2_mergers$t90, Goldstein_S2_mergers$`Peak E. over Flue.`, pch=4, col='red')
points(Goldstein_S2_collapsars$t90, Goldstein_S2_collapsars$`Peak E. over Flue.`, pch=8, col='blue')
legend("topleft",
       legend = c('Unknown Long', 'Unknown Short', "Mergers", 'Collapsars'),
       col = c('black', 'grey', 'red', 'blue'),
       pch = c(20, 20, 4, 8))
##
missing<-which(!complete.cases(Goldstein_S2_Data))
no_NA_Goldstein_S2_Data<- Goldstein_S2_Data[-missing, ]
collapsar_mask<-no_NA_Goldstein_S2_Data$Name %in% Collapsars
merger_mask<-no_NA_Goldstein_S2_Data$Name %in% Mergers
# short_list<-which(no_NA_Goldstein_S2_Data$t90<4.2)
# long_list<-which(no_NA_Goldstein_S2_Data$t90>4.2)
Classification<-rep("Unknown", nrow(no_NA_Goldstein_S2_Data))
# Classification[short_list]<-"merger"
# Classification[long_list]<-"collapsar" 
Classification[collapsar_mask]<-"collapsar"
Classification[merger_mask]<-"merger"
# new_Goldstein_S2_Data<-data.frame(cbind(log10(no_NA_Goldstein_S2_Data$`Peak E. over Flue.`), log10(no_NA_Goldstein_S2_Data$E_P_Over_S_Err), log10(no_NA_Goldstein_S2_Data$t90), log(no_NA_Goldstein_S2_Data$t90_err), as.factor(Classification)))
# colnames(new_Goldstein_S2_Data)<-c("Peak_E_over_Flu", "Peak_E_over_S_err", "t90", "t90_err", "as.factor.Classification.")
new_Goldstein_S2_Data<-data.frame(cbind(log10(no_NA_Goldstein_S2_Data$`Peak E. over Flue.`), log10(no_NA_Goldstein_S2_Data$t90), as.factor(Classification)))
colnames(new_Goldstein_S2_Data)<-c("Peak_E_over_Flu", "t90", "as.factor.Classification.")
unknown_remover<-which(new_Goldstein_S2_Data$as.factor.Classification.==3)
merger_mask<-which(new_Goldstein_S2_Data$as.factor.Classification.==2)
collapsar_mask<-which(new_Goldstein_S2_Data$as.factor.Classification.==1)
training_set=new_Goldstein_S2_Data[-unknown_remover, ]
svmfit<-svm(training_set$as.factor.Classification. ~ ., data = training_set, type = "C-classification", cost = 1.0, kernel = "sigmoid", probability=TRUE)
print(svmfit)
plot(svmfit, training_set, Peak_E_over_Flu~t90, ylab=expression(E[p]/S[prompt]~' 10kev-10MeV ('~erg ~ cm^{2} ~ erg^{-1} ~ ', GBM)'), xlab='t90 (s, GBM)', log="xy")
# points(log10(Goldstein_S2_unknown$t90), log10(Goldstein_S2_unknown$`Peak E. over Flue.`))
predicted_svm<-predict(svmfit, new_Goldstein_S2_Data, probability=TRUE)
new_table<-attr(predicted_svm, "probabilities")
new_table<-cbind(no_NA_Goldstein_S2_Data$Name, new_table)
colnames(new_table)<-c("Name", "P_collapsar", "P_merger")
new_table<-data.frame(new_table)
write.csv(new_table, "/Users/nnuessle/Documents/Work/burst_matching_algorithm/actual_paper/prompt-and-afterglow-matching/Goldstein_Classification.csv")
# y2<-as.numeric(predicted_svm)
# training_mask<-which(y2==2)
# y2[training_mask]<-0
# calibrated.predicted_svm <- probability.calibration(y2, predicted_svm, regularization = TRUE)
# y = training_set[,"as.factor.Classification."]
# training_mask<-which(y==2)
# y[training_mask]<-0
#  x = training_set[,1:2]
# ( rf.mdl <- randomForest(x=x, y=factor(y)) )
#  y.hat <- predict(rf.mdl, training_set[,1:2], type="prob")[,2]
#  calibrated.y.hat <- probability.calibration(y, y.hat, regularization = TRUE) 
plot(new_Goldstein_S2_Data[unknown_remover, ]$Peak_E_over_Flu~new_Goldstein_S2_Data[unknown_remover, ]$t90, ylab=expression(E[p]/S[prompt]~' 10kev-10MeV ('~erg ~ cm^{2} ~ erg^{-1} ~ ', GBM)'), xlab='t90 (s, GBM)', col=predicted_svm, pch=20)
points(log10(Goldstein_S2_mergers$t90), log10(Goldstein_S2_mergers$`Peak E. over Flue.`), pch=4, col='#09622A')
points(log10(Goldstein_S2_collapsars$t90), log10(Goldstein_S2_collapsars$`Peak E. over Flue.`), pch=8, col='blue')
# arrows(new_Goldstein_S2_Data$t90, new_Goldstein_S2_Data$Peak_E_over_Flu-new_Goldstein_S2_Data$Peak_E_over_S_err, new_Goldstein_S2_Data$t90, new_Goldstein_S2_Data$Peak_E_over_Flu+new_Goldstein_S2_Data$Peak_E_over_S_err, length=0.05, angle=90, code=3,col=predicted_svm)
# arrows(Goldstein_S2_mergers$t90, Goldstein_S2_mergers$`Peak E. over Flue.`-Goldstein_S2_mergers$E_P_Over_S_Err, Goldstein_S2_mergers$t90, Goldstein_S2_mergers$`Peak E. over Flue.`+Goldstein_S2_mergers$E_P_Over_S_Err, length=0.05, angle=90, code=3,col='#09622A')
# arrows(Goldstein_S2_collapsars$t90, Goldstein_S2_collapsars$`Peak E. over Flue.`-Goldstein_S2_collapsars$E_P_Over_S_Err, Goldstein_S2_collapsars$t90, Goldstein_S2_collapsars$`Peak E. over Flue.`+Goldstein_S2_collapsars$E_P_Over_S_Err, length=0.05, angle=90, code=3,col='blue')
# arrows(new_Goldstein_S2_Data$t90-new_Goldstein_S2_Data$t90_err, new_Goldstein_S2_Data$Peak_E_over_Flu, new_Goldstein_S2_Data$t90+new_Goldstein_S2_Data$t90_err, new_Goldstein_S2_Data$Peak_E_over_Flu, length=0.05, angle=90, code=3,col=predicted_svm)
# arrows(Goldstein_S2_mergers$t90-Goldstein_S2_mergers$t90_err, Goldstein_S2_mergers$`Peak E. over Flue.`, Goldstein_S2_mergers$t90+Goldstein_S2_mergers$t90_err, Goldstein_S2_mergers$`Peak E. over Flue.`, length=0.05, angle=90, code=3,col='#09622A')
# arrows(Goldstein_S2_collapsars$t90-Goldstein_S2_collapsars$t90_err, Goldstein_S2_collapsars$`Peak E. over Flue.`, Goldstein_S2_collapsars$t90+Goldstein_S2_collapsars$t90_err, Goldstein_S2_collapsars$`Peak E. over Flue.`, length=0.05, angle=90, code=3,col='blue')
legend("topleft",
       legend = c('Sorted Collapsars', 'Sorted Mergers', "Detected Mergers", 'Detected Collapsars'),
       col = c('black', 'red', '#09622A', 'blue'),
       pch = c(20, 20, 4, 8))
# svm_check=predict(svmfit, new_Goldstein_S6_Data[-unknown_remover, ])
# confusionMatrix(svm_check, factor(new_Goldstein_S6_Data[-unknown_remover, ]$as.factor.Classification.), dnn = c("Prediction", "Reference"))
###
#now let's try it on the overlapping sample with redshifts
# Goldstein_S6_Data <- read_excel("/Users/nnuessle/Documents/Work/burst_matching_algorithm/actual_paper/prompt-and-afterglow-matching/Goldstein_Sample_6_Data.xlsx", col_types = c("skip", "numeric", "numeric", "numeric", "numeric"))
# missing<-which(!complete.cases(Goldstein_S6_Data))
# no_NA_Goldstein_S6_Data<- Goldstein_S6_Data[-missing, ]
# collapsar_mask<-no_NA_Goldstein_S6_Data$Name %in% Collapsars
# merger_mask<-no_NA_Goldstein_S6_Data$Name %in% Mergers
# Classification<-rep("Unknown", nrow(no_NA_Goldstein_S6_Data))
# Classification[collapsar_mask]<-"collapsar"
# Classification[merger_mask]<-"merger"
# new_Goldstein_S6_Data<-data.frame(cbind(log10(no_NA_Goldstein_S6_Data$`Peak E. over Flue.`), log10(no_NA_Goldstein_S6_Data$t90), as.factor(Classification)))
# colnames(new_Goldstein_S6_Data)<-c("Peak_E_over_Flu", "t90", "as.factor.Classification.")
# unknown_remover<-which(new_Goldstein_S6_Data$as.factor.Classification.==3)
# Second_predicted_svm<-predict(svmfit, new_Goldstein_S6_Data)
# plot(new_Goldstein_S6_Data$Peak_E_over_Flu~new_Goldstein_S6_Data$t90, ylab=expression(E[p]/S[prompt]~' 10kev-10MeV ('~erg ~ cm^{2} ~ erg^{-1} ~ ', GBM)'), xlab='t90 (s, GBM)', col=Second_predicted_svm, pch=20)
# svm_check=predict(svmfit, new_Goldstein_S6_Data[-unknown_remover, ])
# confusionMatrix(svm_check, factor(new_Goldstein_S6_Data[-unknown_remover, ]$as.factor.Classification.), dnn = c("Prediction", "Reference"))
##
```

```{r Gehrels Hypothesis, echo=FALSE}
Gehrels_S3_Data <- read_excel("/Users/nnuessle/Documents/Work/burst_matching_algorithm/actual_paper/prompt-and-afterglow-matching/Gehrels_Sample_3_Data.xlsx", col_types = c("skip", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric"))
# actually_usable_mask<-which(log10(Gehrels_S3_Data$`X-ray_F11`)< -(14+log10(8)))
# Gehrels_S3_Data<-Gehrels_S3_Data[-c(actually_usable_mask), ]
# Gehrels_S3_Data<-Gehrels_S3_Data[-c(146), ] #removed an outlier from the linear model
collapsar_mask=Gehrels_S3_Data$Name %in% Collapsars
merger_mask=Gehrels_S3_Data$Name %in% Mergers
Gehrels_S3_collapsars=Gehrels_S3_Data[collapsar_mask, ]
Gehrels_S3_mergers=Gehrels_S3_Data[merger_mask, ]
Gehrels_S3_unknown=Gehrels_S3_Data[!c(collapsar_mask+merger_mask), ]
long_mask=which(Gehrels_S3_unknown$t90>4.5)
short_mask=which(Gehrels_S3_unknown$t90<=4.5)
Gehrels_S3_Long=Gehrels_S3_unknown[long_mask, ]
Gehrels_S3_Short=Gehrels_S3_unknown[short_mask, ]
x<-log10(Gehrels_S3_Data$Prompt_Flu)
xerr<-log10(Gehrels_S3_Data$Flu_Err)
y<-log10(Gehrels_S3_Data$`X-ray_F11`)
yerr<-log10(Gehrels_S3_Data$Flux_Err)
z<-log10(Gehrels_S3_Data$t90)
Gehrels_S3_Long<-Gehrels_S3_Long[-c(17, 96, 171), ]
x2<-log10(Gehrels_S3_Long$Prompt_Flu)
xerr2<-log10(Gehrels_S3_Long$Flu_Err)
y2<-log10(Gehrels_S3_Long$`X-ray_F11`)
yerr2<-log10(Gehrels_S3_Long$Flux_Err)
z2<-log10(Gehrels_S3_Long$t90)
x3<-log10(Gehrels_S3_Short$Prompt_Flu)
xerr3<-log10(Gehrels_S3_Short$Flu_Err)
y3<-log10(Gehrels_S3_Short$`X-ray_F11`)
yerr3<-log10(Gehrels_S3_Short$Flux_Err)
z3<-log10(Gehrels_S3_Short$t90)
##
modGehrels<-lm(y~x)
par(mfrow=c(1,1))
plot(modGehrels)
print(anova(modGehrels))
print(summary(modGehrels))
#
modGehrels2<-lm(y~x+z)
par(mfrow=c(2,2))
plot(modGehrels2)
print(anova(modGehrels2))
print(summary(modGehrels2))
#
modGehrels3<-lm(y2~x2)
par(mfrow=c(2,2))
plot(modGehrels3)
print(anova(modGehrels3))
print(summary(modGehrels3))
#
modGehrels4<-lm(y3~x3)
par(mfrow=c(2,2))
plot(modGehrels4)
print(anova(modGehrels4))
print(summary(modGehrels4))
##
newx <- seq(min(x2), max(x2), length.out=100)
preds <- predict(modGehrels3, newdata=data.frame(x2=newx), interval='prediction')
##
newx2 <- seq(min(x3), max(x3), length.out=100)
preds2 <- predict(modGehrels4, newdata=data.frame(x3=newx2), interval='prediction')
##
par(mfrow=c(1,1))
par(mar=c(5,5,5,5))
plot(Gehrels_S3_unknown$Prompt_Flu, Gehrels_S3_unknown$`X-ray_F11`, pch=20, xlab=expression('Prompt Fluence 10kev-10MeV (erg'~cm^{-2}~', GBM)'), ylab=expression('Afterglow '~Flux[11~Hr.]~' 0.3-10 keV (erg'~cm^{-2}~s^{-1}~', XRT)'), log="xy", xlim = c(1e-7, 1e-3), ylim = c(1e-20, 1e-8))
points(Gehrels_S3_mergers$Prompt_Flu, Gehrels_S3_mergers$`X-ray_F11`, pch=4, col='red')
points(Gehrels_S3_collapsars$Prompt_Flu, Gehrels_S3_collapsars$`X-ray_F11`, pch=8, col='blue')
arrows(Gehrels_S3_unknown$Prompt_Flu, Gehrels_S3_unknown$`X-ray_F11`-Gehrels_S3_unknown$Flux_Err, Gehrels_S3_unknown$Prompt_Flu, Gehrels_S3_unknown$`X-ray_F11`+Gehrels_S3_unknown$Flux_Err, length=0.05, angle=90, code=3)
arrows(Gehrels_S3_collapsars$Prompt_Flu, Gehrels_S3_collapsars$`X-ray_F11`-Gehrels_S3_collapsars$Flux_Err, Gehrels_S3_collapsars$Prompt_Flu, Gehrels_S3_collapsars$`X-ray_F11`+Gehrels_S3_collapsars$Flux_Err, length=0.05, angle=90, code=3)
arrows(Gehrels_S3_mergers$Prompt_Flu, Gehrels_S3_mergers$`X-ray_F11`-Gehrels_S3_mergers$Flux_Err, Gehrels_S3_mergers$Prompt_Flu, Gehrels_S3_mergers$`X-ray_F11`+Gehrels_S3_mergers$Flux_Err, length=0.05, angle=90, code=3)
arrows(Gehrels_S3_unknown$Prompt_Flu-Gehrels_S3_unknown$Flu_Err, Gehrels_S3_unknown$`X-ray_F11`, Gehrels_S3_unknown$Prompt_Flu+Gehrels_S3_unknown$Flu_Err, Gehrels_S3_unknown$`X-ray_F11`, length=0.05, angle=90, code=3)
arrows(Gehrels_S3_collapsars$Prompt_Flu-Gehrels_S3_collapsars$Flu_Err, Gehrels_S3_collapsars$`X-ray_F11`, Gehrels_S3_collapsars$Prompt_Flu+Gehrels_S3_collapsars$Flu_Err, Gehrels_S3_collapsars$`X-ray_F11`, length=0.05, angle=90, code=3)
arrows(Gehrels_S3_mergers$Prompt_Flu-Gehrels_S3_mergers$Flu_Err, Gehrels_S3_mergers$`X-ray_F11`, Gehrels_S3_mergers$Prompt_Flu+Gehrels_S3_mergers$Flu_Err, Gehrels_S3_mergers$`X-ray_F11`, length=0.05, angle=90, code=3)
abline(modGehrels3)
abline(modGehrels4)
#add dashed lines for confidence bands
lines(10^newx, 10^preds[ ,3], lty = 'dashed', col = 'black')
lines(10^newx, 10^preds[ ,2], lty = 'dashed', col = 'black')
lines(10^newx2, 10^preds2[ ,3], lty = 'dashed', col = 'grey')
lines(10^newx2, 10^preds2[ ,2], lty = 'dashed', col = 'grey')
legend("bottomright",
       legend = c('Unknown', 'Mergers', 'Collapsars'),
       col = c('black', 'red', 'blue'),
       pch = c(20, 4, 8))
##
# newx <- seq(min(x2), max(x2), length.out=100)
# preds <- predict(modGehrels, newdata=data.frame(x2=newx), interval='prediction')
##
par(mar=c(5,5,5,5))
plot(Gehrels_S3_Long$Prompt_Flu, Gehrels_S3_Long$`X-ray_F11`, pch=20, col='black', xlab=expression('Prompt Fluence 10kev-10MeV (erg'~cm^{-2}~', GBM)'), ylab=expression('Afterglow '~Flux[11~Hr.]~' 0.3-10 keV (erg'~cm^{-2}~s^{-1}~', XRT)'), log="xy", xlim = c(1e-7, 1e-3), ylim = c(1e-20, 1e-8))
points(Gehrels_S3_Short$Prompt_Flu, Gehrels_S3_Short$`X-ray_F11`, pch=20, col='grey')
points(Gehrels_S3_mergers$Prompt_Flu, Gehrels_S3_mergers$`X-ray_F11`, pch=4, col='red')
points(Gehrels_S3_collapsars$Prompt_Flu, Gehrels_S3_collapsars$`X-ray_F11`, pch=8, col='blue')
arrows(Gehrels_S3_Long$Prompt_Flu, Gehrels_S3_Long$`X-ray_F11`-Gehrels_S3_Long$Flux_Err, Gehrels_S3_Long$Prompt_Flu, Gehrels_S3_Long$`X-ray_F11`+Gehrels_S3_Long$Flux_Err, length=0.05, angle=90, code=3, col = 'black')
arrows(Gehrels_S3_Short$Prompt_Flu, Gehrels_S3_Short$`X-ray_F11`-Gehrels_S3_Short$Flux_Err, Gehrels_S3_Short$Prompt_Flu, Gehrels_S3_Short$`X-ray_F11`+Gehrels_S3_Short$Flux_Err, length=0.05, angle=90, code=3, col = 'grey')
arrows(Gehrels_S3_collapsars$Prompt_Flu, Gehrels_S3_collapsars$`X-ray_F11`-Gehrels_S3_collapsars$Flux_Err, Gehrels_S3_collapsars$Prompt_Flu, Gehrels_S3_collapsars$`X-ray_F11`+Gehrels_S3_collapsars$Flux_Err, length=0.05, angle=90, code=3, col = 'blue')
arrows(Gehrels_S3_mergers$Prompt_Flu, Gehrels_S3_mergers$`X-ray_F11`-Gehrels_S3_mergers$Flux_Err, Gehrels_S3_mergers$Prompt_Flu, Gehrels_S3_mergers$`X-ray_F11`+Gehrels_S3_mergers$Flux_Err, length=0.05, angle=90, code=3, col = 'red')
arrows(Gehrels_S3_Long$Prompt_Flu-Gehrels_S3_Long$Flu_Err, Gehrels_S3_Long$`X-ray_F11`, Gehrels_S3_Long$Prompt_Flu+Gehrels_S3_Long$Flu_Err, Gehrels_S3_Long$`X-ray_F11`, length=0.05, angle=90, code=3, col = 'black')
arrows(Gehrels_S3_Short$Prompt_Flu-Gehrels_S3_Short$Flu_Err, Gehrels_S3_Short$`X-ray_F11`, Gehrels_S3_Short$Prompt_Flu+Gehrels_S3_Short$Flu_Err, Gehrels_S3_Short$`X-ray_F11`, length=0.05, angle=90, code=3, col = 'grey')
arrows(Gehrels_S3_collapsars$Prompt_Flu-Gehrels_S3_collapsars$Flu_Err, Gehrels_S3_collapsars$`X-ray_F11`, Gehrels_S3_collapsars$Prompt_Flu+Gehrels_S3_collapsars$Flu_Err, Gehrels_S3_collapsars$`X-ray_F11`, length=0.05, angle=90, code=3, col = 'blue')
arrows(Gehrels_S3_mergers$Prompt_Flu-Gehrels_S3_mergers$Flu_Err, Gehrels_S3_mergers$`X-ray_F11`, Gehrels_S3_mergers$Prompt_Flu+Gehrels_S3_mergers$Flu_Err, Gehrels_S3_mergers$`X-ray_F11`, length=0.05, angle=90, code=3, col = 'red')
abline(modGehrels3, col='black')
abline(modGehrels4, col='grey')
#add dashed lines for confidence bands
lines(10^newx, 10^preds[ ,3], lty = 'dashed', col = 'black')
lines(10^newx, 10^preds[ ,2], lty = 'dashed', col = 'black')
lines(10^newx2, 10^preds2[ ,3], lty = 'dashed', col = 'grey')
lines(10^newx2, 10^preds2[ ,2], lty = 'dashed', col = 'grey')
legend("bottomright",
       legend = c('Unknown Long', "Unknown Short", 'Mergers', 'Collapsars'),
       col = c('black', 'grey', 'red', 'blue'),
       pch = c(20, 20, 4, 8))
10^confint(modGehrels, 'x', level=0.99)
####
# Gehrels_S6_Data <- read_excel("/Users/nnuessle/Documents/Work/burst_matching_algorithm/actual_paper/prompt-and-afterglow-matching/Gehrels_Sample_6_Data.xlsx", col_types = c("skip", "numeric", "numeric", "numeric", "numeric"))
# Gehrels_S6_Data<-Gehrels_S6_Data[-c(40), ] #removed an outlier from the linear model
# collapsar_mask=Gehrels_S6_Data$Name %in% Collapsars
# merger_mask=Gehrels_S6_Data$Name %in% Mergers
# Gehrels_S6_collapsars=Gehrels_S6_Data[collapsar_mask, ]
# Gehrels_S6_mergers=Gehrels_S6_Data[merger_mask, ]
# Gehrels_S6_unknown=Gehrels_S6_Data[!c(collapsar_mask+merger_mask), ]
# long_mask=which(Gehrels_S6_unknown$t90>4.5)
# short_mask=which(Gehrels_S6_unknown$t90<=4.5)
# Gehrels_S6_Long=Gehrels_S6_unknown[long_mask, ]
# Gehrels_S6_Short=Gehrels_S6_unknown[short_mask, ]
# x<-log10(Gehrels_S6_Data$Prompt_E_iso)
# y<-log10(Gehrels_S6_Data$`X-ray_F11`)
# z<-log10(Gehrels_S6_Data$t90)
# x2<-log10(Gehrels_S6_Long$Prompt_E_iso)
# y2<-log10(Gehrels_S6_Long$`X-ray_F11`)
# z2<-log10(Gehrels_S6_Long$t90)
# ##
# modGehrels<-lm(y~x)
# par(mfrow=c(2,2))
# plot(modGehrels)
# print(anova(modGehrels))
# print(summary(modGehrels))
# #
# modGehrels2<-lm(y~x+z)
# plot(modGehrels2)
# print(anova(modGehrels2))
# print(summary(modGehrels2))
# #
# modGehrels3<-lm(y2~x2)
# par(mfrow=c(2,2))
# plot(modGehrels3)
# print(anova(modGehrels3))
# print(summary(modGehrels3))
# ##
# newx <- seq(min(x), max(x), length.out=100)
# preds <- predict(modGehrels, newdata=data.frame(x=newx), interval='prediction')
# ##
# par(mfrow=c(1,1))
# par(mar=c(5,5,5,5))
# plot(Gehrels_S6_unknown$Prompt_E_iso, Gehrels_S6_unknown$`X-ray_F11`, pch=20,  xlab=expression('Prompt E_iso 10kev-10MeV (erg, GBM)'), ylab=expression('Afterglow '~Flux[11~Hr.]~' 0.3-10 keV (erg'~cm^{-2}~s^{-1}~', XRT)'), log="xy", ylim = c(1e-16, 1e-8))
# # points(Gehrels_S6_mergers$Prompt_E_iso, Gehrels_S6_mergers$`X-ray_F11`, pch=4, col='red')
# points(Gehrels_S6_collapsars$Prompt_E_iso, Gehrels_S6_collapsars$`X-ray_F11`, pch=8, col='blue')
# abline(modGehrels)
# #add dashed lines for confidence bands
# lines(10^newx, 10^preds[ ,3], lty = 'dashed', col = 'green')
# lines(10^newx, 10^preds[ ,2], lty = 'dashed', col = 'green')
# legend("bottomright",
#        legend = c('Unknown', 'Collapsars'),
#        col = c('black', 'blue'),
#        pch = c(20, 8))
# ##
# # newx <- seq(min(x2), max(x2), length.out=100)
# # preds <- predict(modGehrels, newdata=data.frame(x2=newx), interval='prediction')
# ##
# par(mar=c(5,5,5,5))
# plot(Gehrels_S6_Long$Prompt_E_iso, Gehrels_S6_Long$`X-ray_F11`, pch=20, col='black', xlab=expression('Prompt E_iso 10kev-10MeV (erg, GBM)'), ylab=expression('Afterglow '~Flux[11~Hr.]~' 0.3-10 keV (erg'~cm^{-2}~s^{-1}~', XRT)'), log="xy", ylim = c(1e-16, 1e-8))
# points(Gehrels_S6_Short$Prompt_E_iso, Gehrels_S6_Short$`X-ray_F11`, pch=20, col='grey')
# # points(Gehrels_S3_mergers$Prompt_Flu, Gehrels_S3_mergers$`X-ray_F11`, pch=4, col='red')
# points(Gehrels_S6_collapsars$Prompt_E_iso, Gehrels_S6_collapsars$`X-ray_F11`, pch=8, col='blue')
# abline(modGehrels)
# #add dashed lines for confidence bands
# lines(10^newx, 10^preds[ ,3], lty = 'dashed', col = 'green')
# lines(10^newx, 10^preds[ ,2], lty = 'dashed', col = 'green')
# legend("bottomright",
#        legend = c('Unknown Long', "Unknown Short", 'Collapsars'),
#        col = c('black', 'grey', 'blue'),
#        pch = c(20, 20, 8))
##
# missing<-which(!complete.cases(Gehrels_S3_Data))
# no_NA_Gehrels_Data<- Gehrels_S3_Data[-missing, ]
# collapsar_mask<-no_NA_Gehrels_Data$Name %in% Collapsars
# merger_mask<-no_NA_Gehrels_Data$Name %in% Mergers
# Classification<-rep("Unknown", nrow(no_NA_Gehrels_Data))
# Classification[collapsar_mask]<-"collapsar"
# Classification[merger_mask]<-"merger"
# new_Gehrels_S3_Data<-data.frame(cbind(log10(no_NA_Gehrels_Data$Prompt_Flu), log10(no_NA_Gehrels_Data$`X-ray_F11`), log10(no_NA_Gehrels_Data$t90), Classification))
# colnames(new_Gehrels_S3_Data)<-c("Prompt_Flu", "X_ray_F11", "t90", "Classification")
# unknown_remover<-which(new_Gehrels_S3_Data$Classification=='Unknown')
# merger_mask<-which(new_Gehrels_S3_Data$Classification=='merger')
# collapsar_mask<-which(new_Gehrels_S3_Data$Classification=='collapsar')
# training_set=new_Gehrels_S3_Data[-unknown_remover, ]
# # svmfit<-svm(training_set$as.factor.Classification. ~ ., data = training_set, type = "C-classification", cost = 1.0, kernel = "sigmoid")
# training_set$Classification <- as.factor(training_set$Classification)
# table(training_set$Classification)
# rf_fit<-randomForest(Classification ~ ., data = training_set, importance = TRUE, proximity = TRUE)
# print(rf_fit)
# colnames(no_NA_Gehrels_Data)<-c("Name", "Prompt_Flu", "X_ray_F11", "t90")
# predict_rf<-predict(rf_fit, no_NA_Gehrels_Data, type="prob")
# new_table<-predict_rf
# new_table<-cbind(no_NA_Gehrels_Data$Name, new_table)
# colnames(new_table)<-c("Name", "P_collapsar", "P_merger")
# new_table<-data.frame(new_table)
# write.csv(new_table, "/Users/nnuessle/Documents/Work/burst_matching_algorithm/actual_paper/prompt-and-afterglow-matching/Gehrels_Classification.csv")
# ##
# Fermi_overlap_mask<-Goldstein_S2_Data$Name %in% Gehrels_S3_Data$Name #these are the ones BAT and XRT also saw
# Goldstein_S3_Data=Goldstein_S2_Data[Fermi_overlap_mask, ]
# missing<-which(!complete.cases(Goldstein_S3_Data)) #no, I don't know why it doesn't work on incomplete data. Ask a statistics book
# no_NA_Goldstein_S3_Data<- Goldstein_S3_Data[-missing, ]
# collapsar_mask<-no_NA_Goldstein_S3_Data$Name %in% Collapsars
# merger_mask<-no_NA_Goldstein_S3_Data$Name %in% Mergers
# Classification<-rep("Unknown", nrow(no_NA_Goldstein_S3_Data))
# Classification[collapsar_mask]<-"collapsar"
# Classification[merger_mask]<-"merger"
# new_Goldstein_S3_Data<-data.frame(cbind(log10(no_NA_Goldstein_S3_Data$`Peak E. over Flue.`), log10(no_NA_Goldstein_S3_Data$t90), as.factor(Classification)))
# colnames(new_Goldstein_S3_Data)<-c("Peak_E_over_Flu", "t90", "as.factor.Classification.")
# predicted_svm<-predict(svmfit, new_Goldstein_S3_Data, probability=TRUE) #predict the data from the next test so we can compare the two. This won't knit, btw
# new_table<-attr(predicted_svm, "probabilities") 
# new_table<-cbind(no_NA_Goldstein_S3_Data$Name, new_table)
# colnames(new_table)<-c("Name", "P_collapsar", "P_merger")
# new_table<-data.frame(new_table)
# write.csv(new_table, "/Users/nnuessle/Documents/Work/burst_matching_algorithm/actual_paper/prompt-and-afterglow-matching/Goldstein_Classification.csv")
```

```{r annoying bootstrap, echo=FALSE}
## straight up stolen from my MA392 notes by Megan Heyman
library(formula.tools)
library(RCurl)
s4<-getURL("https://raw.githubusercontent.com/elegacy/lm.boot/master/residual.boot.R", ssl.verifypeer=FALSE)
s5<-getURL("https://raw.githubusercontent.com/elegacy/lm.boot/master/wild.boot.R", ssl.verifypeer=FALSE)
eval(parse(text=s4))
eval(parse(text=s5))
remove(s4, s5)
##
set.seed(167)
errorDistn<-"t5" #choose from "t5", "U(-5, 5)"
n <- 200 #sample size
bootType<-"residual" #type of bootstrap ("residual or "wild"). we'll do the residual first.
R<- 3 #number of original samples to generate
slope<-modGehrels3$coefficients[2] #true beta 1 (unlikely)
intercept<-modGehrels3$coefficients[1] #true beta 0 (unlikely)
B<-10000 #number of bootstrap samples

ls.slope<-rep(NA, R) #it can put the LS estimates of the slopes in this vector
ls.intercept<-rep(NA, R) #and the LS estimates of the intercepts in this one
b.slope<-matrix(NA, nrow = B, ncol=R) #and then the bootstrap estimated slopes in this vector
b.intercept<-matrix(NA, nrow = B, ncol=R) #and the bootstrap estimated intercepts in this one

## finally we can start the simulation proper
for(r in 1:R){
  x<-runif(n, min(x2), max(x2)) #generate something called a fixed predictor, based on a uniform distribution. I chose to change this from [-1, 2] to the range of our original predictor variable. The actual distribution of detections isn't normal, but that's a technicality.
  if(errorDistn=="t5"){
    y<-intercept+slope*x+rt(n, df=5)
  }else{
    y<-intercept+slope*x+runif(n, -5, 5)
  }
  #fit the LSE model
  theModel<- lm(y~x)
  ls.slope[r]<-as.numeric(coef(theModel)[2])
  ls.intercept[r]<-as.numeric(coef(theModel)[1])
  #get bootstrap estimates
  if(bootType=="wild"){
    theBootEst <- wild.boot(y~x, B=B)$bootEstParam
  }else{
    theBootEst <- residual.boot(y~x, B=B)$bootEstParam
  }
  b.intercept[ , r] <- theBootEst[ , 1]
  b.slope[ , r] <- theBootEst[ , 2]
}

##let's plot the results##
par(mfrow=c(1,3))
for(r in 1:R){
 # make density curve of slope estimates
  slopeDens <- density(b.slope[,r])
  plot(slopeDens, main=paste(strwrap(paste("Estimated slope for n=200, t_5 errors, residual boot., sample", r), width = 30), collapse = "\n"))
  abline(v=slope, col="red")
  abline(v=ls.slope, col="blue", lty=2)
  legend("topright", c("Boot. Distn.", "Linear Model", "L.S.Est."), col=c(1,2,3), lty=c(1,1,2), cex = 0.8)
  #do the same thing for the intercepts
  interceptDens <- density(b.intercept[,r])
  # plot(interceptDens, main=paste("Estimated intercept for n=200, t_5 errors, residual boot., sample", r))
  # abline(v=intercept, col="red")
  # abline(v=ls.intercept, col="blue", lty=2)
  # legend("topright", c("Boot. Distn.", "Linear Model", "L.S.Est."), col=c(1,2,3), lty=c(1,1,2), cex = 0.8)
}
normalized_sorted_slopes <-(sort(b.slope, method="quick"))/abs(max(b.slope)-min(b.slope))
add_on<-normalized_sorted_slopes[1]
normalized_sorted_slopes <- normalized_sorted_slopes-add_on #re-renormalizes it so it's easier to find the percentages
#normalized_sorted_intercepts <- (sort(b.intercept, method="quick"))/max(abs(b.intercept))
#normalized_sorted_intercepts <- normalized_sorted_intercepts-normalized_sorted_intercepts[1] 
#I just realized we don't care about this
#anyway, back to finding where we're more than 99% certain
lowest_value_slope<-max(which(normalized_sorted_slopes<0.005)) #this is the left side of the confidence interval, which is more like 100%
highest_value_slope<-min(which(normalized_sorted_slopes>0.995)) #and this is the right side, which is about 99.5%
print(paste("We are more than 99% confident using a residual bootstrap that as the prompt fluence rises by a factor of ten ergs, the afterglow x-ray flux at 11 hours will change by between", 10^(normalized_sorted_slopes[lowest_value_slope]*abs(max(b.slope)-min(b.slope))+add_on), " and ", 10^(normalized_sorted_slopes[highest_value_slope]*abs(max(b.slope)-min(b.slope))+add_on), "ergs on average."))
```
```{r other annoying bootstrap, echo=FALSE}
set.seed(173)
errorDistn<-"t5" #choose from "t5", "U(-5, 5)"
n <- 200 #sample size
bootType<-"wild" #type of bootstrap ("residual or "wild"). we'll do the residual first.
R<- 3 #number of original samples to generate
slope<-modGehrels4$coefficients[2] #true beta 1 (unlikely)
intercept<-modGehrels4$coefficients[1] #true beta 0 (unlikely)
B<-10000 #number of bootstrap samples

ls.slope<-rep(NA, R) #it can put the LS estimates of the slopes in this vector
ls.intercept<-rep(NA, R) #and the LS estimates of the intercepts in this one
b.slope<-matrix(NA, nrow = B, ncol=R) #and then the bootstrap estimated slopes in this vector
b.intercept<-matrix(NA, nrow = B, ncol=R) #and the bootstrap estimated intercepts in this one

## finally we can start the simulation proper
for(r in 1:R){
  x<-runif(n, min(x2), max(x2)) #generate something called a fixed predictor, based on a uniform distribution. I chose to change this from [-1, 2] to the range of our original predictor variable. The actual distribution of detections isn't normal, but that's a technicality.
  if(errorDistn=="t5"){
    y<-intercept+slope*x+rt(n, df=5)
  }else{
    y<-intercept+slope*x+runif(n, -5, 5)
  }
  #fit the LSE model
  theModel<- lm(y~x)
  ls.slope[r]<-as.numeric(coef(theModel)[2])
  ls.intercept[r]<-as.numeric(coef(theModel)[1])
  #get bootstrap estimates
  if(bootType=="wild"){
    theBootEst <- wild.boot(y~x, B=B)$bootEstParam
  }else{
    theBootEst <- residual.boot(y~x, B=B)$bootEstParam
  }
  b.intercept[ , r] <- theBootEst[ , 1]
  b.slope[ , r] <- theBootEst[ , 2]
}

##let's plot the results##
par(mfrow=c(1,3))
for(r in 1:R){
 # make density curve of slope estimates
  slopeDens <- density(b.slope[,r])
  plot(slopeDens, main=paste(strwrap(paste("Estimated slope for n=200, t_5 errors, wild boot., sample", r), width = 30), collapse = "\n"))
  abline(v=slope, col="red")
  abline(v=ls.slope, col="blue", lty=2)
  legend("topright", c("Boot. Distn.", "Linear Model", "L.S.Est."), col=c(1,2,3), lty=c(1,1,2), cex = 0.8)
  #do the same thing for the intercepts
  interceptDens <- density(b.intercept[,r])
  # plot(interceptDens, main=paste("Estimated intercept for n=200, t_5 errors, residual boot., sample", r))
  # abline(v=intercept, col="red")
  # abline(v=ls.intercept, col="blue", lty=2)
  # legend("topright", c("Boot. Distn.", "Linear Model", "L.S.Est."), col=c(1,2,3), lty=c(1,1,2), cex = 0.8)
}
normalized_sorted_slopes <-(sort(b.slope, method="quick"))/abs(max(b.slope)-min(b.slope))
add_on<-normalized_sorted_slopes[1]
normalized_sorted_slopes <- normalized_sorted_slopes-add_on #re-renormalizes it so it's easier to find the percentages
#normalized_sorted_intercepts <- (sort(b.intercept, method="quick"))/max(abs(b.intercept))
#normalized_sorted_intercepts <- normalized_sorted_intercepts-normalized_sorted_intercepts[1] 
#I just realized we don't care about this
#anyway, back to finding where we're more than 99% certain
lowest_value_slope<-max(which(normalized_sorted_slopes<0.005)) #this is the left side of the confidence interval, which is more like 100%
highest_value_slope<-min(which(normalized_sorted_slopes>0.995)) #and this is the right side, which is about 99.5%
print(paste("We are more than 99% confident using a residual bootstrap that as the prompt fluence rises by a factor of ten ergs, the afterglow x-ray flux at 11 hours will change by between", 10^(normalized_sorted_slopes[lowest_value_slope]*abs(max(b.slope)-min(b.slope))+add_on), " and ", 10^(normalized_sorted_slopes[highest_value_slope]*abs(max(b.slope)-min(b.slope))+add_on), "ergs on average."))
```
```{r Goldstein 2.0, echo=FALSE}
Goldstein_S2_Data <- read_excel("/Users/nnuessle/Documents/Work/burst_matching_algorithm/actual_paper/prompt-and-afterglow-matching/Goldstein_Sample_2_Data.xlsx", col_types = c("skip", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric")) [-c(3), ]
par(mar=c(5,5,5,5))
collapsar_mask=Goldstein_S2_Data$Name %in% Collapsars
merger_mask=Goldstein_S2_Data$Name %in% Mergers
Goldstein_S2_collapsars=Goldstein_S2_Data[collapsar_mask, ]
Goldstein_S2_mergers=Goldstein_S2_Data[merger_mask, ]
Goldstein_S2_unknown=Goldstein_S2_Data[!c(collapsar_mask+merger_mask), ]
long_mask=which(Goldstein_S2_unknown$t90>4.2)
short_mask=which(Goldstein_S2_unknown$t90<=4.2)
Goldstein_S2_Long=Goldstein_S2_unknown[long_mask, ]
Goldstein_S2_Short=Goldstein_S2_unknown[short_mask, ]
plot(Goldstein_S2_Long$t90, Goldstein_S2_Long$`Peak E. over Flue.`, pch=20, ylab=expression(E[p]/S[prompt]~' 10kev-10MeV ('~erg ~ cm^{2} ~ erg^{-1} ~ ', GBM)'), xlab='t90 (s, GBM)', log="xy", xlim=c(1e-2, 1e3))
points(Goldstein_S2_Short$t90, Goldstein_S2_Short$`Peak E. over Flue.`, pch=20, col='grey')
points(Goldstein_S2_mergers$t90, Goldstein_S2_mergers$`Peak E. over Flue.`, pch=4, col='red')
points(Goldstein_S2_collapsars$t90, Goldstein_S2_collapsars$`Peak E. over Flue.`, pch=8, col='blue')
legend("topleft",
       legend = c('Unknown Long', 'Unknown Short', "Mergers", 'Collapsars'),
       col = c('black', 'grey', 'red', 'blue'),
       pch = c(20, 20, 4, 8))
##
missing<-which(!complete.cases(Goldstein_S2_Data))
no_NA_Goldstein_S2_Data<- Goldstein_S2_Data[-missing, ]
collapsar_mask<-no_NA_Goldstein_S2_Data$Name %in% Collapsars
merger_mask<-no_NA_Goldstein_S2_Data$Name %in% Mergers
# short_list<-which(no_NA_Goldstein_S2_Data$t90<4.2)
# long_list<-which(no_NA_Goldstein_S2_Data$t90>4.2)
Classification<-rep("Unknown", nrow(no_NA_Goldstein_S2_Data))
# Classification[short_list]<-"merger"
# Classification[long_list]<-"collapsar" 
Classification[collapsar_mask]<-"collapsar"
Classification[merger_mask]<-"merger"
new_Goldstein_S2_Data<-data.frame(cbind(log10(no_NA_Goldstein_S2_Data$`Peak E. over Flue.`), log10(no_NA_Goldstein_S2_Data$t90), as.factor(Classification)))
colnames(new_Goldstein_S2_Data)<-c("Peak_E_over_Flu", "t90", "as.factor.Classification.")
# model <- randomForest(formula = no_NA_H_2b_Data$Classification ~ ., data = no_NA_H_2b_Data)
unknown_remover<-which(new_Goldstein_S2_Data$as.factor.Classification.==3)
merger_mask<-which(new_Goldstein_S2_Data$as.factor.Classification.==2)
collapsar_mask<-which(new_Goldstein_S2_Data$as.factor.Classification.==1)
training_set=new_Goldstein_S2_Data[-unknown_remover, ]
svmfit<-svm(training_set$as.factor.Classification. ~ ., data = training_set, type = "C-classification", cost = 1.0, kernel = "sigmoid", probability=TRUE)
print(svmfit)
plot(svmfit, training_set, Peak_E_over_Flu~t90, ylab=expression(E[p]/S[prompt]~' 10kev-10MeV ('~erg ~ cm^{2} ~ erg^{-1} ~ ', GBM)'), xlab='t90 (s, GBM)', log="xy")
# points(log10(Goldstein_S2_unknown$t90), log10(Goldstein_S2_unknown$`Peak E. over Flue.`))
predicted_svm<-predict(svmfit, new_Goldstein_S2_Data[unknown_remover, ], probability=TRUE)
new_table<-attr(predicted_svm, "probabilities")
new_table<-cbind(no_NA_Goldstein_S2_Data$Name, no_NA_Goldstein_S2_Data$t90, no_NA_Goldstein_S2_Data$`Peak E. over Flue.`, new_table)
colnames(new_table)<-c("Name", "t90", "E_P_Over_S", "P_collapsar", "P_merger")
new_table<-data.frame(new_table)
write.csv(new_table, "/Users/nnuessle/Documents/Work/burst_matching_algorithm/actual_paper/prompt-and-afterglow-matching/Goldstein_Classification.csv")
colnames(Goldstein_S2_collapsars)<-c("Name", "Peak_E_over_Flu", "E_P_Over_S_Err", "`Hardness Ratio`", "t90", "t90_err")
new_Goldstein_S2_Data<-new_Goldstein_S2_Data;
new_Goldstein_S2_Data$Peak_E_over_Flu<-10^(new_Goldstein_S2_Data$Peak_E_over_Flu)
# new_Goldstein_S2_Data$E_P_Over_S_Err<-10^(new_Goldstein_S2_Data$E_P_Over_S_Err)
new_Goldstein_S2_Data$t90<-10^(new_Goldstein_S2_Data$t90)
# new_Goldstein_S2_Data$t90_err<-10^(new_Goldstein_S2_Data$t90_err)
new_Goldstein_S2_collapsars<-Goldstein_S2_collapsars;
# new_Goldstein_S2_collapsars$Peak_E_over_Flu<-log10(new_Goldstein_S2_collapsars$Peak_E_over_Flu)
# new_Goldstein_S2_collapsars$E_P_Over_S_Err<-log10(new_Goldstein_S2_collapsars$E_P_Over_S_Err)
# new_Goldstein_S2_collapsars$t90<-log10(new_Goldstein_S2_collapsars$t90)
# new_Goldstein_S2_collapsars$t90_err<-log10(new_Goldstein_S2_collapsars$t90_err)
colnames(Goldstein_S2_mergers)<-c("Name", "Peak_E_over_Flu", "E_P_Over_S_Err", "`Hardness Ratio`", "t90", "t90_err")
new_Goldstein_S2_mergers<-Goldstein_S2_mergers;
# new_Goldstein_S2_mergers$Peak_E_over_Flu<-log10(new_Goldstein_S2_mergers$Peak_E_over_Flu)
# new_Goldstein_S2_mergers$E_P_Over_S_Err<-log10(new_Goldstein_S2_mergers$E_P_Over_S_Err)
# new_Goldstein_S2_mergers$t90<-log10(new_Goldstein_S2_mergers$t90)
# new_Goldstein_S2_mergers$t90_err<-log10(new_Goldstein_S2_mergers$t90_err)
ggplot(new_Goldstein_S2_Data[unknown_remover, ], aes(x = t90, y = Peak_E_over_Flu, colour = attr(predicted_svm, "probabilities")[,1])) +geom_point(size = 1)+ylab(expression(E[p]/S[prompt]~' 10kev-10MeV ('~keV ~ cm^{2} ~ erg^{-1} ~ ', GBM)'))+xlab('t90 (s, GBM)')+scale_colour_gradient2(low = "grey",mid =muted("blue"), high = "black",  midpoint = 0.5, name="Inferred Collapsar\n Probability")+geom_point(data = new_Goldstein_S2_mergers, color = "red")+geom_point(data = new_Goldstein_S2_collapsars, color = "cyan")+scale_y_log10(labels = trans_format("log10", math_format(10^.x)))+scale_x_log10(labels = trans_format("log10", math_format(10^.x)))
plot(NULL ,xaxt='n',yaxt='n',bty='n',ylab='',xlab='', xlim=0:1, ylim=0:1)
legend("topleft", title='Known Burst Types', legend = c('Detected Collapsar', 'Detected Merger'), col = c( 'cyan', 'red'),  pch = c(20, 20))
write.svm(svmfit, svm.file = "Goldstein-classifier.svm", scale.file = "Goldstein-classifier.scale")
# plot(new_Goldstein_S2_Data[unknown_remover, ]$Peak_E_over_Flu~new_Goldstein_S2_Data[unknown_remover, ]$t90, ylab=expression(E[p]/S[prompt]~' 10kev-10MeV ('~erg ~ cm^{2} ~ erg^{-1} ~ ', GBM)'), xlab='t90 (s, GBM)', col=attr(predicted_svm, "probabilities")[,1], pch=20)
# points(log10(Goldstein_S2_mergers$t90), log10(Goldstein_S2_mergers$`Peak E. over Flue.`), pch=4, col='#09622A')
# points(log10(Goldstein_S2_collapsars$t90), log10(Goldstein_S2_collapsars$`Peak E. over Flue.`), pch=8, col='blue')
# legend("bottomleft",
#        legend = c('Sorted Collapsars', 'Sorted Mergers', "Detected Mergers", 'Detected Collapsars'),
#        col = c('black', 'grey', 'red', 'cyan'),
#        pch = c(20, 20, 20, 20))
###
#now let's try it on the overlapping sample with redshifts
Goldstein_S6_Data <- read_excel("/Users/nnuessle/Documents/Work/burst_matching_algorithm/actual_paper/prompt-and-afterglow-matching/Goldstein_Sample_6_Data.xlsx", col_types = c("skip", "numeric", "numeric", "numeric", "numeric"))
missing<-which(!complete.cases(Goldstein_S6_Data))
no_NA_Goldstein_S6_Data<- Goldstein_S6_Data[-missing, ]
collapsar_mask<-no_NA_Goldstein_S6_Data$Name %in% Collapsars
merger_mask<-no_NA_Goldstein_S6_Data$Name %in% Mergers
Classification<-rep("Unknown", nrow(no_NA_Goldstein_S6_Data))
Classification[collapsar_mask]<-"collapsar"
Classification[merger_mask]<-"merger"
new_Goldstein_S6_Data<-data.frame(cbind(log10(no_NA_Goldstein_S6_Data$`Peak E. over Flue.`), log10(no_NA_Goldstein_S6_Data$t90), as.factor(Classification)))
colnames(new_Goldstein_S6_Data)<-c("Peak_E_over_Flu", "t90", "as.factor.Classification.")
unknown_remover<-which(new_Goldstein_S6_Data$as.factor.Classification.==3)
Second_predicted_svm<-predict(svmfit, new_Goldstein_S6_Data)
plot(new_Goldstein_S6_Data$Peak_E_over_Flu~new_Goldstein_S6_Data$t90, ylab=expression(E[p]/S[prompt]~' 10kev-10MeV ('~erg ~ cm^{2} ~ erg^{-1} ~ ', GBM)'), xlab='t90 (s, GBM)', col=Second_predicted_svm, pch=20)
svm_check=predict(svmfit, new_Goldstein_S6_Data[-unknown_remover, ])
confusionMatrix(svm_check, factor(new_Goldstein_S6_Data[-unknown_remover, ]$as.factor.Classification.), dnn = c("Prediction", "Reference"))
```

```{r Chunk just for error bars, echo=FALSE}
Goldstein_S2_Data <- read_excel("/Users/nnuessle/Documents/Work/burst_matching_algorithm/actual_paper/prompt-and-afterglow-matching/Goldstein_Sample_2_Data.xlsx", col_types = c("skip", "numeric", "numeric", "numeric", "numeric", "numeric", "numeric")) [-c(3), ]
par(mar=c(5,5,5,5))
collapsar_mask=Goldstein_S2_Data$Name %in% Collapsars
merger_mask=Goldstein_S2_Data$Name %in% Mergers
Goldstein_S2_collapsars=Goldstein_S2_Data[collapsar_mask, ]
Goldstein_S2_mergers=Goldstein_S2_Data[merger_mask, ]
Goldstein_S2_unknown=Goldstein_S2_Data[!c(collapsar_mask+merger_mask), ]
long_mask=which(Goldstein_S2_unknown$t90>4.2)
short_mask=which(Goldstein_S2_unknown$t90<=4.2)
Goldstein_S2_Long=Goldstein_S2_unknown[long_mask, ]
Goldstein_S2_Short=Goldstein_S2_unknown[short_mask, ]
plot(Goldstein_S2_Long$t90, Goldstein_S2_Long$`Peak E. over Flue.`, pch=20, ylab=expression(E[p]/S[prompt]~' 10kev-10MeV ('~erg ~ cm^{2} ~ erg^{-1} ~ ', GBM)'), xlab='t90 (s, GBM)', log="xy", xlim=c(1e-2, 1e3))
points(Goldstein_S2_Short$t90, Goldstein_S2_Short$`Peak E. over Flue.`, pch=20, col='grey')
points(Goldstein_S2_mergers$t90, Goldstein_S2_mergers$`Peak E. over Flue.`, pch=4, col='red')
points(Goldstein_S2_collapsars$t90, Goldstein_S2_collapsars$`Peak E. over Flue.`, pch=8, col='blue')
legend("topleft",
       legend = c('Unknown Long', 'Unknown Short', "Mergers", 'Collapsars'),
       col = c('black', 'grey', 'red', 'blue'),
       pch = c(20, 20, 4, 8))
##
missing<-which(!complete.cases(Goldstein_S2_Data))
no_NA_Goldstein_S2_Data<- Goldstein_S2_Data[-missing, ]
collapsar_mask<-no_NA_Goldstein_S2_Data$Name %in% Collapsars
merger_mask<-no_NA_Goldstein_S2_Data$Name %in% Mergers
# short_list<-which(no_NA_Goldstein_S2_Data$t90<4.2)
# long_list<-which(no_NA_Goldstein_S2_Data$t90>4.2)
Classification<-rep("Unknown", nrow(no_NA_Goldstein_S2_Data))
# Classification[short_list]<-"merger"
# Classification[long_list]<-"collapsar" 
Classification[collapsar_mask]<-"collapsar"
Classification[merger_mask]<-"merger"
new_Goldstein_S2_Data<-data.frame(cbind(log10(no_NA_Goldstein_S2_Data$`Peak E. over Flue.`), log10(no_NA_Goldstein_S2_Data$E_P_Over_S_Err), log10(no_NA_Goldstein_S2_Data$t90), log10(no_NA_Goldstein_S2_Data$t90_err), as.factor(Classification)))
colnames(new_Goldstein_S2_Data)<-c("Peak_E_over_Flu", "Peak_E_over_Flu_err", "t90", "t90_err", "as.factor.Classification.")
# model <- randomForest(formula = no_NA_H_2b_Data$Classification ~ ., data = no_NA_H_2b_Data)
unknown_remover<-which(new_Goldstein_S2_Data$as.factor.Classification.==3)
merger_mask<-which(new_Goldstein_S2_Data$as.factor.Classification.==2)
collapsar_mask<-which(new_Goldstein_S2_Data$as.factor.Classification.==1)
training_set=new_Goldstein_S2_Data[-unknown_remover, ]
svmfit<-svm(training_set$as.factor.Classification. ~ ., data = training_set, type = "C-classification", cost = 1.0, kernel = "sigmoid", probability=TRUE)
print(svmfit)
plot(svmfit, training_set, Peak_E_over_Flu~t90, ylab=expression(E[p]/S[prompt]~' 10kev-10MeV ('~erg ~ cm^{2} ~ erg^{-1} ~ ', GBM)'), xlab='t90 (s, GBM)', log="xy")
# points(log10(Goldstein_S2_unknown$t90), log10(Goldstein_S2_unknown$`Peak E. over Flue.`))
predicted_svm<-predict(svmfit, new_Goldstein_S2_Data[unknown_remover, ], probability=TRUE)
new_table<-attr(predicted_svm, "probabilities")
new_table<-cbind(no_NA_Goldstein_S2_Data$Name, no_NA_Goldstein_S2_Data$t90, no_NA_Goldstein_S2_Data$`Peak E. over Flue.`, new_table)
colnames(new_table)<-c("Name", "t90", "E_P_Over_S", "P_collapsar", "P_merger")
new_table<-data.frame(new_table)
write.csv(new_table, "/Users/nnuessle/Documents/Work/burst_matching_algorithm/actual_paper/prompt-and-afterglow-matching/Goldstein_Classification.csv")
colnames(Goldstein_S2_collapsars)<-c("Name", "Peak_E_over_Flu", "Peak_E_over_Flu_err", "`Hardness Ratio`", "t90", "t90_err")
new_Goldstein_S2_Data<-new_Goldstein_S2_Data;
new_Goldstein_S2_Data$Peak_E_over_Flu<-10^(new_Goldstein_S2_Data$Peak_E_over_Flu)
new_Goldstein_S2_Data$Peak_E_over_Flu_err<-10^(new_Goldstein_S2_Data$Peak_E_over_Flu_err)
new_Goldstein_S2_Data$t90<-10^(new_Goldstein_S2_Data$t90)
new_Goldstein_S2_Data$t90_err<-10^(new_Goldstein_S2_Data$t90_err)
new_Goldstein_S2_collapsars<-Goldstein_S2_collapsars;
# new_Goldstein_S2_collapsars$Peak_E_over_Flu<-log10(new_Goldstein_S2_collapsars$Peak_E_over_Flu)
# new_Goldstein_S2_collapsars$E_P_Over_S_Err<-log10(new_Goldstein_S2_collapsars$E_P_Over_S_Err)
# new_Goldstein_S2_collapsars$t90<-log10(new_Goldstein_S2_collapsars$t90)
# new_Goldstein_S2_collapsars$t90_err<-log10(new_Goldstein_S2_collapsars$t90_err)
colnames(Goldstein_S2_mergers)<-c("Name", "Peak_E_over_Flu", "Peak_E_over_Flu_err", "`Hardness Ratio`", "t90", "t90_err")
new_Goldstein_S2_mergers<-Goldstein_S2_mergers;
ggplot(new_Goldstein_S2_Data[unknown_remover, ], aes(x = t90, y = Peak_E_over_Flu, colour = attr(predicted_svm, "probabilities")[,1])) +ylab(expression(E[p]/S[prompt]~' 10kev-10MeV ('~keV ~ cm^{2} ~ erg^{-1} ~ ', GBM)'))+xlab('t90 (s, GBM)')+scale_colour_gradient2(low = "grey",mid =muted("blue"), high = "black",  midpoint = 0.5, name="Inferred Collapsar\n Probability")+geom_point(data = new_Goldstein_S2_mergers, color = "red")+geom_point(data = new_Goldstein_S2_collapsars, color = "cyan")+scale_y_log10(labels = trans_format("log10", math_format(10^.x)))+scale_x_log10(labels = trans_format("log10", math_format(10^.x)))+geom_pointrange(aes(ymin=Peak_E_over_Flu-Peak_E_over_Flu_err, ymax=Peak_E_over_Flu+Peak_E_over_Flu_err))+geom_pointrange(aes(xmin=t90-t90_err, xmax=t90+t90_err))+geom_pointrange(data=new_Goldstein_S2_mergers, aes(ymin=Peak_E_over_Flu-Peak_E_over_Flu_err, ymax=Peak_E_over_Flu+Peak_E_over_Flu_err), color = "red")+geom_pointrange(data=new_Goldstein_S2_mergers, aes(xmin=t90-t90_err, xmax=t90+t90_err), color = "red")+geom_pointrange(data=new_Goldstein_S2_collapsars, aes(ymin=Peak_E_over_Flu-Peak_E_over_Flu_err, ymax=Peak_E_over_Flu+Peak_E_over_Flu_err), color = "cyan") +geom_pointrange(data=new_Goldstein_S2_collapsars, aes(xmin=t90-t90_err, xmax=t90+t90_err), color = "cyan")
```
